To Do

* document new use of 'TaskID failed' as an output: added on the fly as
  a new output if failure occurs, then removed from the output list on
  reset.

* if chooser is clicked just as target system shuts down, failure to
  connect error breaks the app, requiring use of 'kill'.

* lockserver errors to a logfile (e.g. if it is killed it silently 
  fails to restart due to existing Pyro nameserver entry).

* cylc ping hangs if cylc is killed without cleaning up: needs timeout.

* long-running (almost 1 day) dummy mode oper run (started via vnc for
  ministerial opening demo) could not be unlocked or stopped (etc.) -
  got remote I/O Error via Pyro?

* env vars in %TASK - e.g. $[HOME]

* cycle-time conditional environment and commandlines in taskdefs.

* persistent state for lockserver, in case of crash or restart while
  systems are running. 

* use new cylc_mode class everywhere mode test is required.

* dummy task does not use lockserver

* lockserver: non-user-specific ($HOME-relative) pid file required, so
  user-specific .cylcrc is not the right place to store this information
  (multiple users need to be able to access the lockserver, but perhaps not
   start and stop it).  MAYBE $CYLC_DIR/.cylcrc IS REQUIRED?

* submit --scheduler: task state resets to 'running' but all messages
  are ignored.

* task stdout and stderr for remote tasks!

* consider how task timeout alerts might be incorporated into cylc? 

* extreme task elimination method - extrapolate forward in time to see
  if a finished task will ever be needed, otherwise delete?

* iteration over dictionary items: DO NOT USE
  = for item in dict:
  =    (operation that adds or removes items from dict)
  -> RuntimeError: dictionary changed size during iteration

  Instead use
  = for item in dict.keys():
  which must build a temporary list?

  CHECK MY USE OF DICTIONARY ITERATION THROUGHOUT THE CODE

* Record stopping time in state dump in case system shutdown and
  restarted before all tasks reach the stop time is reached? (currently
  at restart those that did reach the stop time will be finished and
  unspawned, while those that didn't will carry on as if there was no
  stop time).

* Document UM-style custom-wrapper based job submission.

* catch obscure errors, such as attempting to restart when one or more 
  tasks has been commented out of the task list.

* src/which.py, like the shell command, searches only for executable
  files. The ll_raw job submit classes use which to find task scripts
  that don't have a full path supplied in the taskdef; these need
  to check that which returns a result before continuing (e.g. if 
  the task script has not been set executable). 

* DOCUMENT: daemon and asynchronous task

* WILL_SATSIFY_ME() REQUIRED FOR FUZZY and LOOSE PREREQUISITES?
  (else purge will fail if involving these tasks).

* task groups defined in system_config cause abort if any of the tasks
  therein are not defined (e.g. if commented out of the task list!)

* parse "HH:mm" for contact delay times etc.

* message command (command line usage only!!!) needs lock and practice mode?

* FINISH OFF THE CONNECTION EXCEPTION HANDLING IN MANAGER CLASS.

* consider reset --no-spawn (Bernard tried to reset a waiting unspawned
  task to finished, which made it spawn ... is this the desired
  behaviour?)

* insert may need a no-spawn option!

* consider restart messages for split tasks that actually use the same 
  restart files: e.g. nzlam_long (06,18Z) and nzlam_short (00,12Z). 
  Currently must combine this into one task with conditionals, OR 
  register (and report) restart messages explicitly because the
  automatic restart messages will not have the right task name.

* check that practice mode systems initialise with the same clock time
  as the original system!

* DOCUMENT or CHANGE: cotemporal peers of failed tasks are not deleted
  automatically because they we USED TO restart with failed tasks in the 
  'waiting' state (not 'ready') - thus the aforementioned peers may be
  required to satisfy the failed task's prerequisites post resetting.

* Consider the effect of "# uncomment for earliest NON-FAILED" (x2) in
  manager.py - and test with dummy mode failout tasks.  For failed F in
  userguide example system, it allows some intermediate finished cycles
  to be deleted, but this does not affect the delay due to max runahead.

* consider task proc loop invocation - could we separate summary update
  vs task processing (e.g. when a task fails we have to run pointlessly
  (?) through the loop in order to update the summary immediately for
  monitoring.

* warn about consequences of deleting a task: system may move on so that
  a reinserted task will not get its prerequisites satisfied.

* task generator should look for mispelled $(CYLCE_TIME)

* is taskdef CYCLES sorted for order?

* optionally allow a pyro request handling (or main loop?) timeout.
  (this is not needed now that the stalling problem is solved?)

* consistent system exit strategy: 
   -sys.exit(1), 
   -raise SystemExit(message)
   -custom exceptions

* all error messages should go to stderr: print >> sys.stderr, 'message'

* Conditional and "self destruct" prerequisites would allow automated
  response, by cylc, to failed tasks rather than delegating that
  responsibility to the system operator or to the external task
  implementation. For example IF a weather forecast fails, run a backup
  forecast configured with a shorter timestep, but IF the original
  forecast succeeds, the backup can self destruct (remove itself from
  the system). Forecast post-processing task(s) would trigger off EITHER
  the original or the backup forecast.

* allow cylc task proxies to kill their real external tasks at shutdown
  (and otherwise)?

* make sure that no remote operation, other than 'stop', can bring a
  system down (exception handling on all remote switches).

* when there are multiple finished tasks that can satisfy a new task's
  restart prerequisites, the one that actually satisfies the new task
  will be an essentially random choice (the first one that comes along). 
  This is OK because the only thing that matters is that at least one
  task can satisfy the restart dependency, then the new task calls the
  prerequisite satisfied. However, we could get tasks to record the ID
  of the satisfier task as well, for each prerequisite, and also to
  choose the latest task as satisfier if more than one can do it.

* the task-generator script should check that the user-defined task
  names do not clash with parent class or attribute names.

* when remote killing all waiting tasks at a ref time, check that (a)
  the system has moved on passed that time, and (b) none of the waiting
  tasks are contact tasks whose time has not come up yet.

* tasks with conditional outputs may have trouble with the "keep one
  finished task of each kind" procedure in kill_spent_tasks(). best to
  have multiple tasks instead? 

* detect when taskdef files are newer than task_classes file, and warn
  that use of configure-system may be required.

* use the custom clock everywhere (it knows about dummy mode).

* clean up the clock class with respect to dummy vs real time, and move
  it into task manager?

* do we need non-interpolation of single-quoted strings in taksdef
  environment vars, commandline, extra scripting etc. (would be
  implemented in jobs_submit.py)?

====================================
FUZZY PREREQUISITES (only for infrequent 'advanced' usage - e.g. hourly
TopNet in EcoConnect)

* allow mixed fuzzy and non-fuzzy prerequisites (currently have to 
  set identical fuzzy bounds to simulate the non-fuzzy case; see
  topnet.py).

* FUZZY MATCHING CURRENTLY ASSUMES AT MOST ONE COMPATIBLE OLDER FINISHED
  VERSION OF THE UPSTREAM TASK IS PRESENT, otherwise the match occurs
  with the first one found, whichever it is. This can fail if a system
  problem puts a hold on spent task deletion! E.g.: topnet and oper
  interface go on ahead when topnet_vis has failed (unlikely to happen
  though!)

* just before a task runs, try to re-satisfy fuzzy prerequisites in case
  a more up-to-date satisfier has shown up while the task was waiting
  for other prerequisites to be satisfied ... OR (better?!) don't try to
  satisfy fuzzy prerequistes until after all non-fuzzy ones have been
  satsified. 
