
Since moving cylc to github, I'm using this page to keep track of 
half-formed ideas and issues that require further investigation 
before concluding there is a problem ... at which point the issue
can be migrated to the github issue tracker.

_______
GENERAL

* Restarting a suite with a failed family but no failed members fails 
  (can be tested in dummy mode):
  Traceback (most recent call last):
    File "/oper/admin/ecoconnect_admin/cylc-3.3.5/bin/_restart", line 260, in ?
server.run()
    File "/oper/admin/ecoconnect_admin/cylc-3.3.5/src/scheduler.py", line 469, in run
self.negotiate()
    File "/oper/admin/ecoconnect_admin/cylc-3.3.5/src/scheduler.py", line 746, in negotiate
itask.check_requisites()
    File "/oper/admin/ecoconnect_admin/cylc-3.3.5/src/task-types/family.py", line 60, in check_requisites
    self.incoming( 'NORMAL', self.id + ' succeeded' )
    File "/oper/admin/ecoconnect_admin/cylc-3.3.5/src/task-types/task.py", line 461, in incoming
self.__class__.update_mean_total_elapsed_time( self.started_time, self.succeeded_time )
    File "/oper/admin/ecoconnect_admin/cylc-3.3.5/src/task-types/task.py", line 139, in update_mean_total_elapsed_time
cls.elapsed_times.append( succeeded - started )
    TypeError: unsupported operand type(s) for -: 'datetime.datetime' and 'NoneType'

* Consider changing the task pool list to a dictionary indexed by task
  ID. This would avoid having to loop through the pool to find a task.
* Also, consider a major change to the scheduling algorithm that would
  fit quite nicely with a dict-based task pool: if dict values contain 
  a list of *known trigger tasks* determined from the dependency graph
  each task could just ask those tasks, rather than all of them (via the
  broker) for satisfaction. We could then eliminate the broker, and
  may significantly increase efficiency for very large suites?

* suite validation problem: missing '=' causes crash due to configobj
  error.

* lockserver configuration is currently installation-wide under
  $CYLC_DIR/conf - should allow user override.

* RECURSIVE PURGE OVERHAUL? see documentation of limitations in the
  purge command help. Post cylc-3.0 we could easily determine, via the
  suite dependency graph, if any tasks that should be affected by the
  purge have not yet reached the purge start time. Also: see TO DO in
  the in-method comments: ensure that ALL tasks whose prerequisites get
  satisfied in the virtual system evolution that occurs in the purge
  algorithm, get unsatisfied again at the end of it.
 (consider also: clock-triggered tasks downstream of the purge root -
 they won't trigger in the purge simulation if their time is not up yet?)

* dummy_command module not needed due to default command in suite.rc?

* a 'nudge' that just updates task state info, without going through
  the full task processing loop?

* warm, cold, and raw start should insert tasks beyond the optional
  final task in the 'held' state, not just delete them? (see 'STOPPING'
  in bin/_run

*  Do suicide prerequisites need to be re-instated in cylc-3? Maybe they 
   are not needed now that we have conditional prerequisites?

* system level install of cylc - the (non-system-level) cylc environment 
  script is currently source automatically by cylc task job scripts.

* Consider replacing finished tasks with a data structure that remembers
  what happened. More efficient for very large suites?

* IMPORTANT: rationalize suite shutdown criteria in main loop.

* exclude failed tasks in the cleanup algorithms.
  Failed mean prereqs were satisfied so we don't need to keep 
  upstream tasks around. This may depend on the next item:
* cleanup algorithm and failed tasks: test with userguide suite in dummy
  mode, failing C and F. In case of F, why do none of A,B,C get
  removed? 

* exclude inserted spinup/temporary tasks from runahead check?
  (or manually alter the check - this should be fine because the
  catching up spinup task will be all alone out behind the 
  caught-up operational tasks - so the suite won't get cluttered
  with finished tasks as a result of the long runahead limit).

* errors caught by validate should also be caught cleanly if the user
  tries to start the suite. E.g. misspell a task in 'tasks to exclude at
  startup'.  And/or should a full validation be done automatically prior
  to starting a suite? 

* GUI: check for suite block before popping up entry dialogs?

* Practice mode (currently disabled):
    * message command (command line usage only) lock and practice mode?
    * practice mode should be allowed even for exclusive suite locks. 
    * check that practice mode suites initialise with the same clock time
      as the original suite.

* method arg checking in remote switch: just use generic exception
  handling for efficiency, leaving specific arg format checking to
  the commands?

* stop-at-cycle-time won't shutdown if there are any tasks stuck in
  'waiting', even if they are all passed the stop cycle (still true?).

* temporary job file location should be configurable, other than via
  $TMPDIR?

* update cylc xdot code from latest version available? (see recently
  deleted 'external' directory)

* log a warning for remote change to runahead limit.

* config(suite) writes to stdout/stderr (gcylc parent terminal) - see
  gcylc:view_log() for a non-validating suite.

* allow $CYLC_DIR/conf overrides by user in .cylc?

* db export, copy, import should take group: as target even for single suites.

* clean up src/gui/textload.py and use of it: it was quickly hacked out
  of the tailing logviewer and should be treated separately and more simply.

* CANNOT USE a suite reg GROUP:NAME as a suite definition dir
  as the colon screws up the PATH to the suite bin directory.

* tasks that are not in the dep graph can now be run with 'submit';
  should we allow insertion too?

* clean up prerequisites classes - put all in one module? (same with
  outputs + requisites?)

* SystemExit() in config.py, cylcconfigobj, (...?) BAD FOR GUI!

* gcylc: setting running suite group green fails if multiple suites are
  running. Need to parse each group member and check if any are running.

* Consider possible changes to cylc internals in light of the fact
  that as of cylc-3 we know all task dependencies in advance, thanks
  to the suite.rc dependency graph. E.g. we may be able to remove many
  finished tasks ahead of the generic cleanup cut off.

* locking code could be simplified or cleaned up a bit now that
  the lockserver is user-specific?

* consider calling task-started from task execution script instead of
  cylc-wrapper or task scripts: this would eliminate submitted state
  failures, and allow error trapping on tasks with significant
  in-suiterc scripting (and scripting-only tasks?)

* currently all task reset commands go through the 'remote' object,
  which all suites have, but we could get a proxy for the task proxy directly,
  in which case we'd could catch Pyro.NamingError to detect if no such
  task exists in the suite. 

* Pyro config:
  + PYRO_MAXCONNECTIONS , default 200: max number
  of simultaneous connections to a single pyro server?
  The default connection validator checks for this.
  + port range: set sufficiently wide for large sites.
  (Consider lockservers too)
  + consider Pyro multi-threading again?

* '--host' should not be allowed for intervention commands because
  owner's username does not cross machine boundaries, generally.

* what happens if we restart after suite.rc task content changed?

* Check that the user-defined task names do not clash with
  parent class or attribute names.

* Do some more profiling of execution time with cProfile and pstats,
  to identify areas where we might be able to make efficiency gains.

* --port= does not prevent port scan for lockserver?
  check for non-essential port scanning, esp. in gui.
  (see GUI note below)

* ?can deletion and insertion while a suite is HELD result in 
    "INSERTING A TASK
      ERROR: A%2010081800 has already registered its outputs"

* document reason for naming of pyro-connected objects
  (owner.suite.obj): prevent accidentally intervening in the wrong
  suite when using explicit port numbers (if we allow that). Also, 
  is this still required?

* temporary job submission filenames should contain the suite name
  so that automated cleanup processes can distinguish between suites.

* Python re: check use of re m.group() and m.groups(): 

    m.group(0)  # entire match
    m.group(1)  # first parenthesised sub-group
                # ...

    m.groups()  # tuple of parenthesised sub-groups


* task ID should not be needed in message strings (?); it can be supplied 
  automatically by access methods (for started, finished, etc.)

* cycle-dependent number of restarts: this can cause problems because
  only the most recent finished task is retained to satisfy
  prerequisites. If a task alternately does short and long forecasts
  with accordingly few and many restart outputs, we must retain *both*
  previously finished short and long versions of the task when currently
  only the short one would be retained. THE CYLC TASK ELIMINATION
  ALGORITHM MUST TAKE RESTART OUTPUTS INTO ACCOUNT: Do not eliminate a
  finished task if its restart outputs are still valid.
* DUPLICATE?: consider restart messages for split tasks that actually
  use the same restart files: e.g. nzlam_long (06,18Z) and nzlam_short
  (00,12Z).  Currently must combine this into one task with
  conditionals, OR register (and report) restart messages explicitly
  because the automatic restart messages will not have the right task
  name.

* consider some kind of internal queuing system as a more flexible
  alternative to the simple max runahead limit?

* check all open( file, mode ) statements for mode 'rb' etc. 

* wherever I've used this:
    os.makedirs( os.path.dirname( filename ) )
  check that filename is not just a bare local dir filename like foo.bar
  as opposed to dir/foo.bar, else dirname() will return empty string and 
  makedirs() will fail.  This could happen if the user tries to use
  files in $PWD without specifying the full path.

* example system implementations should always use $USER in temp dir
  paths, to avoid interference between users. (done?)

* allow insertion of tasks in 'spawned already' state, for oneoff runs 
  of non-oneoff tasks?

* stop (without --now) won't cause shutdown if a task family (but not
  it's members) has just triggered?

* task state at initialization: there's no point in giving initial
  state of "finished" for example, if this does not result in setting
  prerequisites and outputs satisfied and completed, respectively.
  Consolidate this task state resetting code into methods in task.py?

* note that prerequisites are no longer derived from requisites. Change
  documentation in the latter class (and elsewhere?) to reflect this.

* use new cylc_mode class everywhere mode test is required.

* consider more specialized messaging commands:
    cylc task error
    cylc task warning
    cylc task message
    cylc task output

* cylc submit --scheduler: task state resets to 'running' but all
  messages are ignored.

* extreme task elimination method - extrapolate forward in time to see
  if a finished task will ever be needed, otherwise delete? Or, post 
  cylc-3, use the predefined dependency graph to detect tasks that 
  will not be needed anymore?

* CHECK USE OF DICTIONARY ITERATION THROUGHOUT THE CODE:
    for item in dict:
       (operation that adds or removes items from dict)
  => RuntimeError: dictionary changed size during iteration

  Instead use:
    for item in dict.keys():
  which must build a temporary list?

* src/which.py, like the shell command, searches only for executable
  files. The ll_raw job submit classes use which to find task scripts
  that don't have a full path supplied in the taskdef; these need
  to check that which returns a result before continuing (e.g. if 
  the task script has not been set executable). 

* DAEMON TASKS: as for asynchronous tasks, demonstrated in cylc-2; go
  back, check, and complete, for cylc-3.

* consider reset --no-spawn (Bernard tried to reset a waiting unspawned
  task to finished, which made it spawn ... is this the desired
  behaviour?)

* DOCUMENT or CHANGE: cotemporal peers of failed tasks are not deleted
  automatically because we USED TO restart with failed tasks in the 
  'waiting' state (not 'ready') - thus the aforementioned peers may be
  required to satisfy the failed task's prerequisites post resetting.

* consider task proc loop invocation - could we separate summary update
  vs task processing (e.g. when a task fails we have to run pointlessly
  (?) through the loop in order to update the summary immediately for
  monitoring.

* check that all error messages go to stderr (print >> sys.stderr).

* allow cylc task proxies to kill their real external tasks at shutdown
  (and otherwise)?

* when there are multiple finished tasks that can satisfy a new task's
  restart prerequisites, the one that actually satisfies the new task
  will be an essentially random choice (the first one that comes along). 
  This is OK because the only thing that matters is that at least one
  task can satisfy the restart dependency, then the new task calls the
  prerequisite satisfied. However, we could get tasks to record the ID
  of the satisfier task as well, for each prerequisite, and also to
  choose the latest task as satisfier if more than one can do it.

* need a way to make the the custom clock (accelerated in dummy mode)
  available throughout the code, so we can easily use it anywhere
  (task.set_execution_timer is a kludge we could avoid, for instance).

* clean up the clock class with respect to dummy vs real time, and move
  it into task pool?

GUI

* dynamic reloading of the LED panel if the number of tasks in the
  running suite change (currently we have to start with *all* tasks
  including unused ones listed.

* don't parse suite.rc if the suite is already running?

* currently scans for port on every command - should store found port.

* access to task stdout and stderr for remote tasks? In fact, more
  generally, current we assume the viewer is running locally.

====================================
GRAPH STABILITY:

Small changes to graph content can cause large layout jumps - this is
probably inevitable. 

However, changes to the order of nodes and edges in the dot-file
for the *same* graph may also cause layout changes. I've traced 
this back to config.get_graph() for the cylc base graph and verified
that I'm sorting edges and nodes prior to adding them to the graph.
Thus the random(?) reordering seems to be a feature of the internals
of pygraphviz? (maybe it stores nodes in dicts in the underlying C
library...?)

CONSIDER ADDING LAYOUT ONCE to base graph, and thereafter only when new 
tasks are added to the graph? 

====================================
TEMPORARY FILES (as used mainly in the job submit classes):

tempfile.NamedTemporaryFile( delete=False ) creates a file and opens
it, but delete=False is post python 2.6 and we still currently run 2.4
on some platforms!  (auto-delete on close() will remove file before
the 'at' command runs it!)

tempfile.mktemp() is deprecated in favour of mkstemp() but the latter
was also introduced at python 2.6.
====================================
FUZZY PREREQUISITES

* allow mixed fuzzy and non-fuzzy prerequisites (currently have to 
  set identical fuzzy bounds to simulate the non-fuzzy case; see
  topnet.py).

* FUZZY MATCHING CURRENTLY ASSUMES AT MOST ONE COMPATIBLE OLDER FINISHED
  VERSION OF THE UPSTREAM TASK IS PRESENT, otherwise the match occurs
  with the first one found, whichever it is. This can fail if a suite
  problem puts a hold on spent task deletion! E.g.: topnet and oper
  interface go on ahead when topnet_vis has failed (unlikely to happen
  though!)

* just before a task runs, try to re-satisfy fuzzy prerequisites in case
  a more up-to-date satisfier has shown up while the task was waiting
  for other prerequisites to be satisfied ... OR (better?!) don't try to
  satisfy fuzzy prerequistes until after all non-fuzzy ones have been
  satsified. 
