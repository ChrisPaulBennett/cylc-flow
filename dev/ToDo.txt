_______
GENERAL

* DON'T LOAD CONFIG() FOR GREP AND EDIT - NO NEED - USE REGISTER INSTEAD.
  # also a clean inlined viewer for line numbers on config key error.

* suite.rc include-files: currently cannot be nested. But can be
  mulitply-included.

* consider calling task-started from task execution script instead of
  cylc-wrapper or task scripts: this would eliminate submitted state
  failures, and allow error trapping on tasks with significant
  in-suiterc scripting (and scripting-only tasks?)

* 'coldstart task list' should be replaced with a list auto-determined
  while parsing the dependency graph. [also, how's it interact with
  the old taskdef suite definition]

* document that a restart early in a coldstart will not be recognized as
  a coldstart.

* TO DO: NEW CONFIG: 
    - conditional dependencies

* currently all task reset commands go through the 'remote' object,
  which all suites have, but we could get a proxy for the task proxy directly,
  in which case we'd could catch Pyro.NamingError to detect if no such
  task exists in the suite.  Currently we get a sensible error if requesting
  to reset a non-existent task type, but not for a task ID of valid type but 
  which is not present at the requested cycle time.

* Pyro config:
  + PYRO_MAXCONNECTIONS , default 200: max number
  of simultaneous connections to a single pyro server?
  The default connection validator checks for this.
  + port range: set sufficiently wide for UKMO.
  (Consider cylclockd too)
  + consider Pyro multi-threading again?
  + use passphrase authentication in the default pyro connection validator
 (see the Pyro userguide security page).
  THESE SHOULD BE USER-SPECIFIC GLOBAL PREFERENCES?

* 'cylc view' read-only gui mode - e.g. for monitoring other's suites.

* '--host' should not be allowed for intervention commands because
  owner's username does not cross machine boundaries, generally.

* default dummy out (comment out command list) should use default
  CYLC_DUMMY_SLEEP for execution time (currently no sleep used).

* consider the need for different spawning behaviour of sequential (and
  tied?) tasks - why not just depend on prev%finished?

* document that oldstyle [taskdefs] and new style [tasks] + [dependency
  graph] can be used together in the one suite.rc file.

* document that continuation lines and include files are cylc-specific
  extensions to ConfigObj.

* documentation: 
  export PYTHONUNBUFFERED=true
  before running cylc via nohup, to prevent output buffering (results in 
  only stderr going to nohup.out until at the last moment when the suite
  is shut down).

* show suicide prerequisites, etc., in requisite dump.

* put roadmap into documentation.  additional item: expanding dependency
  graph based monitor view?

* housekeeping util needs parallel processing: see my new
  src/multisubprocess module, and use it to process multiple files at
  once within each housekeeping config line (which will be more
  effective than processing config lines in parallel). May have to 
  spawn shell commands to move and delete files as well as copy and diff,
  rather than use shutil.mv() ...

* generate new stdout and stderr log files when a task is reset.

* in new config, is restart OK after suite.rc tasks changed?

* TASK FAMILIES:
  + Ability to reset (or otherwise operate on) all members of a family.
  + Check effect of 'reset to waiting' on task families - need to reset
    the special finished prerequisites too?
  + Task family needs to be set 'failed' if all (or any?) members fail
  + use with --include and --exclude?
  + task owner should not be required with families

* check that the user-defined task names do not clash with parent class
  or attribute names.

* abstract out the common code in the cold,warm,raw start command line
  and source modules.

* implement automatic rolling dependency graph of last N (=24) hours.

* at some point, do some profiling of execution time and memory use:
    cProfile
    hotshot
    timeit
  are all part of the standard library. The first (and hostshot too?)
  generate stats files that can easily be manipulated and viewed
  with the pstats module.  See standard Python documentation, and
  this article:
    http://pparkkin.info/2010/02/21/profiling-python-hotshot-timeit-and-heapy
  For finding any memory leaks, see:
     heapy
  (not std lib, but explained in the above article).

* --port= does not prevent port scan for lockserver?
  check for non-essential port scanning, esp. in gui.
  (see GUI note below)

* document task inclusion and exclusion, at startup, by commandline or
suite.rc file: can be used separately or both at once, for cold, warm,
and restart.

* document how to re-run partial suite over existing data:
    - exclude some tasks
    - insert a new task to generate the outputs representing
      the existing data, and/OR
    - dummy out the tasks that generated the existing data.

* separate cold and warm start into distinct classes (currently warm is
  a variation on coldstart_scheduler, which is less than transparent).

* inserting an already existing task causes cylc to shut down with 
  'error: task X has already registered its outputs' - is this the
  desired behavior?

* can doing task deletion and insertion while a suite is PAUSED result
  in "INSERTING A TASK
      ERROR: A%2010081800 has already registered its outputs"
(DUPLICATE; see above)

* document reason for naming of pyro-connected objects
  (owner.suite.obj): prevent accidentally intervening in the wrong
  suite when using explicit port numbers (if we allow that). Also, 
  is this still required?

* temporary job submission filenames should contain the suite name
  so that automated cleanup processes can distinguish between suites.

* check use of re m.group() and m.groups(): 

    m.group(0)  # entire match
    m.group(1)  # first parenthesised sub-group
                # ...

    m.groups()  # tuple of parenthesised sub-groups


* task ID should not be needed in message strings (?); it can be supplied 
  automatically by access methods (for started, finished, etc.)

* cycle-dependent number of restarts: this can cause problems because
  only the most recent finished task is retained to satisfy
  prerequisites. If a task alternately does short and long forecasts
  with accordingly few and many restart outputs, we must retain *both*
  previously finished short and long versions of the task when currently
  only the short one would be retained. THE CYLC TASK ELIMINATION
  ALGORITHM MUST TAKE RESTART OUTPUTS INTO ACCOUNT: Do not eliminate a
  finished task if its restart outputs are still valid.
* DUPLICATE?: consider restart messages for split tasks that actually
  use the same restart files: e.g. nzlam_long (06,18Z) and nzlam_short
  (00,12Z).  Currently must combine this into one task with
  conditionals, OR register (and report) restart messages explicitly
  because the automatic restart messages will not have the right task
  name.

* some kind of internal queuing system as a more flexible alternative to
  the simple max runahead limit?

* commandline option parsing: defaults can be set to int or float, but 
  values read from commandline input are always strings and need to be
  converted.

* dummy mode restart: clock-rate is set by state dump file, so no point 
  in having rate as a commandline option unless it overrides. (and what
  about offset? should it be in the state dump too?).

* a new task type modifier that allows failed "non-critical" tasks to be
  ignored when applying the max runahead limit?

* dot-file graph output assumes that task families are internally
  cotemporal - is this necessarily the case?

* check all open( file, mode ) statements for mode 'rb' etc.  What is
  'b'? "binary"? if so, is this appropriate for cylc's usage.

* wherever I've used this:
    os.makedirs( os.path.dirname( filename ) )
  check that filename is not just a bare local dir filename like foo.bar
  as opposed to dir/foo.bar, else dirname() will return empty string and 
  makedirs() will fail.  This could happen if the user tries to use
  files in $PWD without specifying the full path.

* example system implementations should always use $USER in temp dir
  paths, to avoid interference between users.

* allow default loadleveler directives for ll_basic etc., to be
  specified in suite.rc?

* allow insertion of tasks in 'spawned already' state, for oneoff runs 
  of non-oneoff tasks?

* purge algorithm: see TO DO in the in-method comments: ensure that ALL
  tasks whose prerequisites get satisfied in the virtual system
  evolution that occurs in the purge algorithm, get unsatisfied again at
  the end of it.

* practice mode should be allowed even for exclusive suite locks. 

* stop (without --now) won't cause shutdown if a task family (but not
  it's members!) has just triggered.

* task state at initialization: there's no point in giving initial
  state of "finished" for example, if this does not result in setting
  prerequisites and outputs satisfied and completed, respectively.
  Consolidate this task state resetting code into methods in task.py?

* note that prerequisites are no longer derived from requisites. Change
  documentation in the latter class (and elsewhere?) to reflect this.

* if a job with a stop time has task failures and is then restarted the
  restart should know about the stop time (otherwise the restart has no
  stop time but tasks that previously reached the stop time will not
  respawn -although this can be rectified by task insertion).

* current method of setting task commands is not very robust: each new
  command in a retry list is set in jobsubmit.py "remotely" from task.py

* --fail=TASKID: check that TASKID exists in the target suite.

* In task scripts, document that failure inside RES=$( foo.sh ) does not
  trigger the err trap!

* check that the main uses for "oneoff cold start tasks" are documented.

* %COMMAND: allow single quotes in path or commandline?

* allow $(CYCLE_HOUR) etc. and arithmetic in task messages (so actual 
  filenames can be used). 

* document new use of 'TaskID failed' as an output: added on the fly as
  a new output if failure occurs, then removed from the output list on
  reset.

* use new cylc_mode class everywhere mode test is required.

* cylc submit --scheduler: task state resets to 'running' but all
  messages are ignored.

* extreme task elimination method - extrapolate forward in time to see
  if a finished task will ever be needed, otherwise delete?

* iteration over dictionary items: DO NOT USE
  = for item in dict:
  =    (operation that adds or removes items from dict)
  -> RuntimeError: dictionary changed size during iteration

  Instead use
  = for item in dict.keys():
  which must build a temporary list?

  CHECK USE OF DICTIONARY ITERATION THROUGHOUT THE CODE

* Record stopping time in state dump in case suite shutdown and
  restarted before all tasks reach the stop time is reached? (currently
  at restart those that did reach the stop time will be finished and
  unspawned, while those that didn't will carry on as if there was no
  stop time).

* src/which.py, like the shell command, searches only for executable
  files. The ll_raw job submit classes use which to find task scripts
  that don't have a full path supplied in the taskdef; these need
  to check that which returns a result before continuing (e.g. if 
  the task script has not been set executable). 

* daemon and asynchronous task: initial tests done; go back, check, and
  complete, for new versions of cylc.

* message command (command line usage only) lock and practice mode?

* consider reset --no-spawn (Bernard tried to reset a waiting unspawned
  task to finished, which made it spawn ... is this the desired
  behaviour?)

* check that practice mode suites initialise with the same clock time
  as the original suite!

* DOCUMENT or CHANGE: cotemporal peers of failed tasks are not deleted
  automatically because we USED TO restart with failed tasks in the 
  'waiting' state (not 'ready') - thus the aforementioned peers may be
  required to satisfy the failed task's prerequisites post resetting.

* Consider the effect of "# uncomment for earliest NON-FAILED" (x2) in
  manager.py - and test with dummy mode failout tasks.  For failed F in
  userguide example suite, it allows some intermediate finished cycles
  to be deleted, but this does not affect the delay due to max runahead.

* consider task proc loop invocation - could we separate summary update
  vs task processing (e.g. when a task fails we have to run pointlessly
  (?) through the loop in order to update the summary immediately for
  monitoring.

* document this: deleting a task may allow the suite to move on to the
  point that a reinserted task will not get its prerequisites satisfied
  automatically.

* consistent suite exit strategy: 
   -sys.exit(1), 
   -raise SystemExit(message)
   -custom exceptions

* all error messages should go to stderr: print >> sys.stderr, 'message'

* allow cylc task proxies to kill their real external tasks at shutdown
  (and otherwise)?

* make sure that no remote operation, other than 'stop', can bring a
  suite down (exception handling on all remote switches).

* when there are multiple finished tasks that can satisfy a new task's
  restart prerequisites, the one that actually satisfies the new task
  will be an essentially random choice (the first one that comes along). 
  This is OK because the only thing that matters is that at least one
  task can satisfy the restart dependency, then the new task calls the
  prerequisite satisfied. However, we could get tasks to record the ID
  of the satisfier task as well, for each prerequisite, and also to
  choose the latest task as satisfier if more than one can do it.

* when remote killing all waiting tasks at a ref time, check that (a)
  the suite has moved on passed that time, and (b) none of the waiting
  tasks are contact tasks whose time has not come up yet.

* we need a way to make the the custom clock (accelerated in dummy mode)
  available throughout the code, so we can easily use it anywhere
  (task.set_execution_timer is a kludge we could avoid, for instance).

* clean up the clock class with respect to dummy vs real time, and move
  it into task pool?

* do we need non-interpolation of single-quoted strings in taskdef
  environment, scripting, command? (implement in job_submit.py)?

* see To Do comment in broker.negotiate() - priority low.


__________
LOCKSERVER

* allow for a different lockserver host? (probably not). 

* document that when a suite releases its lock all of that suite's task
  locks are also released (e.g. when a suite is stopped --now with 
  tasks still running).

___
GUI

* don't parse suite.rc if the suite is already running?

* gui suite.rc editor

* currently scans for port on every command - should store found port.

* exception handling, input check, result detection, for the new control
  features.

* allow to put single tasks on hold / paused ?

* access to task stdout and stderr for remote tasks? In fact, more
  generally, current we assume the viewer is running locally.

* more information about tasks in the prerequisites-and-outputs popup:
  - HOURS
  - type (and spawning behaviour)

* VIEWING AND INTERACTING WITH REMOTE SUITES:
THIS IS PROBABLY NO LONGER RELEVANT SINCE DITCHING THE PYRO NAMESERVER
  'cylc view --host=foo'               .... works
  'cylc view -u USER --host=foo SUITE' .... fails
  The '-u USER' option does not work for cylc commands when '--host' is
  required (remote machine) because cylc preferences looks for USER's
  home directory locally => WHEN --host IS USED WE CANNOT LOAD PREFS (TO
  PRELOAD THE TASK LIST; HAVE TO GET IT DYNAMICALLY FROM THE RUNNING
  SUITE).  

====================================
FUZZY PREREQUISITES (only for infrequent 'advanced' usage - e.g. hourly
TopNet in EcoConnect)

* allow mixed fuzzy and non-fuzzy prerequisites (currently have to 
  set identical fuzzy bounds to simulate the non-fuzzy case; see
  topnet.py).

* FUZZY MATCHING CURRENTLY ASSUMES AT MOST ONE COMPATIBLE OLDER FINISHED
  VERSION OF THE UPSTREAM TASK IS PRESENT, otherwise the match occurs
  with the first one found, whichever it is. This can fail if a suite
  problem puts a hold on spent task deletion! E.g.: topnet and oper
  interface go on ahead when topnet_vis has failed (unlikely to happen
  though!)

* just before a task runs, try to re-satisfy fuzzy prerequisites in case
  a more up-to-date satisfier has shown up while the task was waiting
  for other prerequisites to be satisfied ... OR (better?!) don't try to
  satisfy fuzzy prerequistes until after all non-fuzzy ones have been
  satsified. 
