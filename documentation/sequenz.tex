%\documentclass[11pt,a4paper]{report}
\documentclass[11pt,a4paper]{article}

\usepackage{listings}
\usepackage{amsmath}

\lstset{language=Python}

\title{Asynchronous Dynamic Task Sequencing 
for Cycling Multi-Model Forecast Systems}

\author{Hilary Oliver, NIWA}

\begin{document}

\maketitle
\tableofcontents

\begin{abstract}

{\em Dynamic Task Sequencing} is a new and extremely flexible approach
to controlling the execution of a complex set of interdependent tasks.
Each task is represented by a self-contained {\em task object} that
knows nothing about other tasks in the system (such as who will generate
its inputs or who will use its outputs) but can interact with other
tasks to negotiate dependencies so that {\em correct sequencing emerges
naturally at run time}. The absence of explicit sequencing logic means
complete freedom to switch tasks on and off, or to add new ones to the
system, without any change to the sequencing algorithm. Our dynamic
sequencing implementation, {\em Sequenz}, is aimed at cycling
multi-model real time forecasting systems. It can run tasks from many
different forecast cycles simultaneously, where dependencies allow. In
addition, it can be completely tested on the configured task set without
running any real tasks, and partial parallel test systems that feed off
the main operational system can be quickly created on an ad hoc basis.
Sequenz is written in Python, and uses the Python Remote Object protocol
({\em Pyro}) for direct network communication between task objects and
the tasks they represent. Pyro also enables efficient RPC-based system
monitoring by external programs.  Sequenz can be interfaced to existing
models and tasks with minimal overhead.

\end{abstract}

\section{Task Sequencing}

NIWA's EcoConnect operation runs a set of regional environmental models
(weather, sea state, storm surge, river flow, tide) driven by global and
regional weather and sea state models, along with many associated pre-
and post-processing tasks for each model, product generation, archiving,
etc.  The EcoConnect forecasting engine runs on heterogenous distributed
hardware, and each model (and associated tasks) runs between 1 and 24
times per day, depending on the model. We define a {\em task} to be any
group of processes treated as a single entity for scheduling purposes
(and which would generally be controlled by a single top level script or
program). Controlling such a system is largely a matter of determining
when each task, which may depend on output from one or more other tasks,
is ready to execute.  This is not easy to do in a flexible and
extensible way because  such systems may have multiple parallel streams
of execution that branch (when one task generates output for several
downstream task) and merge (when one task takes input from several
upstream task), and the detailed properties of this ``sequence'' depend
entirely on the particular inputs and outputs of the configured task
set. The typical in-house solution to this problem is a highly specific
Finite State Machine that enforces a predetermined order of operations
using hard coded sequencing logic ({\em if A has generated file X, and B
has finished, then start executing C}, etc.) which quickly becomes
convoluted and inflexible as system complexity increases.  In addition,
forecasting control systems simplify their job by assuming that all
tasks from one cycle will complete before the next cycle begins, even
though any task is technically ready to run as soon as its own
prerequisites are satisfied\footnote{Most tasks depend only on their own
immediate predecessor (forecast models usually begin from a ``background
state'' generated by the previous forecast) and one more cotemporal
peers.} regardless of whether tasks from previous cycles are still
running or yet to start. This is reasonable in normal real time
operation where time is spent between cycles waiting on external input
(e.g. new observational data), but it is a significant impediment when
external input for multiple cycles is already available, such as when
catching up after system downtime in a resource constrained
computational environment, or when running the entire system over
historical case study periods.  Attempting to relax this constraint to
achieve ``asynchronous'' behaviour within the confines of a hard coded
finite state machine, however, dramatically exacerbates the
aforementioned coding problems.  


\section{Dynamic Task Sequencing}

Dynamic Sequencing is an object oriented approach to the task sequencing
problem.  Within the control program each task is represented by a
self-contained {\em task object} that needs to know only what it would
to run in isolation, namely its own prerequisites (usually input files)
and outputs, without reference to who will generate its inputs or who
will use its outputs. A task object can launch its own external task
when all of its prerequisites are satisfied (by submitting it to a batch
queue scheduler on the task's target machine), and must then keep its
internal state in sync with the external task via remote method calls.
Most importantly, a task object can interact with other task objects to
find out if they have satisfied any of its prerequisites yet.  The
controller gets each task to interact with every other task\footnote{It
doesn't matter that most of these interactions will be fruitless.}, each
time a new remote call comes in (which indicates someone's state has
changed).  Thus, regardless of the number of tasks in the system or the
complexity of their interdependencies, the the control program remains
simple and completely generic - just a set of standalone tasks that
don't know they are part of a wider system\footnote{Of course the system
manager has to ensure that the task pool is self consistent, in that
each task's prerequisites will be satisfied by some other task in the
system.}.  The total absence of explicit sequencing logic makes this
method extremely flexible: tasks can be switched on and off, and new
ones added, without changing the main program at all. 

Dynamic sequencing is essentially a simulation of a set of
interdependent tasks in which the state of each {\em simulee} is
strongly tied to that of the real task it represents.  This makes
possible a powerful ``dummy mode'' allowing complete testing of the
control system for a given task set, in accelerated time, without
actually running any of the real tasks: instead of launching the real
task we launch an external dummy program that masquerades as the real
task by reporting each of its prerequisites satisfied in turn. The
control program will not be able to distinguish this from real
operations.


\section{Sequenz}

Our dynamic sequencing implementation, {\em Sequenz} (described below),
features asynchronous sequencing (tasks from many different forecast
cycles can run at once where dependencies allow, as described above), it
transitions seamlessly from ``catchup mode'' (in which all initial input
is already available; e.g. after downtime) to real time operation, and
the powerful dummy mode, above.  Tasks can be turned on and off
trivially, and new ones added, without any change to the main program.
Sequenz controls NIWA's complex network of linked environmental
forecasting models and associated tasks (EcoConnect). 

{\em Sequenz} is a Python program that implements the dynamic sequencing
concept. It is used to run NIWA's EcoConnect operational environmental
forecasting system, which consists of global weather and sea state
models that drive regional weather, sea state, storm surge, tide, and
river flow models, and many associated pre- and post-processing tasks.
The tasks run on heterogenous distributed hardware, on an operational
schedule that repeats several times daily (between one and twenty four
times, depending on the task).  It automatically runs tasks from many
many different forecast cycles simultaneously, where dependencies allow,
for maximum throughput\footnote{This is useful when catching up to real
time after system delays, and for running the entire system over
historical periods for which all the initial input data is already
available.} ({\em multiflight} operation). Tasks can be switched on and
off trivially, and new ones can be added by simply defining their
prerequisites (without reference to who will satisfy them) and outputs
(without reference to who will use them). The system can be restarted in
arbitrarily complex states after maintenance, and sequencing of all
system tasks can be fully tested in an accelerated-time dummy mode
without actually running the real external tasks. 


\subsection{Applicability}

The dynamic sequencing concept is very general and could in principle be
implemented for any set of interdependent tasks. Sequenz, however, is
somewhat specialized toward systems, such as EcoConnect, that normally
need to keep cycling indefinitely. In particular, each task has an
associated {\em reference time}, representing the nominal start time of
its associated forecast run, and all prerequisites and outputs are
assumed to depend on it in some way.  One-off task pools with no
particular time dependence, however, are much simpler than this, and it
would not be difficult to strip all reference time handling from the
program.

In addition, EcoConnect operates in a well defined environment so that,
for example, each task knows exactly what its input files look like
(filenaming conventions) and where to get them from (e.g. {\em task X}'s
output directory). Consequently, for file-based prerequisites, the
controller does not need to know the file's actual location or check for
its existence, because the external tasks already do that. It could,
however, easily be made to pass file locations between tasks so that all
input/output filenames and paths could be defined centrally in the
control program itself.  


\subsection{Alternatives}

There are currently no other systems in existence that can handle
general {\em asynchronous} sequencing, as far as the author is aware.

In the planning stage, in addition to considering a Finite State Machine
controller, as discussed above, we also considered new generation batch
queue schedulers (which now allow simple job dependencies), and the use
of a generic control framework.  Batch queue schedulers were still far
too rudimentary for our purposes, however, and no generic control
framework that was obviously well suited came to light. In any case, in
the author's opinion, the dynamic sequencing design described in this
paper simplifies the problem to such an extent that it is unlikely any
generic framework could compete.  


\section{Implementation}

To implement dynamic sequencing we need a specific {\em task management}
scheme that controls when tasks will be created and destroyed, and so
on. There are almost too many options here; for instance: should tasks
be created all at once, in cotemporal batches, or one at a time as their
predecessors finish? The consequences of choices such as this have to
be evaluated carefully, which isn't easy because of the inherent
complexity of multiflight operation. At the simple end of the task
management spectrum, for example, we could create a whole month's worth
of tasks at once and just let them interact until everything runs to
completion. Nothing would run out of sequence, {\em but} system
monitoring would be difficult because of the sheer number of tasks
involved, the end of the month would present an artificial barrier to
multiflight operation, tasks that lack prerequisites would all want to
run at once, and system restarts would be overly complicated. 

\subsection{Main Algorithm}

The algorithm below operates on a single pool of interacting task
objects, has simple start up and continuous operation, and is relatively
easy to monitor (task objects exist by the time they are needed but not
for too long before that, and not for too long after they are finished). 

The simplicity of the dynamic sequencing algorithm is clear from the
following code listing, taken directly from the main program:

{\small
\noindent
\rule{5cm}{.2mm}
\begin{lstlisting}
# (startup initialization code omitted)

while True: # MAIN LOOP

   if task_base.state_changed:
       # PROCESS ALL TASKS whenever one has changed state
       # as a result of a remote task message coming in: 
       # interact, run, create new, and kill spent tasks
       #---
       task_pool.process_tasks()
       task_pool.dump_state()
       if task_pool.all_finished():
           clean_shutdown( "ALL TASKS FINISHED" )

    # REMOTE METHOD HANDLING; handleRequests() returns 
    # after one or more remote method invocations are 
    # processed (these are not just task messages, hence 
    # the use of task_base.state_changed above).
    #---
    task_base.state_changed = False
    pyro_daemon.handleRequests( timeout = None )

# END MAIN LOOP
\end{lstlisting}
}

\subsection{Details}

\subsubsection{Startup and Initialization}

An initial reference time and list of task object names are read in from
the config file, then each task object is created at the initial
reference time {\em or} at the first subsequent reference time that is
valid for the task type. Optionally, we can tell the controller to
reload the current state dump file (which may have been edited); this
will override the configured start time and task list. After startup,
new tasks are created only by {\em abdication} (below).

An initial run through the {\em task processing} code, by virtue of the
fact that the main loop starts with task processing, causes tasks with
no prerequisites (e.g. {\em downloader}) to enter the {\em running}
state and launch their external tasks immediately. Otherwise ({\em or}
if there are no tasks that lack prerequisites) nothing will happen.



\subsubsection{Creation of New Tasks}

New tasks are created by abdication, i.e. create $foo(T\negmedspace
+\negmedspace 1)$ if $foo(T)$ is {\em finished}.  Task abdication
ensures that $foo(T\negmedspace +\negmedspace 1)$ won't run before
$foo(T)$ finishes, without imposing explicit intercycle prerequisites
that would require special treatment at startup (when there is no
previous cycle).  It also ensures that tasks with no prerequisites, e.g.
{\em downloader} and {\em nztide}, won't all try to run at once.
Tasks are not deleted immediately on abdication (see below).


\subsubsection{Task Interaction} 

Each task keeps track of which of its postrequisites are completed, and
asks the other tasks if they can satisfy any of its prerequisites.  The
fact that task objects do not need to know who is supposed to satisfy
their prerequisites (because they can ask, indiscriminately, every other
task in the system) makes the task interaction (sequencing!) algorithm
almost trivial. The fact that most of these interactions are fruitless
is of no consequence. 

{\small
\noindent
\rule{5cm}{.2mm}
\begin{lstlisting}
class task_pool( Pyro.core.ObjBase ):
    # ...
    def interact( self ):
        # get each task to ask all the others if 
        # they can satisfy its prerequisites
        #--
        for task in self.tasks:
            task.get_satisfaction( self.tasks )
    # ...
\end{lstlisting}
}

\subsubsection{Running Tasks}

Each task object can launch its associated external task, and enter the
{\em running} state if its prerequisites are all satisfied, any existing
older tasks of the same type are already {\em finished}, and fewer than
{\em MAX\_ RUNAHEAD} finished tasks of the same type still exist (this
stops tasks with no prerequisites from running ahead indefinitely).

\subsubsection{Pyro Remote Method Calls}

The Pyro request handling loop executes remote method calls coming in
from external tasks, and returns after at least one call was handled.
Pyro must be run in non-default single-threaded mode (see Appendix
\ref{pyro-appendix}).

\subsubsection{Dumping State} 

The current state (waiting, running, or finished) of each task is
written out to the {\em state dump file}.  This provides a running
snapshot of the system as it runs, and just prior to shutdown or
failure. The controller can optionally start up by loading the state
dump (which can be edited first). Any 'running' tasks are reloaded in
the 'waiting' state.

\subsubsection{Removing Spent Tasks} 

A task is spent if it finished {\em and} no longer needed to satisfy the
prequisites of any other task. Most tasks are only needed by other
cotemporal downstream tasks; these can be removed when they are finished
{\em and} older than the oldest non-finished task. For rare cases that
are needed by tasks in later reference times (e.g. nzlam post
processing: multiple hourly topnet tasks need the same most recent
previously finished 06 or 18Z nzlam post processing task), each
non-finished task reports its {\em cutoff reference time} which is the
oldest reference time that may contain tasks still needed to satisfy its
own prerequisites (if it is waiting) or those of its immediate
post-abdication successor (if it is running already), then the task
manager can then kill any finished tasks that are also older than the
oldest task cutoff time.

\subsubsection{Removing Lame Tasks} 

Tasks that will never run (because their prerequisites cannot be
satisfied by any other task in the system) are removed from the {\em
oldest batch} of tasks.  If not removed they would prevent the spent
task deletion algorithm from working properly. Lame tasks can only be
detected in the oldest task batch; in younger batches some tasks may yet
appear as their predecessors abdicate.

Lame tasks are abdicated rather than just deleted, because their
descendents will not necessarily be lame: e.g. if the system is started
at 12Z with topnet turned on, all topnet tasks from 12Z through 17Z will
be valid but lame, because they will want to take input from a
non-existent nzlam\_post from 06Z prior to startup. However, the
presence of lame tasks may indicate user error: e.g. if you forget
to turn on task type $foo$ that supplies input to task type $bar$,
any instance of $bar$ will be lame.


\section{Dummy Mode}

Dummy mode allows complete testing of the control system without running
any real external tasks\footnote{The only difference between dummy mode
and real operation, as far as the controller is concerned, is that
external dummy tasks are not delayed by resource contention.}. When it
is ready to run, a task object will launch an external dummy program
that (i) gets a list of postrequisites from the parent task object and
then (ii) reports back that each one is satisfied at the (estimated)
right time relative to an accelerated dummy clock. Dummy tasks therefore
complete in approximately the same dummy clock time as the real tasks do
in real time. An initial dummy clock offset relative to the initial
reference time can also be specified, which allows simulation of the
transition between catchup and real time operation. Log messages are
stamped with dummy clock time instead of real time.

The same script is used for all external dummy tasks but it has special
behaviour in certain cases: the dummy downloader ``waits for incoming
files'' until 3:15 past its reference time, and the dummy topnet ``waits
for streamflow data'' until 0:15 past its reference time.

The dummy clock can be bumped forward a number of hours by remote
control, while the system is running. This affects the postrequisite
timing of running tasks correctly, but if it causes a running task to
finish immediately the next task in line will still start from the
beginning no matter how big the bump.


\section{Program Usage}

All user-configurable parameters are set in \verb#config.py#. There is
one commandline option to force a restart from the state dump file
(which may have been edited) instead of the configured start time and
task list:

\lstset{language=sh}

{\small

\noindent
\rule{5cm}{.2mm}
\begin{lstlisting}
ecocontroller [-r]
Options:
    + most inputs should be configured in config.py
    + [-r] restart from the state dump file
\end{lstlisting}
}

\lstset{language=Python}

\subsection{Config File}

{\small
\noindent
\rule{5cm}{.2mm}
\lstinputlisting{../config.py}
}

\appendix

\section{Essential OOP Concepts}

The simplicity of the dynamic sequencing implementation in {\em sequenz}
is critically dependent on the {\em polymorphic} nature of the {\em task
objects} in the program.  This section contains a minimal introduction
to these Object Oriented Programming concepts.  Refer to any OOP
reference for more detail.

\subsection{Classes and Objects}

A {\em class} is essentially a generalisation {\em data type}, to
include {\em behaviour} (i.e. functions or {\em methods}) as well as
state.  {\em Objects} are more or less self contained {\em instances} of
a class. For example, a $shape$ class could define a $position$ data
member that describes the location of each shape object, a $move()$
method that causes a shape object to alter its position, and a $draw()$
method that causes it to display itself in the right place on screen.

\subsection{Inheritance}

A {\em derived class} or {\em subclass} inherits the properties (methods
and data members) of a {\em base class}. It can also {\em override}
specific base class properties, or add new properties that aren't
present in the base class. Calling a particular method on an object
invokes the object's own class method if one is defined, otherwise the
immediate base class is searched, and so on down to the root of the
inheritance graph. 

For example, we could derive a $circle$ class from $shape$, adding a
`radius' data member and overriding the $draw()$ to get circle objects
to display themselves as actual circles.  Because we didn't override the
$move()$ method, calling $circle.move()$ would invoke the base class
method, $shape.move()$. 


\subsection{Polymorphism}

Polymorphism is the ability of one type to appear as and be used like
another type.  In OOP languages with inheritance, this usually refers to
the ability to treat derived/sub-class objects as if they were members
of a base class.  In particular, a group of mixed-type objects can all
be treated as members of a common base class. For example, we could
construct a list of $shape$ objects from $circles$, $triangles$, and
$squares$; calling $[list member].draw()$ will invoke the right derived
class $draw()$. This is a very powerful mechanism because {\em it allows
unmodified old code to call new code}: if we later derive an entirely
new kind of shape ($hexagon$, say) with it's own unique behaviour, the
existing program, without modification, will process the new objects in
the proper hexagon-specific way.


\section{Threading in Pyro} \label{pyro-appendix}

With Pyro in {\em single threaded mode}, \verb#handleRequests()# returns
after {\em either} a timeout has occurred {\em or} at least one request
(i.e.  remote method call) was handled. With \verb#timeout = None# this
allows us to process tasks {\em only} after remote method invocations
come in.  Further, we can detect the remote calls that actually change
task states, and thereby drop into the task processing code only when
necessary, which minimizes non-useful output from the task processing
loop (e.g. in dummy mode there are a lot of remote calls on the dummy
clock object, which does not alter tasks at all). 

In {\em multithreaded mode}, \verb#handleRequests()# returns immediately
after creating a new request handling thread for a single remote object
and thereafter remote method calls on that object come in asynchronously
in the dedicated thread. This is not good for the dynamic sequencing
algorithm because tasks are only set running in the task processing
block which can be delayed while \verb#handleRequests()# blocks waiting
for a new connection to be established even as messages that warrent
task processing are coming in on existing connections. The only way
around this is to do task processing on \verb#handleRequests()# timeouts
which results in a lot of unnecessary task processing when nothing
important is happening.


\section{YET TO BE DOCUMENTED}

\begin{itemize}
 \item usage
 \item logging
 \item debugging
 \item adding new task definitions
 \item system monitors
 \item remote control: 
    \begin{itemize}
    \item clean shutdown of pyro
    \item bumping the dummy clock forward
    \end{itemize}
 \item external task messaging interface script
 \item dummying out tasks in real mode
 \item how to set up partial parallel test systems
\end{itemize}

\section{Miscellaneous Notes}

(To be incorporated into the main documentation, or deleted).

\subsection{catchup mode}

Note that ``correct model sequencing'' is not equivalent to ``orderly
generation of products by reference time''.  Nzlam can run continuously,
regardless of the downstream processing that depends on it.

Catchup mode is now task-dependent, rather than a property of the whole
system (as it is if only tasks from the same reference time can run at
once).  Where this matters, it can be detected by the relevant external
task. E.g. if the external topnet(T) task starts up at real time t
greater than the streamflow data time for T (i.e. $T+15$ min), i.e. the
required streamflow data is already available, then we're still in
catchup. If, on the other hand, the topnet task finds that it has to
wait for its streamflow data time to arrive, then we're caught up to
real time.  This matters because topnet is allowed to run ahead by a
different amount of time depending on whether we're in catchup mode or
not.


\subsection{controlling when a task executes}

\begin{itemize}
 \item  prerequisites
 \item artificial prerequisites (e.g. make nztide depend on nzlam)
 \item delayed instantiation (a task can't run if it doesn't exist yet).
 \item other contraints based on, for example, the number of previous
 instances that still exist in the system.
\end{itemize}


\subsection{fuzzy prequisites}

{\em Exact prerequisites} (most tasks): times are specified exactly,
relative to the task's own reference time.  E.g. {\em file foo\_{T}.nc
ready} where T is the task's reference time.

{\em Fuzzy prerequisites} (topnet): a time boundary is specified
relative to the task's own reference time; any task with a reference
time greater than or equal to the boundary time can satisify the
prerequisite.

\subsection{Task Messaging}

To the task objects, outputs are just {\em messages} indicating that the
external task has reached a significant waypoint, such as generation of
a particular output file.

\section{To Do}

\begin{itemize}

\item
 retrofit proper exception handling throughout (currently used sparsely and 
  inconsistently)

\item
 potential bug in the free task class: will never run if too many
 previous instances exist that are newer than the task deletion cutoff

\item
 remote logging from messaging and dummy task scripts, in case the
 controller itself is dead.

\end{itemize}

\end{document}
