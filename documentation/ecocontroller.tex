\documentclass[12pt]{amsart}

\title{Multiflight Dynamic Sequencing Controller Documentation}

\author{Hilary Oliver, NIWA}

\begin{document}
\maketitle

\section{EcoConnect Task Sequencing} 

From a control system perspective, the EcoConnect forecasting engine is
comprised of many distinct tasks\footnote{A {\em task} is a set of
processes that we want separate scheduling control over, as a group.}
that have to execute in an order that is largely determined by
availability of input files, many of which are generated by other tasks
within the system.  The ordering is not a simple linear sequence,
however; rather, there are multiple parallel streams of execution that
can branch (when one task supplies input to several others) and merge
(when one task takes input from several others). The controller design
needs to be flexible (so that tasks can be turned on and off easily) and
extensible (so that new tasks can be added to the system easily) and it
must allow tasks from different forecast cycles to run at the same time,
where dependencies allow, for maximum throughput after system delays
({\em multiflight} operation). 


\subsection{The Trouble with Explicit Sequencing Logic}

The obvious thing to try first (which indeed we did) is a Finite State
Machine that enforces the correct predetermined, hardwired, task
sequence: 

\begin{verbatim}
IF [file X is ready] AND [task B(T) is finished]
   THEN [run task C(T)] 
(etc.)
\end{verbatim} 

For a relatively simple single-flight system, this is easily understood
and it works well, but as system complexity increases the program
inevitably becomes convoluted and inflexible, and it is hard to see how
to generalise it to multiflight operation without ending up in a real
mess (note that we can't just fire off a sequence of overlapping
independent single-flight controllers because of intercycle
dependencies\footnote{The simplest of these is that $foo(T+1)$ usually
depends on $foo(T)$ because most forecast models start from a
``background state'' that is generated by the previous forecast.}). 


\section{Dynamic Sequencing}

This method was inspired by basic object oriented game programming
techniques. Tasks are represented by objects (in the {\em Object
Oriented Programming} sense) that are only aware of their own state
information but are able to interact to dynamically to satisfy each
other's dependencies.  Thus, rather than enforcing a prescribed task
sequence from the outset, correct sequencing just emerges naturally at
run time. The total lack of explicit sequencing logic makes this
approach extremely flexible: new tasks can be added to the system, or
existing tasks switched on and off, without modifying the main control
program at all.


\subsection{Task Dependencies}

Tasks have {\em prerequisites} that must be satisfied before they can
run, e.g. ``file foo is ready'' [to use], and {\em postrequisites} that
are satisfied as they run, e.g. ``file bar is ready'' [to be used by
others]. This is just the minimal external interface information needed
to run a task in isolation (i.e. what inputs are required, and what
outputs are generated) {\em but} because one task's output is another's
input, it entirely determines the global task sequence too. Explicit
sequencing logic is not needed because sequencing information is already
present, implicitly, in the matching-up of task pre- and
post-requisites. 

\subsection{Task Objects}

Within the controller, tasks are represented by {\em task objects} that
know their own pre- and post-requisites and can interact with other
tasks to get their prerequisites satisfied, can launch their external
tasks when all prerequisites are satisfied, and whose internal states
are kept in sync with the external tasks they represent by way of a
Pyro-based\footnote{The Python Remote Object protocol allows direct
network communication between external tasks and their parent task
objects in the controller} messaging system. 

Note that task objects do not need to know {\em who} will satisfy their
prerequisites because they can ask all other tasks indiscriminately.
This makes the task interaction code almost trivial and it is immaterial
that most of the interactions will be fruitless. 

Note also that postrequisite messages are just {\em messages}. If the
controller receives a ``file ready'' message, for example, it trusts the
message source and does not bother to check for the actual file's
existence. To do otherwise would be redundant because the external tasks
necessarily have to verify the existence of input files anyway, and they
can report back in case of error.


\section{Implementation}

To implement the dynamic sequencing concept we need to decide when tasks
will be created and destroyed, and how live tasks will be handled within
the program.  There are almost too many choices here, and the advantages
and disadvantages of potential task management schemes have to be
evaluated carefully (which often isn't easy because of the inherent
complexity of multiflight operation). In principle we could, for
example, create a whole month's worth of tasks at once and let them
interact until everything runs to completion.  That seems refreshingly
simple, and nothing would run out of sequence, {\em but} system
monitoring would be difficult because of the sheer number of tasks
involved, the end of the month presents an artificial barrier to
multiflight operation, any tasks that lack prerequisites would all want
to run at once, and restarting the system after a problem could be very
difficult. 

The algorithm actually implemented in the controller, below, allows
simple start up and continuous operation, and is relatively easy to
monitor (task objects exist by the time they are needed but not for too
long before that, and not for too long after they are spent) and the
main program is completely task-agnostic: it operates on a single pool
of tasks that each care only about their own inputs and outputs and
know nothing about the other tasks.  

\subsection{Summary}

\begin{itemize}
    \item startup (create initial tasks)
    \item repeat ad infinitum:
    \begin{itemize}
        \item Pyro request handling (process remote method calls, which
        include task messages)
        \item task processing (whenever a new task message comes in:
        tasks.interact(), tasks.run\_if\_ready(), create new tasks, kill
        spent tasks, etc.)
    \end{itemize}
\end{itemize}


\subsection{Details}

\subsubsection{Startup}

The user supplies an initial reference time and list of task names.
Create named task objects at the initial reference time {\em or} at the
first subsequent reference time that is valid for the task type.
Subsequently, new tasks are created only by {\em abdication} (below).
    \begin{itemize}
        \item tasks are uniquely identified by type and reference time. 
        \item new task objects are created in a {\em waiting} state, by
        default.
        \item we can also start from a previous {\em state dump} file
        (see below).
    \end{itemize}


An initial run through the {\em task processing block} (see below)
causes any tasks with no prerequisites (e.g. {\em downloader}) to enter the
{\em running} state and launch their external tasks immediately.
    \begin{itemize}
    \item if there are no prerequisiteless tasks, nothing will happen.
    \end{itemize}

\subsubsection{Pyro request handling}

The program now enters the {\em Pyro request loop}, which:

    \begin{itemize}
    \item handles remote method calls coming in from external tasks, 
    \item returns after at least one remote method call is handled. 
    \end{itemize}

\subsubsection{task processing block} 

The following processing is done whenever the Pyro request loop returns
and one or more tasks have changed state: 

    \begin{itemize} 
    \item \verb#regeneration#: create new tasks by abdication, i.e.
    create $foo(T+1)$ when $foo(T)$ achieves a {\em finished} state.
    \begin{itemize}
    \item this ensures that $foo(T+1)$ won't run before $foo(T)$
    finishes, without imposing explicit intercycle prerequisites
    that would require special treatment at startup (when there is no
    previous cycle). 
    \item it also ensures that tasks with no prerequisites, e.g.
    {\em downloader} and {\em nztide}, won't all try to run at once.
    \item tasks are not deleted immediately on abdication (see below). 
    \end{itemize}


    \item \verb#interaction#: satisfy each others' prerequisites. 

    \item \verb#run if ready#: launch your external task and enter the
    {\em running} state if:
        \begin{itemize}
        \item your prerequisites are all satisfied
        \item any existing older tasks of your type are {\em finished} 
        \item fewer than {\em MAX\_ RUNAHEAD} finished tasks of your
        type still exist (this stops tasks with no prerequisites from
        running ahead indefinitely).
        \end{itemize}

    \item \verb#dump state#: the current state (waiting, running, or
    finished) of all tasks is written out to the {\em state dump file}.
        \begin{itemize}
        \item this provides a snapshot of the system just prior to shutdown.

        \item the controller can be initialised from the state dump file
            \begin{itemize}
            \item the state dump file can be edited before reloading

            \item any 'running' tasks are reloaded in the 'waiting' state.
            \end{itemize}
        \end{itemize}

    \item \verb#kill spent tasks#: a task is spent if it (a) finished,
    and (b) no longer needed to satisfy the prequisites of any other
    task.
       \begin{itemize}

       \item each non-finished task reports its {\em cutoff reference
       time}, i.e. the oldest reference time that is still needed for to
       satisfy its own prerequisites or those of its immediate successor
       after abdication.  In most cases this is just the task's own
       reference time. For hourly {\em topnet} it is the reference time
       of the previous finished 06 or 18Z {\em nzlam\_post} task (the
       next topnet task may need the same nzlam\_post).  

       \item the task manager then kills any batch of cotemporal tasks
       that are all finished {\em and} older than the oldest task cutoff
       time.

       \end{itemize}

    \item \verb#kill lame ducks#: remove tasks that will never run
    because their prerequisites cannot be satisfied by any other task in
    the system.  

       \begin{itemize}
       \item these need to be removed or they'll prevent the spent
       task deletion algorithm from working.
       
       \item they can only be detected in the {\em oldest} batch
       of cotemporal tasks. At other times more tasks may appear later
       on as their predecessors abdicate.

       \item the presence of lame ducks may indicate user error: e.g.
       forgetting to include task type $foo$ that supplies input to
       task type $bar$ will turn any instance of $bar$ into a lame
       duck.

       \item lame ducks are to be expected sometimes at start up. E.g.
       if the system is started at 12Z with topnet turned on, all topnet
       tasks from 12Z through 17Z will be valid but lame (because
       they will want to take input from a non-existent nzlam\_post
       from 06Z prior to startup).

       \item lame ducks are abdicated rather than just deleted, because
       their descendents might not be lame (see topnet case above). 
       \end{itemize}
   \end{itemize}

\appendix

\section{Dummy Mode}

Dummy mode allows complete testing of the control system without running
any of the real external tasks\footnote{The only difference between
dummy mode and real operation, as far as the controller is concerned, is
that external dummy tasks are not delayed by resource contention}.  When
it is ready to run, a task object will launch an external dummy program
that (i) gets a list of postrequisites from the parent task object and
then (ii) reports back that each one is satisfied in turn.  Messages are
sent back at the (estimated) right time relative to the controller's
accelerated clock so that dummy tasks complete in approximately the same
dummy clock time as the real tasks do in real time. An initial dummy
clock offset relative to the initial reference time can also be
specified, which also allows simulation of catchup operation and the
transition to real time mode.  Log messages are stamped with dummy clock
time instead of real time.

The same script is used for all external dummy tasks but it has special
behaviour in certain cases: the dummy downloader ``waits for incoming
files'' until 3:15 past its reference time, and the dummy topnet ``waits
for streamflow data'' until 0:15 past its reference time.

The dummy clock can be bumped forward a number of hours by remote
control, while the system is running. This affects the postrequisite
timing of running tasks correctly, but if it causes a running task to
finish immediately the next task in line will still start from the
beginning no matter how big the bump.


\section{Threading in Pyro}

In SINGLE THREADED PYRO, handleRequests() returns after EITHER a timeout has
occurred OR at least one request (remote method call) was handled.  With
``timeout = None'' this allows us to process tasks ONLY after remote method
invocations come in. Further, the processing\_required boolean set in
task\_base.incoming() allows us to process tasks ONLY when a task changes state
as a result of an incoming message, which minimizes non-useful output from the
task processing loop (e.g. in dummy mode there are a lot of remote calls on
the dummy clock object, which does not alter tasks at all). 

In MULTITHREADED PYRO, handleRequests() returns immediately after creating a
new request handling thread for a single remote object and thereafter remote
method calls on that object come in asynchronously in the dedicated thread.
It is impossible(?) to make our main loop work properly like this because
handleRequests will block until a new connection is made, even while messages
from existing remote objects are coming in.  Tasks that are ready to run are
only set running in the processing loop, so these will be delayed
unnecessarily until handleRequests returns.  The only way out of this is to do
task processing on a handleRequests timeout as well, which results in a lot of
unnecessary task processing.
 

\section{YET TO BE DOCUMENTED}

\begin{itemize}
 \item usage
 \item logging
 \item debugging
 \item how to add new tasks
 \item simple system monitors
 \item remote control: 
    \begin{itemize}
    \item clean shutdown of pyro
    \item bumping the dummy clock forward
    \end{itemize}
 \item external task messaging interface script
 \item config file, and optional initialisation from state dump
 \item dummying out specific tasks in real mode
\end{itemize}


\section{Miscellaneous Notes}

(To be incorporated into the main documentation, or deleted).

\subsection{catchup mode}

Note that ``correct model sequencing'' is not equivalent to ``orderly
generation of products by reference time'', in catchup operation.  E.g.
nzlam can run continuously regardless of the downstream processing that
depends on it.

Catchup vs up-to-date operation is now task-dependent, rather than a
property of the whole system (as it is if only tasks from the same
reference time can run at once).  Where this matters, it can be detected
by the relevant external task. E.g. if the external topnet(T) task
starts up at real time t greater than the streamflow data time for T
(i.e. T+15 min), i.e. the required streamflow data is already available,
then we're still in catchup. If, on the other hand, the topnet task
finds that it has to wait for its streamflow data time to arrive, then
we're caught up to real time.  This matters because topnet is allowed to
run ahead by a different amount of time depending on whether we're in
catchup mode or not.


\subsection{controlling when a task executes}

\begin{itemize}
 \item  prerequisites
 \item artificial prerequisites (e.g. make nztide depend on nzlam)
 \item delayed instantiation (a task can't run if it doesn't exist yet).
 \item other contraints based on, for example, the number of previous instances
       that still exist in the system.
\end{itemize}


\subsection{requisites}

{\em EXACT PREREQUISITES} (most tasks): times are specified exactly,
relative to the task's own reference time.  E.g. ``file foo\_{T}.nc
ready'' where T is the task's reference time.

{\em FUZZY PREREQUISITES} (topnet): a time boundary, Tb, is specified
relative to the task's own reference time, and any task with a reference
time greater than or equal to Tb can satisify the prerequisite.


\section{Object Oriented Programming}

This section contains a minimal introduction to the main OOP concepts
that are needed to understand how the controller works.  Please refer to
an OOP textbook for more information.

\subsection{classes and objects}

A {\em class definition} defines the properties of {\em objects} or {\em
instances} of that class. An object is a more or less self contained
entity, that can be assigned to a variable, with specific {\em state}
(data) and class dependent {\em behaviour} (functions or ``methods''
that operate on the data and are the means by which objects interacts
with the outside world).    

For example, a $shape$ class might define a $position$ data member that
describes the location of each shape object, and a $draw()$ method that
causes a shape object to draw itself in the right location on screen.

\subsection{inheritance}

A {\em subclass} is a class that inherits the properties (methods and
data members) of its {\em parent class}, but can also {\em override}
specific parent class properties, or add new properties that aren't
present in the parent class. Calling a method $f()$ on an object invokes
the object's own class method $f()$ if one is defined, or otherwise
falls back to its parent class's $f()$, and so on down to the {\em
base class's} $f()$ at the root of the inheritance tree. 

For example, $circle$ and $square$ classes could be derived from the
$shape$ class; these would define additional variables to describe their
particular kind of shape, such as a $radius$ for circles, and would
override $shape.draw()$ so that a circle object would draw itself as a
proper circle, and so on.


\subsection{polymorphism}

This refers to the ability to treat a group of objects of different
classes as if they were all members of a common parent class.

For example, consider a list of $shape$ objects that actually contains a
mix of $circles$, $triangles$, and $squares$, all derived from the
$shape$ base class.  Calling $draw()$ on each list member in turn would
result in each object drawing itself in its own unique position and
colour using the $draw()$ method appropriate to its own subclass (so
that $circle$ objects would look like circles, etc.). This is very
powerful because {\em it allows unmodified old code to call new code}:
two years after writing this program we could derive an entirely new
kind of shape ($hexagon$, say) with it's own unique behaviour, and add
it to the list of shapes; the old shape handling code, without
modification, would magically do the right thing when it encountered 
the new shape objects.

\subsection{... in the controller}

The controller makes extensive use of inheritance and polymorphism, and
in particular it handles task objects polymorphically. All tasks are
treated as if they were instances of the base class that defines common
task behaviour, which is an enormous simplification, but they respond in
derived-class-specific ways when necessary: calling $task.run()$ on an
nztide task object results in the real tide model running, and so on. 


\end{document}
