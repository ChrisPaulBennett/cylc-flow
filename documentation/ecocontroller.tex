\documentclass[12pt]{article}

\title{Multiflight Dynamic Sequencing Controller Documentation}

\author{Hilary Oliver, NIWA}

\begin{document}
\maketitle

\section{EcoConnect Task Sequencing} 

The EcoConnect forecasting engine consists of many tasks\footnote{A {\em
task} is a set of processes that we want separate scheduling control
over, as a group.} that have to execute in the right order. Ordering is
determined by availability of input files, many of which are generated
by other tasks within the system.  In general this results in a
non-linear task ``sequence'' consisting of multiple parallel streams of
execution that can branch (when one task supplies input to several
others) and merge (when one task takes input from several others). The
control system to automate this needs to be flexible (tasks can be
turned on and off easily) and extensible (new tasks can be added to the
system easily) and it must allow tasks from multiple forecast cycles to
run at once, where dependencies allow, for maximum throughput after
system delays ({\em multiflight} operation). 


\subsection{The Trouble with Explicit Sequencing Logic}

The obvious thing to try first (which we did) is a Finite State Machine
that enforces the correct task sequence, which is predetermined and hard
wired: 
\begin{verbatim}
IF [task A(T) has completed file X] AND [task B(T) is finished]
   THEN [run task C(T)] 
(etc.)
\end{verbatim} 

This is easy to understand and it works well for a relatively simple
single-flight system, but as system complexity increases the program
inevitably becomes convoluted and inflexible, and it is hard to see how
to generalise it to multiflight operation without ending up in a real
mess (note that we can't just fire off a sequence of overlapping
independent single-flight controllers because of intercycle
dependencies\footnote{The simplest of these is that $foo(T+1)$ usually
depends on $foo(T)$ because most forecast models start from a
``background state'' that is generated by the previous forecast.}). 


\section{Dynamic Sequencing}

This method was inspired by basic object oriented game programming
techniques. Rather than enforcing a prescribed task sequence from the
outset, let tasks be represented by independent objects that are only
aware of their own state information but are able to interact to
dynamically satisfy each other's dependencies so that correct sequencing
just emerges naturally at run time. The total lack of explicit
sequencing logic makes this approach extremely flexible: new tasks can
be added to the system, or existing tasks turned off, without modifying
the main control program at all.


\subsection{Task Dependencies}

Tasks have {\em prerequisites} that must be satisfied before they can
run, e.g. ``file foo is ready'' [to use], and {\em postrequisites} that
are satisfied as they run, e.g. ``file bar is ready'' [to be used by
others]. This is in fact just the minimum external interface information
needed to run a task, even in isolation, {\em but} it actually entirely
determines the global task sequence too (because one task's output is
another's input, etc.).  In other words, explicit sequencing logic
should not be needed because task sequencing information is already
present, implicitly, in the matching-up of task pre- and
post-requisites. 

\subsection{Task Objects}

Within the controller, tasks are represented by {\em task objects} that,
\begin{itemize}
\item know their own pre- and post-requisites
\item can interact with other tasks to satisfy dependencies
\item can launch their external tasks when all their prerequisites are
satisfied 
\item can keep in sync with external task progress (e.g. notification of
completed postrequisites) through a messaging system. 
\end{itemize}

Messaging is achieved via Pyro, the Python Remote Object protocol, which
allows direct communication between external tasks and their parent task
objects in the controller. 

Note that task objects do not need to know {\em who} will satisfy their
prerequisites because they can ask all other tasks indiscriminately.
This makes the task interaction code almost trivial and it is immaterial
that most of the interactions will be fruitless. 

Note also that postrequisite messages are just {\em messages}. If the
controller receives a ``file ready'' message, for example, it trusts the
message source and does not bother to check for the actual file's
existence. To do otherwise would be redundant because the external tasks
necessarily have to verify the existence of input files anyway, and they
can report back in case of error.


\subsection{The Algorithm}

There are any number of ``task management'' schemes that could be
employed to achieve dynamic sequencing. For example, we could create a
month's worth of tasks at once, then just let them interact until
everything has run to completion.  That's refreshingly simple, and
nothing would run out of sequence, but there are some negative
consequences: for instance, system monitoring would be difficult, the
end of the month presents an artificial barrier to multiflight
operation, and all tasks that have no prerequisites, for the whole
month, would want to run immediately.

The algorithm below is still reasonably simple but it is continuous, and
easier to monitor: task objects exist by the time they are needed but
not for too long before that, and not for too long after they are spent.
Note that the algorithm is completely generic in that it knows nothing
of relationships between the tasks it manages; it simply operates on a
single pool of tasks, each of which cares only about its own inputs and
outputs.  

\begin{itemize}
    \item At startup, the user supplies an initial reference time and
    list of task names. Task objects are created for each named task at
    the initial reference time, {\em or} at the first subsequent
    reference time that is valid for the particular task type.
    \begin{itemize}
        \item tasks are uniquely identified by type and reference time. 
        \item new task objects are created in a {\em waiting} state, by
        default.
        \item we can also start from a previous {\em state dump} file
        (see below).
    \end{itemize}

\item After startup, new tasks are created only by {\em abdication}:
$foo(T+1)$ is created only when $foo(T)$ achieves a {\em finished} state.
    \begin{itemize}
    \item this ensures that $foo(T+1)$ won't run before $foo(T)$
    finishes, without imposing explicit intercycle prerequisites
    that would require special treatment at startup (when there is no
    previous cycle). 
    \item it also ensures that tasks with no prerequisites, e.g.
    downloader and nztide, won't all try to run at once.
    \item tasks are not deleted immediately on abdication (see below). 
    \end{itemize}

\item An initial run through the {\em task processing block} (see below)
causes any tasks with no prerequisites (e.g. 'downloader') to enter the
'running' state and launch their external tasks immediately.
    \begin{itemize}
    \item if there are no tasks that lack prequisites, nothing starts running.
    \end{itemize}

\item The program now enters the {\em Pyro request loop}, which:

    \begin{itemize}
    \item handles remote method calls coming in from external tasks, 
    \item returns after at least one remote method call is handled. 
    \end{itemize}

\item The {\em task processing block} executes whenever the Pyro request
loop returns and one or more tasks have changed state: 

    \begin{itemize} 
    \item \verb#regeneration#: create new tasks by abdication.

    \item \verb#interaction#: satisfy each others' prerequisites. 

    \item \verb#run if ready#: launch your external task and enter the
    {\em running} state if:
        \begin{itemize}
        \item your prerequisites are all satisfied
        \item any existing older tasks of your type are {\em finished} 
        \item fewer than {\em MAX\_ RUNAHEAD} finished tasks of your
        type still exist (this stops tasks with no prerequisites from
        running ahead indefinitely).
        \end{itemize}

    \item \verb#dump state#: the current state (waiting, running, or
    finished) of all tasks is written out to the {\em state dump file}.
        \begin{itemize}
        \item this provides a snapshot of the system just prior to shutdown.

        \item the controller can be initialised from the state dump file
            \begin{itemize}
            \item the state dump file can be edited before reloading

            \item any 'running' tasks are reloaded in the 'waiting' state.
            \end{itemize}
        \end{itemize}

    \item \verb#kill spent tasks#: a task is spent if it (a) finished,
    and (b) no longer needed to satisfy the prequisites of any other
    task.
       \begin{itemize}

       \item each non-finished task reports its {\em cutoff reference
       time}, i.e. the oldest reference time that it thinks is still
       needed for satisfying its own, or its successors, prerequisites.
       In most cases this is just the tasks own reference time. For
       hourly topnet, it is the reference time of the previous finished
       06 or 18Z 'nzlam\_post' task (the next hourly topnet may get
       input from the same nzlam\_post).  

       \item the task manager then kills any batch of cotemporal tasks
       that are all finished {\em and} older than the oldest task cutoff
       time.

       \end{itemize}

    \item \verb#kill lame ducks#: these are tasks that will never run
    because their prerequisites can not be satisfied by any other task
    in the system.  

       \begin{itemize}
       \item lame ducks need to be removed or they'll prevent the spent
       task deletion algorithm from working.
       
       \item lame ducks can only be detected in the {\em oldest} batch
       of cotemporal tasks. At other times new tasks, which may satisfy
       someone's prequisites, may appear later on as their predecessors
       abdicate.

       \item the presence of lame ducks may indicate user error: e.g.
       forgetting to include task type $foo$ that supplies input to
       task type $bar$ will turn any instance of $bar$ into a lame
       duck.

       \item lame ducks are to be expected in certain start up
       situations. E.g. if we start the system at 12Z with topnet turned
       on, all hourly topnet objects from 12Z through 17Z are valid, but
       they will want to take input from the non-existent nzlam\_post
       from 06Z prior to startup.

       \item lame ducks are abdicated rather than just deleted, because
       on of their descendents may not be lame (see topnet case above). 
       \end{itemize}
   \end{itemize}
\end{itemize}


\appendix

\section{Dummy Mode}

Dummy mode allows complete testing of the control system without running
any external tasks: the only difference from real operation, as far as
the controller is concerned, is that external dummy tasks are not
delayed by resource contention. 


In dummy mode, task objects launch an external dummy program instead of
real external tasks. The dummy programs get a list of postrequisites
from their parent task object (via Pyro) and report back that each one
is satisfied in turn, at the right time relative to an accelerated
clock, so they complete in approximately the same dummy clock time as
the real tasks do in real time. An initial dummy clock offset relative
to the initial reference time can also be specified, which also allows
simulation of catchup operation and the transition to real time mode.
Log messages are stamped with dummy clock time instead of real time.

The same script is used for all external dummy tasks but it has special
behaviour when representing some tasks (downloader and topnet) in order
to correctly simulate their behaviour (the downloader ``waits for incoming
files'' until the clock time is at least 3:15 past its reference time, and
topnet ``waits until the clock time 0:15 min past the task reference
time'' (i.e. the stream flow data extraction cutoff).

The dummy clock can be bumped forward by a number of hours by remote
control, while the system is running. This affects the postrequisite
timing of running tasks correctly, but if it causes a running task to
finish immediately the next task in line will still start from the
beginning no matter how big the bump.


\section{Threading in Pyro}

In SINGLE THREADED PYRO, handleRequests() returns after EITHER a timeout has
occurred OR at least one request (remote method call) was handled.  With
``timeout = None'' this allows us to process tasks ONLY after remote method
invocations come in. Further, the processing\_required boolean set in
task\_base.incoming() allows us to process tasks ONLY when a task changes state
as a result of an incoming message, which minimizes non-useful output from the
task processing loop (e.g. in dummy mode there are a lot of remote calls on
the dummy clock object, which does not alter tasks at all). 

In MULTITHREADED PYRO, handleRequests() returns immediately after creating a
new request handling thread for a single remote object and thereafter remote
method calls on that object come in asynchronously in the dedicated thread.
It is impossible(?) to make our main loop work properly like this because
handleRequests will block until a new connection is made, even while messages
from existing remote objects are coming in.  Tasks that are ready to run are
only set running in the processing loop, so these will be delayed
unnecessarily until handleRequests returns.  The only way out of this is to do
task processing on a handleRequests timeout as well, which results in a lot of
unnecessary task processing.
 

\section{YET TO BE DOCUMENTED}

\begin{itemize}
 \item usage
 \item how to extend with new tasks
 \item simple system monitors
 \item remote control: 
    \begin{itemize}
    \item clean shutdown of pyro
    \item bumping the dummy clock forward
    \end{itemize}
 \item external task messaging interface script
 \item config file, and optional initialisation from state dump
 \item dummying out specific tasks in real mode
\end{itemize}


\section{Miscellaneous Notes}

(To be incorporated into the main documentation, or deleted).

\subsection{catchup mode}

Note that ``correct model sequencing'' is not equivalent to ``orderly
generation of products by reference time'', in catchup operation.  E.g.
nzlam can run continuously regardless of the downstream processing that
depends on it.

Catchup vs up-to-date operation is now task-dependent, rather than a
property of the whole system (as it is if only tasks from the same
reference time can run at once).  Where this matters, it can be detected
by the relevant external task. E.g. if the external topnet(T) task
starts up at real time t greater than the streamflow data time for T
(i.e. T+15 min), i.e. the required streamflow data is already available,
then we're still in catchup. If, on the other hand, the topnet task
finds that it has to wait for its streamflow data time to arrive, then
we're caught up to real time.  This matters because topnet is allowed to
run ahead by a different amount of time depending on whether we're in
catchup mode or not.


\subsection{controlling when a task executes}

\begin{itemize}
 \item  prerequisites
 \item artificial prerequisites (e.g. make nztide depend on nzlam)
 \item delayed instantiation (a task can't run if it doesn't exist yet).
 \item other contraints based on, for example, the number of previous instances
       that still exist in the system.
\end{itemize}


\subsection{requisites}

{\em EXACT PREREQUISITES} (most tasks): times are specified exactly,
relative to the task's own reference time.  E.g. ``file foo\_{T}.nc
ready'' where T is the task's reference time.

{\em FUZZY PREREQUISITES} (topnet): a time boundary, Tb, is specified
relative to the task's own reference time, and any task with a reference
time greater than or equal to Tb can satisify the prerequisite.


\subsection{Object Oriented Programming}

It is beyond the scope of this document to teach object oriented
programming, but it might be useful to give a quick once-over-lightly
explanation of the main OOP concepts that the controller depends on.

\subsubsection{classes and objects}


From a {\em class definition} one can {\em instantiate} {\em objects} or
{\em instances} (of the class); these are entities with specific {\em
state} (data) and class dependent {\em behaviour} (functions or
``methods'' that operate on the data and are the means by which objects
interacts with the outside world).    

For example, a $shape$ class might define a $position$ data member that
describes the location of each shape object, and a $draw()$ method that
causes a shape object to draw itself in the right location on screen.

\subsubsection{inheritance}

A {\em subclass} is a class that inherits the properties (methods and
data members) of its {\em parent class}, but can also {\em override}
specific parent class properties, or add new properties that aren't
present in the parent class. Calling a method $f()$ on an object invokes
the object's own class method $f()$ if one is defined, or otherwise
falls back to its parent class's $f()$, and so on down to the {\em
base class's} $f()$ at the root of the inheritance tree. 

For example, $circle$ and $square$ classes could be derived from the
$shape$ class; these would define additional variables to describe their
particular kind of shape, such as a $radius$ for circles, and would
override $shape.draw()$ so that a circle object would draw itself as a
proper circle, and so on.


\subsubsection{polymorphism}

This is the ability to treat a set of objects as if they were
all members of a common parent class.

For example, consider a list of $shape$ objects that actually contains a
mix of $circles$, $triangles$, and $squares$, all derived from the
$shape$ base class.  Calling $draw()$ on each list member in turn would
result in each object drawing itself in its own unique position and
colour using the $draw()$ method appropriate to its own subclass (so
that $circle$ objects would look like circles, etc.). This is very
powerful because {\em it allows unmodified old code to call new code}:
two years after writing this program we could derive an entirely new
kind of shape ($hexagon$, say) with it's own unique behaviour, and add
it to the list of shapes; the old shape handling code, without
modification, would magically do the right thing when it encountered any
of the new shape objects.

\subsubsection{... in the controller}

The controller makes extensive use of inheritance and polymorphism, and
in particular it handles task objects polymorphically. All tasks are
treated as if they were instances of the base class that defines common
task behaviour, which is an enormous simplification, but they respond in
derived-class-specific ways when necessary: calling $task.run()$ on an
nztide task object results in the real tide model running, and so on. 


\end{document}
