
=============== ECOCONNECT CONTROLLER WITH IMPLICIT SEQUENCING =============


Model Sequencing ----------

The EcoConnect forecasting engine consists of a set of tasks that must
be executed in correct order as determined, mainly, by availability of
input files that are generated by other tasks (a "task" is any set of
processes that, as a group, we want separate scheduling control over;
this includes, but is not restricted to, "a science model plus its
post-processing"). In general a task may take input from more than one
upstream task, and may generate output for more than one downstream
task; this results in a non-linear task "sequence" that consists of
parallel streams of execution that sometimes branch and merge.


Explicit Sequencing ----------

This is probably the obvious method to try first: determine the final
task sequence in advance, taking into all task interdependencies into
account, and write code to explicitly enforce the sequence. This is
relatively easy to understand, but the resulting program will inevitably
(?) be fragile and inflexible with respect to insertion and deletion of
models, mid-stream startup, maintenance and extensibility, etc. 

Implicit Sequencing ----------

Concept

Rather than enforcing correct sequencing from the outset, let individual
tasks interact dynamically in such a way that correct sequencing emerges
naturally at run time.

Each task has its own set of prerequisites that have to be satisfied
before it can run (e.g. "input file foo is ready") and "postrequisites"
that are satisfied as it runs (e.g. "output file bar is ready"). This is
essentially the minimum information that a task needs even to run in
isolation, BUT it actually entirely determines the global task sequence
too (because one task's prerequisites must be satisfied by another's
completed postrequisites, obviously). So, in principle no extra
"sequencing logic" is needed, we just need to get the tasks to interact
at run time so that unsatisfied prerequisites can be matched with
completed postrequisites. 

Implementation

Tasks are represented within the controller by TASK OBJECTS that know
only their own requisites, can interact with each other to satisfy
prerequisites, can launch their external tasks as soon as their
prerequisites are all satisfied, and whose internal states are kept in
sync with their external tasks (e.g. notification of completed
postrequisites) by a messaging system.  The Python Remote Object
protocol (Pyro) allows direct communication between external tasks and
their representative task objects. Note that task objects do not know in
advance *who* will satisfy their prerequisites; they can inquire of all
the other tasks.   

Note that pre and postrequisites are just *messages*, e.g. an external
task has started or finished, or a particular file is ready for use.  In
the case of "file ready" messages, the controller does not need to know
the actual location of the file.  It could easily be made to, but
there's no point because the external tasks have to know anyway (at
least within EcoConnect) and they can report back any "file not found"
errors.


Task Management Notes ----------

Correct sequencing will occur so long as tasks always exist by the time
they are needed (which encompasses the fact that codependent tasks must
coexist). They shouldn't exist for too long before they are needed,
however, or for too long after they are no longer needed, because that
complicates system monitoring unnecessarily.

We can control when a task executes through:
 (i) prerequisites
 (ii) artificial prerequisites (e.g. make nztide depend on nzlam)
 (iii) delayed instantiation (a task can't run if it doesn't exist yet).


Initial Task: 

This task (the "downloader") is special in that it provides the initial input
to get the whole system started. It has no prerequisites and therefore starts
running as soon as it is created (so long as all previous instances have
finished; see below). Without this task nothing will run at all. The external
downloader (interface to watch_ftp.sh) should watch for the right incoming
files and report back ready when the download has completed OR if the files
already exist because they were downloaded previously.

INTER-CYCLE DEPENDENCIES:

Having each task foo(T) depend explicitly on its previous instance foo(T-1)
finishing prevents successive instances of the same task from running
simultaneously or out of order (where their other prerequisites would allow
this; e.g. downloader or nztide) but it complicates system startup (when there
are no previous tasks) and means finished tasks have to stay around
longer (so that foo(T-1) can tell foo(T) it is finished). 

Instead, we let a task run if no previous instance exists OR any previous
instance that still exists is finished.  This prevents running out of order
but system startup is no longer a special case, and tasks can (usually;
see below) die as soon as all of their same-cycle peers are finished.

TASK CREATION by ABDICATION:

Create a new foo(T+1) only after foo(T) is finished. This is convenient,
and it prevents prerequisiteless tasks from launching immediately, all
at once. 

TASK DELETION:

Normal tasks can only run once all previous instances are finished, so there
is no explicit dependence on previous cycles and we can delete any completely
finished batch(T) that is older than the oldest running task.

HOWEVER, topnet can run ahead of nzlampost so long as the "most recently
generated topnet input file" is < 24 hours old (real time) or < 12 hours old
(catchup).  Nzlampost only generates topnet files at 06 and 18, so: if there
is no running nzlampost, topnet will depend on the most recent FINISHED 06 or
18 nzlampost, and we can delete any finished batches older than that. 

=> cutoff at the older of:
   (i) most-recent-finished-nzlampost
   (ii) oldest running.

TO DO: we could improve this by removing non-nzlampost tasks older than
oldest_running (BUT: make sure this doesn't break the lame duck test).


CONSTRAINED RUNAHEAD TASKS

Any tasks that have no prerequisites can start running, by default, as soon as
they come into existence.  However, they will execute consecutively, not all
at once, because of our abdication-based task management: foo(T+1) depends on
foo(T) IF foo(T) exists.  

To prevent indefinite runahead when can either impose artificial prerequisites
(e.g. tie nztide(T) to nzlam(T)), OR refuse to create a new task foo unless
there are fewer than, say, five previous foo instances still in existence. The
latter option has the advantage that the task remains independent in case we
want to run it when the putative dependee is turned off.

DOWNLOADER tasks must have no prerequisites otherwise nothing will happen,
but we restrict the number of concurrent instances.

NZTIDE tasks have no prerequisites, but we restrict the number of concurrent
instances.


TASKS WITH FUZZY PREQUISITES

TOPNET now runs hourly and can run ahead of the nzlam by up to 23 hours
(uptodate) or 11 hours (catchup).  This is achieved through FUZZY
PREREQUISITES: "file tn_TIME.nc ready" can be satisfied by an otherwise
matching postrequisite whose TIME is under 24 hours different from the
topnet task's prerequisite.  11 hours => topnet always depends on the
most recent long nzlam forecast.

Whether we are in catchup or uptodate modes is detected by the external
topnet task: if topnet(T) launches BEFORE streamflow data time (T+15 min)
then we're still catchup up.  As soon as the first topnet task is
launched at or after streamflow data time, it signals to the controller
that we've caught up. Thereafter, topnet can keep up with the (hourly)
clock time so long as nzlam doesn't slip behind more than 24 hours.


LAME DUCKS:

A "lame duck" is a task that will never run because it's prerequisites can
never be satisfied.  These need to be removed or they will prevent removal of
spent tasks.  We can detect lame ducks by requisite checking amongst all
tasks in the oldest batch(T) that contains any running tasks.  Newer batches
may not be complete yet (they may acquire new tasks as those in the oldest
batch abdicate).  Lame ducks are abdicated rather than just deleted, so
that their descendents can run if they are not lame ducks. As an example of
this, if we start the system at 12Z all topnet tasks prior to 18Z will be dead
soldiers because the 12Z nzlam does not generate topnet input files. 


CLEAN SHUTDOWN

Run the script 'shutdown.py' to tell the controller to shutdown cleanly
at the next opportunity.


STATE DUMP

The controller records its current state, i.e. the state of all
tasks that currently exist, to a file. 

Currently we can't restart from the state file.


DUMMY MODE

In dummy mode an external dummy program (see task_dummy.py) is launched by
each task instead of the real external model/task.  The external dummy program
then tells its in-controller task object that it has satisfied each
postrequisite in turn, at the right time relative to the controller's dummy
clock (below).  

An accelerated clock (which runs at 60 seconds per dummy hour, by default) is
used for dummy task timing and replaces the real time in all log messages.
The user can specify a time offset, relative to the start reference time, at
which to start the dummy time clock. Dummy programs complete in the same time
(relative to the dummy clock rate) as the real models, so long as accurate
time estimates have been defined for the postrequisites. 

If the task definitions (i.e. requisites and their respective time estimates)
are accurate, this enables complete testing of the control system, including
catchup and uptodate running and the transition between, except to the extent
that real external task timing is modified by resource contention.

Note that dummy downloader and topnet tasks are treated differently to
simulate the behaviour of the corresponding real tasks: the downloader "waits"
for incoming files until the clock time is at least 3:15 past its reference
time, and topnet "waits" until the clock time :15 min past its reference time,
which is the stream flow data extraction cutoff.

[note that timed postrequisites apply after a task starts running, so bumping
the dummy clock forward affects a running task correctly, but it doesn't make
tasks that are still waiting start halfway through, etc...]


SINGLE THREADED PYRO REQUIRED

"""In SINGLE THREADED PYRO, handleRequests() returns after EITHER a
timeout has occurred OR at least one request (remote method call)
was handled.  With "timeout = None" this allows us to process tasks
ONLY after remote method invocations come in. Further, the
processing_required boolean set in task_base.incoming() allows us to
process tasks ONLY when a task changes state as a result of an
incoming message, which minimizes non-useful output from the task
processing loop (e.g. in dummy mode there are a lot of remote calls
on the dummy clock object, which does not alter tasks at all). 

In MULTITHREADED PYRO, handleRequests() returns immediately after
creating a new request handling thread for a single remote object
and thereafter remote method calls on that object come in
asynchronously in the dedicated thread.  It is impossible(?) to make
our main loop work properly like this because handleRequests will
block until a new connection is made, even while messages from
existing remote objects are coming in.  Tasks that are ready to run
are only set running in the processing loop, so these will be
delayed unnecessarily until handleRequests returns.  The only way
out of this is to do task processing on a handleRequests timeout
as well, which results in a lot of unnecessary task processing."""
 
 
 Note that during CATCHUP "correct model sequencing" is not equivalent to
"orderly generation of products by reference time".  E.g. nzlam can run
continuously, regardless of the downstream processing that depends on it.

task interaction probably doesn't scale well with large task numbers

we can't start up on a single reference time: not all tasks are
valid at all times, and any task not present at the start will never be
created. So, at start time each configured task is created at the
initial start time OR at the first subsequent reference time for which
it is valid.  

