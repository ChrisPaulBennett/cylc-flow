%\documentclass[11pt,a4paper]{report}
\documentclass[11pt,a4paper]{article}
%\documentclass[11pt,a4paper]{amsart}

% 1 inch margins
\usepackage{fullpage}
\usepackage{framed}
\usepackage{listings}
  \usepackage{courier}
\usepackage{amsmath}
\usepackage{verbatim}
%\usepackage{graphicx}             % latex, eps
\usepackage[pdftex]{graphicx}    % pdflatex, png, jpg, pdf
%\usepackage[dvips,usenames,dvipsnames]{color}   % dvips here screws up graphicx png version, above
\usepackage[usenames]{color}   % dvips here screws up graphicx png version, above
\usepackage{hyperref}
%\usepackage{titletoc}

\usepackage{tocloft}
% prevent double digit sub-sections crowding the toc line
\addtolength\cftsubsecnumwidth{0.5em}  % see tocloft manual

\definecolor{codeblock}{rgb}{0.9,0.9,0.9}
%\definecolor{keywords}{rgb}{1.0,0.3,0.0}
\definecolor{keywords}{rgb}{1.0,0.1,1.0}
%\definecolor{comments}{rgb}{0.0,0.7,0.8}
\definecolor{comments}{rgb}{1.0,0.0,0.0}
\definecolor{identifiers}{rgb}{0.0,0.2,0.8}
\definecolor{strings}{rgb}{0.0,0.6,0.0}
\definecolor{basic}{rgb}{0.0,0.2,0.8}

% hyperlink color:
%\definecolor{linkc}{rgb}{0,0.2,0.68}
% colored hyperlink instead of boxed
%\hypersetup{colorlinks=true, linkcolor=linkc}
\hypersetup{colorlinks=true, linkcolor=red}

\definecolor{shadecolor}{rgb}{0.9,0.9,0.1}

\lstset{
language=,
%xleftmargin=2em,
%frame=single,
backgroundcolor=\color{codeblock},
basicstyle=\color{basic}\footnotesize\ttfamily,
identifierstyle=\color{identifiers},
keywordstyle=\color{keywords},
commentstyle=\color{comments},
stringstyle=\color{strings},
showstringspaces=false,
%numbers=left,
%numberstyle=\color{Gray}
}

\lstset{
language=bash,
numbers=left,
}

\lstdefinelanguage{cylctaskdef}
{
morekeywords={INHERIT,TASK,FAMILY,DESCRIPTION,SCRIPTING,TYPE,LOGFILES,CONTACT_DELAY,OWNER,REMOTE_HOST,HOURS,COMMAND,MEMBERS,MEMBER_OF,ENVIRONMENT,DIRECTIVES,PREREQUISITES,COLDSTART_PREREQUISITES,SUICIDE_PREREQUISITES,OUTPUTS,N_RESTART_OUTPUTS,INTERCYCLE,FOLLOW_ON,conditional},
sensitive=false,
morecomment=[l]{\#},
morestring=[b]\",
numbers=left,
}

\lstdefinelanguage{usage}
{
string=[b]{"},
sensitive=false,
morecomment=[l]{Usage:},
morecomment=[l]{USAGE:},
morecomment=[l]{usage:},
morecomment=[l]{HELP:},
morecomment=[l]{CATEGORY:},
morecomment=[l]{COMMANDs:},
morecomment=[l]{Arguments:},
morecomment=[l]{Options:},
morecomment=[l]{arguments:},
morecomment=[l]{command-options:},
morecomment=[l]{COMMANDS:},
morecomment=[l]{options:},
%morecomment=[l]{\#},
numbers=none,
}

% allow \paragraph as subsubsubsection
% and \subparagraph as subsubsubsubsection
\setcounter{secnumdepth}{5}
\setcounter{tocdepth}{5}

% the follow makes \paragraph{} be followed 
% by a newline, as for section headings.
\makeatletter
\renewcommand\paragraph{%
   \@startsection{paragraph}{4}{0mm}%
      {-\baselineskip}%
      {.5\baselineskip}%
      {\normalfont\normalsize\bfseries}}
\makeatother
% and similarly for \subparagraph{} 
\makeatletter
\renewcommand\subparagraph{%
   \@startsection{subparagraph}{4}{0mm}%
      {-\baselineskip}%
      {.5\baselineskip}%
      {\normalfont\normalsize\bfseries}}
\makeatother


\title{Cylc \linebreak 
An Optimal Adaptive Metascheduler \linebreak 
For Complex Forecasting Suites \linebreak 
{\em \small Version THIS IS NOT A VERSIONED RELEASE} \linebreak
%{\small Copyright NIWA, 2008-2011} }
Copyright NIWA, 2008-2011}

\author{Hilary Oliver}


% define a more compact itemized list environment
\newenvironment{myitemize} {
\begin{itemize}
    \setlength{\itemsep}{1pt}
    \setlength{\parskip}{0pt}
    \setlength{\parsep}{0pt}
    \setlength{\topsep}{0pt}
    }{\end{itemize}}

% define a more compact enumerate list environment
\newenvironment{myenumerate} {
\begin{enumerate}
    \setlength{\itemsep}{1pt}
    \setlength{\parskip}{0pt}
    \setlength{\parsep}{0pt}
    \setlength{\topsep}{0pt}
    }{\end{enumerate}}


\begin{document}

\maketitle

\pagebreak

\input{abstract.tex}

\pagebreak
\tableofcontents
\listoffigures
%\listoftables

\pagebreak
\section{Introduction: How Cylc Works} 
\label{HowCylcWorks}

\subsection{Scheduling Forecast Suites} 
\label{SchedulingForecastSuites}

Environmental forecasting suites generate forecast products from a
potentially large group of interdependent scientific models and
associated data processing tasks. They are constrained by availability
of external driving data: typically one or more tasks will wait on real
time observations and/or model data from an external system, and these
will drive other downstream tasks, and so on. The dependency diagram for
a single forecast cycle in such a system is a {\em Directed Acyclic
Graph} as shown in Figure~\ref{fig-dep-one} (in our terminology, a {\em
forecast cycle} is comprised of all tasks with a common {\em cycle
time}, which is the nominal analysis time or start time of the forecast
models in the group). In real time operation processing will consist of
a series of distinct forecast cycles that are each initiated, after a
gap, by arrival of the new cycle's external driving data.

From a job scheduling perspective task execution order in such a system
must be carefully controlled in order to avoid dependency violations.
Ideally, each task should be queued for execution at the instant its
last prerequisite is satisfied; this is the best that can be done even
if queued tasks are not able to execute immediately because of resource
contention.

\subsection{EcoConnect} 
\label{EcoConnect}

Cylc was developed for the EcoConnect Forecasting System at NIWA
(National Institute of Water and Atmospheric Research, New Zealand).
EcoConnect takes real time atmospheric and stream flow observations, and
operational global weather forecasts from the Met Office (UK), and uses
these to drive global sea state and regional data assimilating weather
models, which in turn drive regional sea state, storm surge, and
catchment river models, plus tide prediction, and a large number of
associated data collection, quality control, preprocessing,
postprocessing, product generation, and archiving tasks.\footnote{Future
plans for EcoConnect include additional deterministic regional weather
forecasts and a statistical ensemble.} The global sea state forecast
runs once daily. The regional weather forecast runs four times daily but
it supplies surface winds and pressure to several downstream models that
run only twice daily, and precipitation accumulations to catchment river
models that run on an hourly cycle assimilating real time stream flow
observations and using the most recent available regional weather
forecast.  EcoConnect runs on heterogenous distributed hardware,
including a massively parallel supercomputer and several Linux servers. 


\subsection{Dependencies Between Tasks}

\subsubsection{Intracycle Dependencies} 
\label{IntracycleDependencies}

Most inter-task dependencies exist within a single forecast cycle.
Figure~\ref{fig-dep-one} shows the dependency diagram for a single
forecast cycle of a simple example suite of three forecast models ({\em
a, b,} and {\em c}) and three post processing or product generation
tasks ({\em d, e} and {\em f}). A scheduler capable of handling this
must manage, within a single forecast cycle, multiple parallel streams
of execution that branch when one task generates output for several
downstream tasks, and merge when one task takes input from several
upstream tasks. 

\begin{figure}
    \begin{center}
        \includegraphics[width=6cm]{inkscape-svg/dep-one-cycle.pdf} 
    \end{center}
    \caption[Single cycle dependency graph for a simple suite]{\small
    The dependency graph for a single forecast cycle of a simple example
    suite. Tasks {\em a, b,} and {\em c} represent forecast models,
    {\em d, e} and {\em f} are post processing or product generation
    tasks, and {\em x} represents external data that the upstream
    forecast model depends on.}
    \label{fig-dep-one} 
\end{figure} 

\begin{figure}
    \begin{center}
        \includegraphics[width=8cm]{inkscape-svg/timeline-one.pdf}
    \end{center}
    \caption[Single cycle job schedules for real time operation]{\small
    The optimal job schedule for two consecutive cycles of our example
    suite during real time operation, assuming that all tasks trigger 
    off upstream tasks finishing completely. The horizontal extent of
    a task bar represents its execution time, and the vertical blue
    lines show when the external driving data becomes available.}
    \label{fig-time-one}
\end{figure}

Figure~\ref{fig-time-one} shows the optimal job schedule for two
consecutive cycles of the example suite in real time operation, given
execution times represented by the horizontal extent of the task bars.
There is a time gap between cycles as the suite waits on new external
driving data.  Each task in the example suite happens to trigger off
upstream tasks {\em finishing}, rather than off any intermediate output
or event; this is merely a simplification that makes for clearer
diagrams.

\begin{figure}
    \begin{center}
        \includegraphics[width=10cm]{inkscape-svg/dep-two-cycles-linked.pdf} 
    \end{center}
    \caption[What if the external data is available early?]{\small If
    the external driving data is available in advance, can we start
    running the next cycle early?} 
    \label{fig-dep-two-linked}
\end{figure}

\begin{figure}
    \begin{center}
        \includegraphics[width=6cm]{inkscape-svg/timeline-one-c.pdf} 
    \end{center}
    \caption[Attempted overlap of consective single-cycle job
    schedules]{\small A naive attempt to overlap two consecutive cycles
    using the single-cycle dependency graph. The red shaded tasks will
    fail because of dependency violations (or will not be able to run
    because of upstream dependency violations).} 
    \label{fig-overlap}
\end{figure} 

\begin{figure}
    \begin{center}
        \includegraphics[width=8cm]{inkscape-svg/timeline-one-a.pdf} 
    \end{center}
    \caption[The only safe multicycle job schedule?]{\small The best that
    can be done {\em in general} when intercycle dependencies are
    ignored.} 
    \label{fig-job-no-overlap}
\end{figure} 

Now the question arises, what happens if the external driving data for
upcoming cycles is available in advance, as it would be after a
significant delay in operations, or when running a historical case
study?  While the forecast model {\em a} appears to depend only on the
external data {\em x} at this stage of the discussion, in fact it would 
typically also depend on its own previous instance for the model {\em
background state} used in initializing the new forecast. Thus, as
alluded to in Figure~\ref{fig-dep-two-linked}, task {\em a} could in
principle start
as soon as its predecessor has finished.  Figure~\ref{fig-overlap}
shows, however, that starting a whole new cycle at this point is
dangerous - it results in dependency violations in half of the tasks in
the example suite. In fact the situation is even worse than this
- imagine that task {\em b} in the first cycle is delayed for any reason
{\em after} the second cycle has been launched? Clearly we must consider
handling intercycle dependencies explicitly or else agree not to start
the next cycle early, as is illustrated in Figure~\ref{fig-job-no-overlap}.

\subsubsection{Intercycle Dependencies} 
\label{IntercycleDependencies}

In most suites dependencies between tasks in different cycles
exist. Forecast models, as above, typically depend on their own most
recent previous forecast for a background state, and different
types of tasks in different forecast cycles can also be linked (in an 
atmospheric forecast analysis suite, for instance, the weather model 
may also generate background states for use by the observation
processing and data-assimilation systems in the next cycle). In real
time operation these intercycle dependencies
can be ignored because they are automatically satisfied when each cycle
finishes before the next one begins. This is just as well
because they dramatically increase the complexity of the dependency
graph of even the simplest suites, by destroying the clean boundary
between forecast cycles. Figure~\ref{fig-dep-multi} illustrates the
problem for our simple example suite assuming the minimal likely
intercycle dependence: the forecast models ($a$, $b$, and $c$) each
depend on their own previous instances.

For this reason, and because we tend to imagine that forecasting suites
always run in distinct cycles, existing metaschedulers (as far as the author
is aware!) ignore intercycle dependencies and therefore {\em require} a
series of distinct cycles at all times. While this does not affect
normal real time operation it can be a serious impediment when advance
availability of external driving data makes it possible, in principle,
to run some tasks from upcoming cycles before the current cycle is
finished - as suggested at the end of the previous section. This occurs
after delays (late arrival of external data, system maintenance, etc.)
and, to an even greater extent, in historical case studies, and parallel
test suites that are delayed with respect to the main operation. It is
a serious problem, in particular, for suites that have little downtime
between forecast cycles and therefore take many cycles to catch up
after a delay. Without taking account of intercycle dependencies, the
best that can be done, in general, is to reduce the gap between cycles
to zero as shown in Figure~\ref{fig-job-no-overlap}. A limited crude
overlap of the single cycle job schedule may be possible for specific
task sets but the allowable overlap may change if new tasks are added,
and it is still dangerous: it amounts to running different parts of a
dependent system as if they were not dependent and as such it cannot be
guaranteed that some unforeseen delay in one cycle, after the 
next cycle has begun, (e.g.\ due to resource contention or task
failures) won't result in dependency violations.

\begin{figure}
    \begin{center}
        \includegraphics[width=8cm]{inkscape-svg/dep-multi-cycle.pdf} 
    \end{center}
    \caption[Complete multicycle dependency graph]{\small The complete
    dependency graph for the example suite, assuming the least possible
    intercycle dependence: the forecast models ($a$, $b$, and $c$)
    depend on their own previous instances. The dashed arrows show
    connections to previous and subsequent forecast cycles.} 
    \label{fig-dep-multi}
\end{figure}

\begin{figure}
    \begin{center}
        \includegraphics[width=6cm]{inkscape-svg/timeline-two-cycles-optimal.pdf} 
    \end{center}
    \caption[Optimal two-cycle job schedule]{\small Optimal two cycle
    job schedule when the next cycle's driving data is available in
    advance, possible in principle when intercycle dependencies are
    handled explicitly.} 
    \label{fig-optimal-two}
\end{figure} 

Figure~\ref{fig-optimal-two} shows, in contrast to
Figure~\ref{fig-overlap}, the optimal two cycle job schedule obtained by
respecting all intercycle dependencies.  This assumes no delays due to
resource contention or otherwise - i.e.\ every task runs
as soon as it is ready to run. The scheduler running
this suite must be able to adapt dynamically to external conditions 
that impact on multicycle scheduling in the presence of
intercycle dependencies or else, again, risk bringing the system down
with dependency violations.

\begin{figure}
    \begin{center}
        \includegraphics[width=12cm]{inkscape-svg/timeline-three.pdf} 
    \end{center}
    \caption[Post delay comparison of job schedules]{\small Job
    schedules for the example suite after a delay of almost one whole
    forecast cycle, when intercycle dependencies are
    taken into account (above the time axis), and when they are not
    (below the time axis). The colored lines indicate the time that
    each cycle is delayed, and normal ``caught up'' cycles
    are shaded gray.} 
    \label{fig-time-three}
\end{figure} 

\begin{figure}
    \begin{center} 
        \includegraphics[width=8cm]{inkscape-svg/timeline-two.pdf}
    \end{center} 
    \caption[Optimal job schedule when all external data is
    available]{\small Job schedules for the example suite in case study
    mode, or after a long delay, when the external driving data are
    available many cycles in advance. Above the time axis is the optimal
    schedule obtained when the suite is constrained only by its true
    dependencies, as in Figure \ref{fig-dep-two-linked}, and underneath
    is the best that can be done, in general, when intercycle
    dependencies are ignored.} 
    \label{fig-time-two}
\end{figure} 

To further illustrate the potential benefits of proper intercycle
dependency handling, Figure~\ref{fig-time-three} shows an operational
delay of almost one whole cycle in a suite with little downtime between
cycles. Above the time axis is the optimal schedule that is possible, in
principle, when intercycle dependencies are taken into account, and
below is the only safe schedule possible {\em in general} when they are
ignored.  In the former case, even the cycle immediately after the delay
is hardly affected, and subsequent cycles are all on time, whilst in the
latter case it takes five full cycles to catch up to normal real time
operation.
%Note that simply overlapping the single cycle schedules of
%Figure~\ref{fig-time-one} from the same start point would have resulted
%in dependency violation by task {\em c}.

Similarly, Figure~\ref{fig-time-two} shows example suite job schedules
for an historical case study, or when catching up after a very long
delay; i.e.\ when the external driving data are available many cycles in
advance.  Task {\em a}, which as the most upstream forecast model is
likely to be a resource intensive atmosphere or ocean model, has no
upstream dependence on cotemporal tasks and can therefore run
continuously, regardless of how much downstream processing is yet to be
completed in its own, or any previous, forecast cycle (actually, task
{\em a} does depend on cotemporal task {\em x} which waits on the
external driving data, but that returns immediately when the external
data is available in advance, so the result stands). The other forecast
models can also cycle continuously or with short gap between, and some
post processing tasks, which have no previous-instance dependence, can
run continuously or even overlap (e.g.\ {\em e} in this case). Thus,
even for this very simple example suite, tasks from three or four
different cycles can in principle run simultaneously at any given time. 
In fact, if our tasks are able to trigger off internal outputs of 
upstream tasks, rather than waiting on full completion, successive
instances of the forecast models could overlap as well (because model
restart outputs are generally completed early in the forecast) for an
even more efficient job schedule. 

%Finally, we note again that a good job scheduler should be able to
%dynamically adapt to delays in any part of the suite due to resource
%contention, varying run times, or anything else that will inevitably
%modify the depicted job schedules. 

\subsection{The Cylc Scheduling Algorithm} 
\label{TheCylcSchedulingAlgorithm}

\begin{figure}
    \begin{center} 
        \includegraphics[width=8cm]{inkscape-svg/task-pool.pdf}
    \end{center} 
    \caption[The cylc task pool]{\small How cylc sees a suite, in
    contrast to the multicycle dependency graph of Figure~\ref{fig-dep-multi}.
    Task colors represent different cycle times, and the small squares
    and circles represent different prerequisites and outputs. A task
    can run when its prerequisites are satisfied by the outputs 
    of other tasks in the pool.} 
    \label{fig-task-pool}
\end{figure} 

Cylc manages a pool of proxy objects that represent real tasks in the
forecasting suite. A task proxy object can run the real task when its
prerequisites are satisfied, and can receive reports of completed
outputs from the real task as it runs. There is no global cycling
mechanism to advance the suite in time; instead each individual task
proxy has a private cycle time and spawns its own successor. Task proxies
are self-contained and do not know what other tasks exist in the suite,
they just know their own prerequisites and outputs. Intercycle
dependencies are not treated specially, and the task pool
can be populated with tasks from many different cycle times. 
How cylc sees the task pool is illustrated in
Figure~\ref{fig-task-pool}. Now,
whenever any task proxy changes state (as a result of an output
completion message, for example) cylc gets the entire pool to interact
indiscriminately ({\em regardless of cycle time}) in an attempt to
match unsatisfied prerequisites with completed outputs.\footnote{In fact
this dependency negotiation goes through a middleman or broker object,
which reduces the interaction scaling from $n^2$ to $n$, where $n$ is
the number of task proxies in the suite.} 

Thus without using global cycling mechanisms, and treating all
dependencies equally, cylc in effect gets a set of individual tasks to
self-organise by negotiating their own dependencies: optimal scheduling,
as described in the previous section, emerges naturally at run time.

In addition, cylc makes no distinction between delayed and real time
operation. In delayed operation the tasks that gather the suite's
external driving data will return immediately (because the data is
already available) and the suite will only be constrained by its
internal dependencies. In real time operation, the data gathering tasks
will return only when the external data becomes available (at
some defined offset with respect to the task's cycle time), delaying
downstream tasks until then, by which time the previous forecast cycle
will have completed. A cylc suite thus transitions seamlessly from
optimal multicycle scheduling to a sequence of distinct forecast cycles
as it catches up to real time operation.

%Perhaps the most difficult problem encountered during cylc
%implementation was how to arrange that every task proxy object exists by
%the time it is needed, but not too much earlier, and does not die too
%long after it is no longer needed. This engendered no small amount
%of hair pulling and teeth gnashing, but once achieved the complexities
%therein are entirely hidden from the user.

\pagebreak

\pagebreak
\section{Installation} 
\label{InstallationAndTesting}

\subsection{Requirements} 
\label{Requirements}

\begin{myitemize}
    \item Operating System: Linux or Unix \footnote{The cylc codebase
        assumes Unix-style file paths in places, but it could easily
        made more portable if necessary.} 
    \item Python Version: 2.4 or later, but not Python
        3.x as yet.\footnote{Python 2.4 was released in November 2004. Python 3
        is the future of Python, but it is not backward compatible with
        2.x and consequently still has significantly less library and
        third party support.  As of mid 2011, Python 2.7 is still the
        standard for new Linux distributions.}
    \item PyGTK, a Python wrapper for the GTK+ graphical user interface toolkit.
        {\em PyGTK is included in
        most Linux Distributions.} http://www.pygtk.org
    \item Pyro 3 (Python Remote Objects) - latest version test
        3.12.\footnote{As of April 2011, Pyro 4, which is compatible
        with Python 3, is in development but it is still not recommended
        for production use.} %Open source license: MIT.
        Recently moved from sourceforge to: http://www.xs4all.nl/~irmen/pyro3
    \item The graphviz graph layout engine (latest version tested:
        2.26.3). %Open source license: Eclipse Public License v1.0.
        http://www.graphviz.org
    \item Pygraphviz, a python interface to graphviz (latest version
        tested: 1.0rc6). %Open source license: BSD
        \newline
        http://networkx.lanl.gov/pygraphviz
\end{myitemize}

Of the software listed above, Python and Pyro are essential; PyGTK is
required to run the gcylc suite database and suite control GUIs, but you
can equally control and monitor cylc suites from the commandline. Graphviz
and pygraphviz are required for dependency graphing and the graph-based
suite control GUI, but you can also run cylc without them.

Cylc has also absorbed in modified form (so you don't need to install 
them) the following open source software packages:
\begin{myitemize}
    \item The xdot graph viewer 
        (http://code.google.com/p/jrfonseca/wiki/XDot,
        open source license: LGPL)
    \item The ConfigObj and Validate python modules \newline
        (http://www.voidspace.org.uk/python/configobj.html,
        open source license: BSD)

\end{myitemize}

\subsection{Installation} 
\label{Installation}

\subsubsection{Cylc}

Cylc is designed to be installed into a normal user account (called
`admin' below). Simply unpack the cylc release tarball into your chosen
location. Users gain access by sourcing the cylc environment script:

\begin{lstlisting}
# configure your shell environment for access to cylc
admin> export CYLC_DIR=/path/to/cylc/installation/
admin> . $CYLC_DIR/environment.sh
\end{lstlisting}

Note that the variable \lstinline=$CYLC_DIR= is actually required by
the environment script, so don't skip the export step.

% TO DO: SYSTEM LEVEL INSTALL INSTRUCTIONS
%For a system-level install just inspect the environment script for the
%few critical executable and source module paths, and install the
%contents therein in standard system locations. Users would then not need
%to source the environment script before using cylc. 

\subsubsection{Other}

Pyro, graphviz, and Pygraphviz all have their own simple installation
instructions.  If you can't get these installed at system level it is 
quite possible to install them all into a user account, and then adapt
the cylc environment script slightly to ensure that cylc can access 
them.

\subsection{Create the Central Suite Database}

Cylc suites must be registered in a local (user-specific) database 
before they can be used. Suites can also be exported to a central
database visible to all users. Run the following script to 
create the central database and export several example suites to
it:

\begin{lstlisting}
admin> cylc admin create-cdb
\end{lstlisting}
(You must have installed cylc and configured your environment as above
before doing this). To view the contents of the central database,
run gcylc and click on `Database' \lstinline@->@ `CentralDB', or 
on the commandline:

    \lstset{ basicstyle=\color{basic}\scriptsize\ttfamily }
\begin{lstlisting}
admin> cylc db print --central
admin:examples:simple  "a simple example suite"  /home/admin/cylc/examples/simple
admin:examples:userguide  "user guide example suite"  /home/admin/cylc/examples/userguide
\end{lstlisting}
    \lstset{ basicstyle=\color{basic}\footnotesize\ttfamily }


\subsection{Testing}
\label{Testing}

\subsubsection{Suite Database Test} 

The command \lstinline=cylc admin test-db= gives suite database
functionality a work out - it registers the user guide example suite
under a new name and then manipulates it (by copying the suite in
various ways, exporting it to the central database, and so on, before
finally deleting the test registrations). This process should complete
in a few seconds without errors.

\subsubsection{Suite Scheduler Test} 

The command \lstinline=cylc admin test-suite= tests the cylc scheduler
itself by running an example suite, configuring it to fail out a
specific task, and then doing some advanced failure recovery
intervention on it (recursive purge plus insertion of cold start tasks).
This process should complete in 2-3 minutes, and can be watched in real
time by right-clicking on the test suite, when it appears in the gcylc
local database window and opening up the suite control GUI.

\pagebreak
\section{Screenshots}

This section of the user guide contains a few screenshots of cylc in use,
just to show what the various elements of the user interface looks like,
and to give a general impression of available functionality.

\begin{myitemize}
    \item Figure~\ref{fig-command-help} - the cylc commandline interface, top level.
    \item Figure~\ref{fig-db} - the gcylc GUI, private (user-specific) database.
    \item Figure~\ref{fig-cdb} - the gcylc GUI, central (multi user) database.
    \item Figure~\ref{fig-cylc-vim} - a simple cylc suite definition file (suite.rc) in the vim editor.
    \item Figure~\ref{fig-simple-graph-2} - the suite definition of Figure~\ref{fig-cylc-vim} graphed by cylc.
    \item Figure~\ref{fig-gcylc-original} - the gcylc suite control GUI, treeview interface.
    \item Figure~\ref{fig-gcylc-graph} - the gcylc suite control GUI, graph interface.
    \item Figure~\ref{fig-ecox-1} - a large operational suite graphed by cylc.
    \item Figure~\ref{fig-ecox-2} - another view of the large operational suite of Figure~\ref{fig-ecox-1}.
\end{myitemize}

\begin{figure}
    \begin{center}
        \includegraphics[width=0.8\textwidth]{../images/screenshots/commandhelp.png}
    \end{center}
\caption{\small The cylc commandline interface, top level}
\label{fig-command-help}
\end{figure} 

\begin{figure}
    \begin{center}
        \includegraphics[width=0.8\textwidth]{../images/screenshots/db.png}
    \end{center}
\caption[gcylc: Private Suite Database]{\small
The gcylc GUI showing the private suite database (user-specific).}
\label{fig-db}
\end{figure} 

\begin{figure}
    \begin{center}
        \includegraphics[width=0.8\textwidth]{../images/screenshots/cdb.png}
    \end{center}
\caption[gcylc: Central Suite Database]{\small
The gcylc GUI showing the central suite database (all users).}
\label{fig-cdb}
\end{figure} 

\begin{figure}
    \begin{center}
        \includegraphics[height=0.45\textheight]{../images/screenshots/simple-suiterc.png}]
    \end{center}
    \caption{A simple cylc suite definition being edited in {\em vim}}
    \label{fig-cylc-vim} 
\end{figure} 

\begin{figure}
    \begin{center}
        \includegraphics[width=0.35\textheight]{../images/screenshots/simple-18-cold.png}
    \end{center}
    \caption{The suite definition of Figure~\ref{fig-cylc-vim} graphed by cylc.}
\label{fig-simple-graph-2}
\end{figure} 

\begin{figure}
    \begin{center}
        \includegraphics[width=0.8\textwidth]{../images/screenshots/control-trad.png}
    \end{center}
\caption{\small The gcylc suite control GUI, treeview interface.}
\label{fig-gcylc-original}
\end{figure} 

\begin{figure}
    \begin{center}
        \includegraphics[width=0.8\textwidth]{../images/screenshots/control-graph.png}
    \end{center}
\caption{\small The gcylc suite control GUI, graph interface.}
\label{fig-gcylc-graph}
\end{figure} 

\begin{figure}
    \begin{center}
        \includegraphics[width=\textwidth]{../images/screenshots/ecox-1.png}
    \end{center}
\caption{\small A large operational suite graphed by cylc.}
\label{fig-ecox-1}
\end{figure} 

\begin{figure}
    \begin{center}
        \includegraphics[width=0.8\textwidth]{../images/screenshots/ecox-2.png}
    \end{center}
    \caption{\small Another view of the large operational suite of Figure~\ref{fig-ecox-1}.}
\label{fig-ecox-2}
\end{figure} 


% dump floats
\clearpage

\pagebreak

\section{On The Meaning Of {\em Cycle Time} In Cylc}

You may be used to the idea that a forecasting suite has a ``current
cycle time'', which is the analysis time or nominal start time
associated with the main forecast model(s) in the suite, and that
the whole suite advances to the next forecast cycle when all tasks in
the current cycle have finished (or even when a particular wall clock
time is reached, in real time operation). This is not how cylc works.

\subsubsection{Cylc Has No Global (Suite-Wide) Cycle Time}

In {\em Introduction: How Cylc Works} (Section~\ref{HowCylcWorks}) it is
explained that {\em each task in a cylc suite has its own private cycle
time} and can run when its prerequisites are satisfied regardless of
other tasks (with, potentially, different cycle times) that happen to be
running at the same time.  Cylc suites advance by means of each task
spawning its own successor at the next valid cycle time for the task,
not by a global loop over successive forecast cycles. 
%\footnote{A task's private cycle time is still the familiar analysis
%time for forecast model tasks, or that of the associated model(s) for
%pre- and post-processing tasks, however.}

However, it is still sometimes convenient (and potentially confusing,
unfortunately) to refer to the ``current cycle'', the ``previous
cycle'', or the ``next cycle'' and so on, with reference to a particular
task, and particularly in real time operation. This means, of course,
all tasks that ``belong to the same forecast cycle''.  Just keep in
mind that the members of such a group may not all exist in the running
suite at the time. In other words, each task may pass through the
``current cycle'' (etc.) at a different time as the suite
evolves, particularly in delayed operation.

\pagebreak
\section{Quick Start Guide} 
\label{QuickStartGuide}

\lstset{language=bash}

In this section we will work through some basic cylc functionality using
the ``QuickStart'' example suites, which should have been registered in
the central suite database during cylc installation. 

\subsection{Cylc Environment}

To gain access to cylc you just need to source the cylc environment
script. Put the following code in your login script, or do the same at the
terminal prompt before using cylc.\footnote{To switch between different
cylc installations just source the appropriate environment script.}
\begin{lstlisting}
# .profile
export CYLC_DIR=/path/to/cylc/installation
. $CYLC_DIR/environment.sh
\end{lstlisting}

You should also specify the graphical and terminal editors you want to
use to edit suites, by setting the following environment variables in
your \lstinline=.profile=:
\begin{lstlisting}
# .profile
export GEDITOR='gvim -f'  # GUI editor launched by gcylc
export EDITOR=vim         # terminal editor launched by 'cylc edit'
\end{lstlisting}
See \lstinline=cylc edit help= (Appendix~\ref{edit}) for other editor
examples. And finally, you must ensure that \lstinline=$TMPDIR= is 
defined in your environment, for example:
\begin{lstlisting}
# .profile
export TMPDIR=/tmp/$USER
\end{lstlisting}

\subsection{Start Your Lockserver Daemon}

Each cylc user should run a lockserver to prevent accidental 
invocation of multiple instances of the same suite or task at the same 
time.  The suite and task locks brokered by the lockserver are analogous
to traditional lock files, but they work across a network, even for
distributed suites containing tasks that start executing on one host and
finish on another.

The lockserver daemon can be started at any time and left running.
\begin{lstlisting}
prompt> cylc lockserver start
\end{lstlisting}

Check that it is running,
\begin{lstlisting}
prompt> cylc lockserver status
\end{lstlisting}

For detailed usage information,
\begin{lstlisting}
prompt> cylc lockserver --help 
\end{lstlisting}

There is a command line client interface, 
\lstinline=cylc lockclient=,
for interrogating the lockserver and managing 
locks manually (c.f.\ deleting a lock file manually if the
associated process died without cleaning up after itself).

You can also choose not to use the lockserver for a particular suite, by
setting the following switch in its suite.rc (suite definition) file,
\begin{lstlisting}
# SUITE.RC:
use lockserver = False  # not recommended!
\end{lstlisting}

\subsection{Start The gcylc GUI}

At the command prompt:
\begin{lstlisting}
prompt> gcylc &
\end{lstlisting}
and use the Database menu to switch to the central database, which
displays suites accessible to all users, in a treeview by owner, group,
and name (see Figure~\ref{fig-cdb}).

\subsubsection{Central Suite Database Actions}

By right-clicking on a suite in the central database, or using the cylc
commandline, you can:
\begin{myenumerate}
    \item retrieve the suite description,
    \item list tasks in the suite,
    \item view the suite definition in your editor,
    \item plot the suite dependency graph,
    \item search the suite definition and bin scripts,
    \item validate the suite definition,
    \item import the suite or group to your private database,
    \item unreregister or delete the suite or group (if you own it),
    \item reregister the suite or group (if you own it).
\end{myenumerate}
But you can only {\em run} suites that are registered in your private
database. 

\subsection{Import The QuickStart Suites To Your Private Database} 

You can register new suites directly in your private database using gcylc 
or the \lstinline=cylc db register= command, or you can import suites
from the central database.

Find the suite registered under the `admin:QuickStart' group in the
central database (replace `admin' with the name of the user account
under which cylc was installed). If there are a lot of suites in the
central database, use View $\rightarrow$ Filter to restrict the view
(you can leave the dialog open and refilter as often as you like).

Now right click on the QuickStart group and choose `Import'; this will
copy the whole group of suites to your private database. A dialog box
will pop up allowing you to register your copy under a different group
(leave this as it is) and a destination for the suite definition
directories in the group (choose something like
\lstinline=$HOME/suites/QuickStart=). 

{\em Note that you can also import individual suites, and that
registration groups do not need to be created explicitly, they
are automatically created and deleted as required.} 

Now use the Database menu to switch back to your private database, and
confirm that you now have a copy of the example suites.

\subsubsection{Commandline}

Here's how to do the same thing on the commandline:

%\lstset{ basicstyle=\color{basic}\scriptsize\ttfamily }
\begin{lstlisting}
# Check that the QuickStart example suites are registered in the central database,
prompt> cylc db print --central | grep QuickStart
admin:QuickStart:foo  "(foo)" /home/admin/cylc/examples/QuickStart/a
admin:QuickStart:bar  "(bar)" /home/admin/cylc/examples/QuickStart/b
admin:QuickStart:baz  "(baz)" /home/admin/cylc/examples/QuickStart/c

# Import the group of suites,
prompt> cylc db import admin:QuickStart: $HOME/suites/QuickStart
# TBD!

# Check the import was successful,
prompt> cylc db print | grep QuickStart
QuickStart:foo  "(foo)" /home/oliverh/suites/QuickStart/a
QuickStart:bar  "(bar)" /home/oliverh/suites/QuickStart/b
QuickStart:baz  "(baz)" /home/oliverh/suites/QuickStart/c
\end{lstlisting}

%\lstset{ basicstyle=\color{basic}\footnotesize\ttfamily }

\subsubsection{Private Suite Database Actions}

By right-clicking on a suite in your private database, or using the cylc
commandline, you can:
\begin{myenumerate}
    \item start a suite control GUI to run the suite (or connect to a running suite),
    \item submit a single suite task to run, just as it would be submitted by the suite
    \item view the suite stdout and stderr streams,
    \item view the suite log file (which records all scheduling events and messages),
    \item retrieve the suite description,
    \item list tasks in the suite,
    \item edit the suite definition in your editor,
    \item plot the suite dependency graph,
    \item search the suite definition and bin scripts,
    \item validate the suite definition,
    \item copy the suite or group,
    \item export the suite or group to the central database,
    \item unreregister the suite or group,
    \item reregister the suite or group.
\end{myenumerate}

Note that the suite title shown in the database viewers is parsed
from the suite.rc file at the time of initial registration; if you
change the title when editing the suite.rc file, use 
\lstinline=cylc db refresh= or gcylc 
\lstinline=View $\rightarrow Refresh= 
to update the database.


\subsection{View The QuickStart:foo Suite Definition}

Right-click on the suite and choose `Edit', or use the edit command,
\begin{lstlisting}
prompt> cylc edit QuickStart:foo
\end{lstlisting}
to view the suite definition (suite.rc file) in your editor. 

This moves to the suite definition directory (so that you can easily
open other suite files in the same edit session) and opens the
suite.rc file in your chosen editor. You can of course
do this entirely manually, but this way is very quick and convenient,
you don't have to remember suite definition directory locations, and
for suite.rc files that contain include files (even nested ones) you can
optionally edit the file inlined - it will be split back into its
constituent include-files {\em when you save and exit the editor}. 

If you use the vim editor your can have nice cylc-specific syntax
highlighting and section folding; see Section~\ref{SyntaxHighlighting}
for a screenshot and instructions. 

You should see the following suite.rc file in your editor: 

\lstinputlisting{../examples/QuickStart/foo/suite.rc}

This defines a complete, valid, runnable suite. To understand suite.rc
files in detail, read {\em Suite Definition}
(Section~\ref{SuiteDefinition}). But here's a summary of what this 
particular suite.rc file means, in words: 

At 0, 6, 12, and 18 hours each day a clock-triggered task called GetData
triggers 1 hour after the wall clock reaches its nominal cycle
time; then a {\em sequential} task called Model triggers when GetData finishes;
and a task called PostA triggers when Model is finished. Additionally,
Model depends on its own previous instance from 6 hours earlier; and twice
per day at 6 and 18 hours another task called PostB also triggers off Model.

The fact that Model is declared to be sequential means that it can't start
running until its previous instance has finished, whereas the other tasks 
can run in parallel with their own previous instances if the opportunity 
arises (in fact there is no particular reason to make Model sequential in
this suite other than to demonstrate that we can force tasks to be
sequential). 

Finally, when the suite is first {\em cold started} from scratch it is
made to wait on a special {\em startup} task
called Prep. Startup tasks are oneoff tasks (non-spawning) that are 
only used at suite startup, and any dependence on a startup task in the
suite graph only applies at suite startup.

The optional visualization section, fairly obviously, just defines
properties used to plot the suite graph, which we'll do next.

\subsection{Plot The QuickStart:foo Dependency Graph}

Right-click on the QuickStart:foo suite in gcylc and choose Graph; or on
the commandline,
\begin{lstlisting}
prompt> cylc graph QuickStart:foo 2011052300 2011042318 &
\end{lstlisting}
This will pop up a zoomable, pannable, graph viewer application showing
the graph of Figure~\ref{fig-QuickStartA-graph18}. 

{\em If you edit the suite.rc file the graph viewer will update whenever
you save the file.}

\begin{figure}
    \begin{center}
        \includegraphics[width=0.7\textwidth]{../images/screenshots/QuickStartA-graph18.png}
    \end{center}
\caption{\small The QuickStart:foo suite dependency graph.}
\label{fig-QuickStartA-graph18}
\end{figure}

\subsection{Run The QuickStart:foo Suite}

No task commandlines have been defined in the QuickStart:foo suite so
cylc will use the default {\em dummy} commandlines for each task.
If defined explicitly in the suite.rc file the dummy task commandlines
would look like this:
\begin{lstlisting}
# SUITE.RC
[tasks]
    [[GetData]]
        command = cylc wrap -m "echo DUMMY $TASK_ID; sleep $CYLC_DUMMY_SLEEP"
\end{lstlisting}
where \lstinline=$TASK_ID= is the tasks unique identifier in the suite 
(\lstinline=TASKNAME%YYYYMMDDHH=) and \lstinline=$CYLC_DUMMY_SLEEP=
defaults to 10 seconds. Fairly obviously, this writes an identifying
message to stdout and then sleeps for a few seconds before exiting. 
The task wrapper \lstinline=cylc wrap= allows cylc to run unmodified
existing commands, scripts, or programs (see {\em Task
Wrapping: Using Existing Scripts As Cylc Tasks} - it automatically
reports the task started, and succeeded or failed according to the 
exit status of the wrapped process (see Section~\ref{TaskWrapping}).

Now start a suite control GUI by right-clicking on the suite in gcylc
and choosing `Control (graph)'. 

{\em Note that if you start a suite running via a suite control GUI
and then shut down the GUI, the suite will keep running.  If you
open another instance of the control GUI (for the same suite) it 
will reconnect if the suite is already running.}

In the control GUI choose Run from the Control menu, enter an initial
cold start cycle time (e.g.\ 2011052306), and select ``Hold (pause) on
startup'' so that the suite starts in the paused state, wherein tasks
won't be submitted even if they are ready to run. 

{\em Do not choose an initial cycle time in the future or nothing will
happen until that time.}

If the initial cycle time ends in 06 or 18 
the suite controller should look like Figure~\ref{fig-QuickStartA-ControlStart06},
otherwise (00 or 12) like Figure~\ref{fig-QuickStartA-ControlStart00}.

\begin{figure}
\begin{minipage}[t]{0.5\textwidth}
    \begin{center}
        \includegraphics[width=\textwidth]{../images/screenshots/QuickStartA-ControlStart06.png}
    \end{center}
    \caption{\small foo}
    \label{fig-QuickStartA-ControlStart06}
\end{minipage}
\hfill
\begin{minipage}[t]{0.5\textwidth}
    \begin{center}
        \includegraphics[width=\textwidth]{../images/screenshots/QuickStartA-ControlStart00.png}
    \end{center}
    \caption{\small bar}
    \label{fig-QuickStartA-ControlStart00}
\end{minipage}
\end{figure} 

The reason for the difference in graph structure between the two start
cycles is this: cylc starts up with every task present, in the waiting
state (blue), at the intitial cycle time {\em or} at the first
subsequent valid cycle time for the task - and PostB is not valid at 00
or 12. The off-white tasks are from the base graph and aren't actually
present in the suite as yet (so they will not appear in the non
graph-based suite control GUI).

\subsubsection{Release The Hold On The Suite}

Choose Release from the Control menu in the suite control GUI, and
observe what happens: all the GetData tasks out to a few cycles ahead
will rapidly go off at once, and then the suite will stall, as shown in
Figures~\ref{fig-QuickStartA-ControlRunning}
and~\ref{fig-QuickStartA-ControlRunning}. 

\begin{figure}
\begin{minipage}[t]{0.5\textwidth}
    \begin{center}
        \includegraphics[width=\textwidth]{../images/screenshots/QuickStartA-ControlRunning.png}
    \end{center}
    \caption{\small foo}
    \label{fig-QuickStartA-ControlRunning}
\end{minipage}
\hfill
\begin{minipage}[t]{0.5\textwidth}
    \begin{center}
        \includegraphics[width=\textwidth]{../images/screenshots/QuickStartA-ControlStalled.png}
    \end{center}
    \caption{\small bar}
    \label{fig-QuickStartA-ControlStalled}
\end{minipage}
\end{figure} 

The Prep task runs immediately because it has no prerequisites and is
not clock-triggered. The clock-triggered GetData tasks then all go off
at once because they have no prerequisites (i.e.\ they do not have to
wait on any upstream tasks), their trigger time as long passed (the
initial cycle time was in the past), and they are not sequential tasks
(so they are able to run in parallel).
They stop spawning beyond four cycles ahead because of the suite 
``runahead limit'' set to 12 hours in the suite.rc file. The runahead
limit is designed to stop free tasks like this from running off too far
into the future. It is normally of no conseqence in real time operation
because the clock triggered tasks are then constrained by the wall
clock, and the other (downstream) tasks have to wait on them.

\subsubsection{Viewing Task States}

If you're wondering why a particular task has not triggered yet in a
running suite you can view the current state of its prerequisites 
by right-clicking on the task and choosing `View State', or using
\lstinline=cylc show=. Doing this for the first Model task, which is 
stuck in the waiting state, results in Figure~\ref{fig-QuickStartA-ModelState}.

\begin{figure}
    \begin{center}
        \includegraphics[width=0.5\textwidth]{../images/screenshots/QuickStartA-ModelState.png}
    \end{center}
    \caption{\small foo}
    \label{fig-QuickStartA-ModelState}
\end{figure} 

It is clear that the reason the task is not running and consequently, by
virtue of the runahead limit, why the suite as a whole has stalled, is
the Model(T) is waiting on Model(T-6) which does not exist at suite
startup. Model of course represents a warm-cycled forecast model that
depends on a ``model background'' or ``restart file(s)'' generated by
its own previous run.

\subsubsection{Triggering Tasks Manually}

Right-click on the waiting Model and choose Trigger, or use
\lstinline=cylc trigger=, to force the task to trigger, and thereby get
the suite up and running. In a real suite this would not be sufficient:
the real forecast model that the Model task represents would probably
fail for lack of the real restart files that it requires as input.
Well see how to handle this properly shortly.

\subsubsection{Shutting Down And Restarting A Suite}

Having watched the QuickStart:foo suite run for a while, choose Stop from
the Control menu, or \lstinline=cylc stop=, to shut it down. The default
stop method waits for any tasks that are currently running to finish
before shutting the suite down, so that the final recorded suite state
is perfectly consistent with what actually happened.  

You can restart the start from where it left off by choosing Run from
the Control menu and selecting the `restart' option, or using
\lstinline=cylc restart=. {\em Note that cylc always writes a special
state dump, and logs its name, prior to actioning any intervention, and
you can restart a suite from one of these states, rather than the 
default most recent state, in case you make a mistake.}

\subsection{QuickStart:bar - Handling Model Cold Starts Properly}

Now take a look at the QuickStart:bar suite, which is a minor modification 
of QuickStart:foo. The suite.rc file has a new {\em coldstart} task called
ColdModel,

\begin{lstlisting}
# SUITE.RC
[special tasks]
    coldstart = ColdModel
\end{lstlisting}
and the dependency graph (see also Figure~\ref{fig-QuickStartB-graph18})
looks like this:
\begin{lstlisting}
# SUITE.RC
[dependencies]
    [[ 0,6,12,18 ]]
        graph  =  """Prep => GetData & ColdModel
                     GetData => Model => PostA
                     ColdModel | Model(T-6) => Model"""
    [[ 6,18 ]]
        graph = "Model => PostB"
\end{lstlisting}

In other words, Model can trigger off {\em either} its previous-cycle
self {\em or} ColdModel in the same cycle. 

\begin{figure}
    \begin{center}
        \includegraphics[width=0.7\textwidth]{../images/screenshots/QuickStartB-graph18.png}
    \end{center}
\caption{\small The QuickStart:bar suite dependency graph showing a model cold start task.}
\label{fig-QuickStartB-graph18}
\end{figure}

A coldstart task is a oneoff task used to satisfy the previous-cycle
dependence of a cotemporal task whose previous-cycle trigger is not
available. The obvious use for this is to cold start warm-cycled
forecast models at suite startup, when there is no previous cycle.
Unlike startup tasks though, cold start dependencies are not restricted
to suite startup because it is sometime useful to be able to 
insert a cold start task into a running suite, to get a model restarted
after it skipped a cycle due to problems, without having to restart the
rest of the suite.

{\em A model cold start task in a real suite often submits a real ``cold
start forecast'' to generates the previous-cycle input files required by
its associated model}.  Or it could just stand in for some external
spinup process, or similar, that has to be completed before the suite
starts - in this case the cold start task would be a dummy task that
simply reports successful completion in order to satisfy the initial
previous-cycle dependence of the model.

If you run QuickStart:bar you'll see that no manually triggering is required
to get the suite started this time.


\subsection{QuickStart:baz - With Complete Task Implementation}

The QuickStart:baz suite is the same as QuickStart:bar except that its
tasks run real scripts, located in the suite bin directory. The task 
scripts are independently configured (i.e.\ they don't know about each
other) but they generate output files and consume input files in such a
way that the dependency graph of Figure~\ref{fig-QuickStartB-graph18}
must be respected or they won't run successfully.

The suite configures the task scripts, through their respective
execution environments, in such a way that they run in the proper
sequence. 

By studying this suite and its tasks, and by making quick copies of 
it to modify and run, you should be able to learn a lot about how 
to build real cylc suites.

\subsection{Following What's Happening In A Running Suite}

\subsubsection{Suite Stdout and Stderr}

When cylc runs a suite it writes warnings and other information messages
(such as when and how each task is submitted) to the stdout stream. If 
you start a suite at the commandline, what happens to this output is
entirely up to you. If you start a suite via gcylc, the output is 
redirected to a special file, \lstinline=$HOME/.cylc/SUITE.out= that can
be reaccessed if you later reconnect to the suite with a new control GUI
instance.

\begin{figure}
    \begin{center}
        \includegraphics[width=0.7\textwidth]{../images/screenshots/suite-output.png}
    \end{center}
\caption{\small Cylc suite stdout/stderr example.}
\label{fig-suite-output}
\end{figure}

\subsubsection{Suite Logs}

The cylc suite log records every event that occurs (incoming messages from tasks
and so no) along with the time of the event. The top level logging directory,
under which a suite-specific log is written, is configurable in the suite.rc file.
The default location is \lstinline=$HOME/.cylc/logging/=. Suite logs are
(optionally) rolled over at start up and the 5 most recent back ups are
automatically kept.

\begin{figure}
    \begin{center}
        \includegraphics[width=0.7\textwidth]{../images/screenshots/suite-log.png}
    \end{center}
\caption{\small A cylc suite log via gcylc.}
\label{fig-suite-log}
\end{figure}

Figure~\ref{fig-suite-log} shows a suite log viewed from within gcylc. The 
\lstinline=cylc log= command also enables viewing and filtering of suite logs
without having to remember the actual log file location.

\subsubsection{Task Stdout and Stderr Logs}

The stdout and stderr logs generated when a task is submitted to run end up
in the {\em job submission log directory}, which is a suite.rc
configurable item (the default location is \lstinline=$HOME/CylcLogs/GROUP/NAME/=).


\subsection{Searching A Suite}

The cylc suite search tool or reports matches in the suite.rc file
by line number, suite section, and file, even if nested include-files
are used, and by file and line number for matches in the suite bin
directory.  The following output listing is from a search of
the examples:userguide suite, because the QuickStart suites are a little
too minimal to bother with in this context:
\begin{lstlisting}
prompt> cylc grep OUTPUT_DIR examples:userguide

FILE: /home/oliverh/suites/examples/userguide/suite.rc
   SECTION: [tasks]->[[X]]->[[[environment]]]
      [53]:             OUTPUT_DIR = $WORKSPACE
   SECTION: [tasks]->[[A]]->[[[environment]]]
      [59]:             OUTPUT_DIR = $WORKSPACE

<...snip...>

FILE: /home/oliverh/suites/examples/userguide/bin/E.sh
   [7]: cylc checkvars -c OUTPUT_DIR
   [21]: touch $OUTPUT_DIR/sea-state.products

FILE: /home/oliverh/suites/examples/userguide/bin/D.sh
   [7]: cylc checkvars -c OUTPUT_DIR
   [24]: touch $OUTPUT_DIR/combined.products

<...snip...>
\end{lstlisting}
(The same thing can of course be done via the gcylc right-click menu).

\subsection{Validation}

After editing a suite always validate it to check for errors, via 
gcylc or the \lstinline=cylc validate SUITE= command.
Figure~\ref{fig-validate-eg} shows validation of 
examples:DepGraphCh6. Note the warnings that the tasks 
will be dummied out, as discussed above. 

\begin{figure}
    \begin{center}
        \includegraphics[width=0.5\textwidth]{../images/screenshots/validate-eg.png}
    \end{center}
\caption{Example Suite DepGraphCh6 Validation.}
\label{fig-validate-eg}
\end{figure}

For more information on suite validation see
Section~\ref{Validation}.

\pagebreak
\section{Using Example Suites To Understand Cylc}

Cylc has been designed from the ground up to make testing and
prototyping very easy.  Simply ``drawing'' (textually) a dependency
graph in a new suite.rc file creates a valid suite that you can run (the
tasks will default to the ``dummy task command'': emitting an
identifying message, sleeping for a few seconds, and then exiting). You
can then arrange for particular tasks to do more complex things (to
fail, for example) by supplying appropriate task commandlines to replace
the default one.

Cylc's example suites run quickly and are portable: you can copy one and
run it without modification (in fact you can run multiple copies at
once, under different registrations, because the suite group and name
are used in all I/O paths).

The ``QuickStart2'' and ``userguide'' examples have actual external task
implementations, in the form of scripts in the suite bin directory, that
behave like real tasks: each generates cycle-specific output files 
required as input by other tasks, and if not executed in the proper
order they will abort with a {\em file not found} error, or similar.

You can copy an example suite in an instant, using the cylc commands or
GUI, make a few changes according to your needs, and then run it to see
what happens.

You can also run real suites in dummy mode, wherein each real task is
replaced by the default dummy task (above) and the suite runs quickly on
an accelerated clock. As far as cylc is concerned this is almost
identical to real operation, so dummy mode can be used to test recovery
strategies for certain kinds of failure, for instance. In dummy mode you
can watch how any suite catches up and transitions from delayed to real
time operation.

The lockserver will let you run multiple instances of the userguide
example suite at once, under different registrations, because the
suite.rc file allows that (i.e.\ the suite group and name are used in
all I/O paths so that different suite instances will not interfere).

\pagebreak
\section{Suite Registration}
\label{SuiteRegistration}

How to construct a cylc suite is described in coming sections of the
user guide. But before you can do anything to a suite with the cylc
command set (which includes tools to aid in suite construction as well
as suite control) you must register it in your {\em private suite
database}. 

\subsection{Private Suite Databases}

Your private suite registration database simply maps suites,
organised by GROUP and NAME, to their suite definition locations (see
{\em Suite Definition}, Section~\ref{SuiteDefinition}). You can then
refer to your suites concisely by ``by name'' without having to specify,
or even remember, where the suite definition actually resides.
For example this command,
\begin{lstlisting}
prompt> cylc info list oper:foo
# or (the `info' command category is optional -see `cylc help'):
prompt> cylc list oper:foo
\end{lstlisting}
lists all the tasks in suite `foo' of the `oper' group.

\subsection{The Public Suite Database}

The public suite registration database also maps suite ``names'' to 
their suite definition locations, except that it organises its suites
by owner as well as group and name, and the associated cylc commands
can automatically copy the actual suite definitions to a central location
too (the suite definition itself isn't ``stored in the database'' but 
the new registration will refer to the new centrally located suite
definition). Also, you can inspect suites in the public database by 
various means, just as in your private database, but you can't run
public suites without {\em importing} them to your private database.

The public suite database facilitates sharing of suites among cylc users
without cluttering the public namespace with suites that are partially
completed, broken, or not generally useful (in the eyes of the owner).

\subsubsection{Warning}

The public suite database is not currently accessible on the network, it
is local to the cylc host, and it briefly locks users out during
operations that change the minimal registration data (i.e.\ the mappings
between suite names and locations, not when copying suite definitions 
to the central location, which is potentially time consuming). 

\subsubsection{Future Development} 

We intend to develop a client/server interface to the public suite
database so that users can share suites across the network. The 
required server functionality is essentially identical to that of the
cylc lockserver, so this will not be difficult. 

\subsection{Database Operations}

On the commandline, the  `database' (or `db') command category contains
commands for discovering what suites have been registered (privately or
publicly); registering new suites; copying, unregistering, deleting,
or re-registering suites; and exporting suites to, or importing them
from, the central database.  

\lstinputlisting{command-usage/database.txt}

The same functionality is also available by right-clicking on suites
or groups in the gcylc GUI, as shown in Figure~\ref{fig-pdb-new}.

\pagebreak
\section{Suite Definition} 
\label{SuiteDefinition}

A cylc suite is defined entirely by a single structured, validated, {\em
suite.rc file} that concisely specifies the properties of, and the
relationships between, the various {\em tasks} managed by the suite. 

This section of the user guide deals with the format and content of the
suite.rc file, including task definition.  Task {\em implementation} - 
what's required of the real commands, scripts, or programs that
do the processing that the tasks represent, is covered in
Section~\ref{TaskImplementation}.

%for how to write the suite.rc dependency graphs that determine the
%structure of your suite see {\em Suite.rc Dependency Graphs}
%(Section~\ref{DependencyGraphs}) ; for how to construct the tasks 
%that do the real processing in a cylc suite see {\em Task
%Implementation} (Section~\ref{TaskImplementation}), and for how cylc
%tasks are actually submitted to run, see{\em Job Submission} 
%(Section~\ref{JobSubmission}).

\subsection{The Suite Definition Directory}

A cylc {\em suite definition directory} contains:
\begin{myitemize}
    \item {\bf a suite.rc file}: this is {\em the} suite definition
    \item any include-files used by the suite.rc file (see Section~\ref{IncludeFiles})
        %\begin{myitemize}
        %    \item use of include-files is optional
        %    \item these may be kept in sub-directories, 
        %    \item paths should be specified portably, relative to the
        %        suite definition directory
        %\end{myitemize}
    \item {\bf a bin directory} for scripts and programs that implement,
        or are used by, suite tasks
        \begin{myitemize}
            \item technically optional - tasks can call external
                commands, scripts, or programs 
            \item tasks get automatic access to their own suite bin directory
        \end{myitemize}
    \item any other suite-related documentation, control files, etc.
        \begin{myitemize}
            \item whole suite definition directories are copied if you
                copy a suite
            \item files in the suite definition directory can be
                accessed portably by tasks at run time 
                through the environment variable \lstinline=$CYLC_SUITE_DIR=
                supplied by the suite (see
                {\em Task Execution Environment}
                (Section~\ref{TaskExecutionEnvironment})
            \item holding everything in one place makes revision control
                easy
        \end{myitemize}
\end{myitemize}

Here's an imaginary example,

\begin{lstlisting}
/path/to/my/suite   # suite definition directory
    suite.rc           # <-- SUITE DEFINITION FILE
    bin/               # bin directory (scripts, programs)
        foo.sh
        bar.sh
        ...
    # (OPTIONAL) any other suite-related files, for example:
    inc/               # suite.rc include-files
        nwp-tasks.rc
        globals.rc
        ...
    doc/               # documentation
    control/           # control files
    ancil/             # ancillary files
    ...
\end{lstlisting}

\subsection{The suite.rc File}
\label{SuiteRCFile}

Cylc suite.rc files parse directly into a nested data structure inside
cylc, which makes it very easy to add and use new configuration items.

Suite.rc files are automatically validated against a specification file 
(\lstinline=$CYLC_DIR/conf/suiterc.spec=) that defines all legal
entries, values, options, and defaults; these are documented
in detail in the {\em Suite.rc Reference}
(Appendix~\ref{SuiteRCReference}).

\subsubsection{Syntax}

\begin{myitemize}
    \item {\bf Entries} take the form \lstinline@item = value@.
    \item {\bf Comments} follow a hash character (\#) to the end of the line.
    \item {\bf Single Line Strings} can be quoted, but the quotes can be 
        omitted if the string contains no commas (which are used for list
        values).
    \item {\bf Multiline Strings} are triple-quoted.
    \item {\bf List Values} are comma separated.
    \item {\bf White Space} is ignored but you can indent for clarity.
    \item {\bf Continuation Lines} follow a trailing backslash.
    \item {\bf Sections}
        \begin{myitemize}
            \item nesting is determined by the number of square
        brackets around the section heading.
            \item sections are closed by the next section heading
                so within a section all top level items must be defined
                before any subsections (and similarly for lower levels
                of nesting).
        \end{myitemize}
    \item {\bf Include-files} can be multiply-included and nested. 
        Paths are specified, portably, relative to the suite definition
        directory. Inclusions can span section boundaries.
    \item  Duplicate items are allowed in environment and directives
        sections (this is good for overriding defaults held in an
        include-file).
\end{myitemize}

The following pseudo-listing illustrates the file structure:

\begin{lstlisting}
# comment
item = value # trailing comment
a string item = the quick brown fox
another string item = "the quick brown fox"
yet another string item = """the quick brown fox
jumped over the lazy dog"""
a list item = foo, bar, baz
a list item with continuation = a, b, c, \
                                d, e, f
[section]
    item = value
%include inc/vars/foo.inc  # include file
    [[subsection]]
        item = value
        [[[subsubsection]]]
            item = value
[another section]
    [[another subsection]]
        # ...
    # ...
# ...
\end{lstlisting}

\subsubsection{An Example}

A typical suite.rc file might contain the following information:
\begin{myitemize}
    \item suite title
    \item suite description
    \item a default job submission method for the suite
    \item lists of tasks with special behaviour (e.g. clock-triggered tasks)
    \item a dependency graph defining the relationships between tasks
    \item a global environment section (variables avaiable to all tasks)
    \item and for each task,
        \begin{myitemize}
            \item task description
            \item task-specific environment section (variables available to just this task)
            \item the commandline to execute when the task is ready to run
        \end{myitemize}
    \item optionally, a visualization section to configure graph plotting for the suite
\end{myitemize}

Here's an example: 

\begin{lstlisting}
# GLOBAL SETTINGS
title = suite foo

description = """Run Model on real time input data and postprocess its 
output with PostA, four times daily; twice daily do additional
postprocessing with PostB."""

job submission method = loadleveler
 
[special tasks]
    # TASKS WITH UNUSUAL BEHAVIOUR
    coldstart       = ColdModel
    sequential      = Model
    clock-triggered = GetData(1)

[dependencies]
    # THE SUITE DEPENDENCY GRAPH
    [[ 0,6,12,18 ]]  # four times daily
        graph  =  """
            GetData => Model => PostA
            ColdModel | Model(T-6) => ModelA  # model cold start or restart
                  """
    [[ 6,18 ]]  # additional postprocessing at 6 and 18 UTC
        graph = "Model => PostB" 

[environment]
    # ENVIRONMENT VARIABLES AVAILABLE TO ALL TASKS
    WORKSPACE = /$TMPDIR/$CYLC_SUITE_GROUP/$CYLC_SUITE_NAME

[tasks]
    # COMMAND AND EXECUTION ENVIRONMENT FOR EACH TASK
    [[GetData]]
        description = "retrieve data for the current cycle time"
        command = cylc wrap GetData.sh
        [[[environment]]]
            # ENVIRONMENT VARIABLES AVAILABLE TO THIS TASK
            GETDATA_OUTPUT_DIR = $WORKSPACE
    [[Model]]
        # ...
    [[PostA]]
        # ...

[visualization]
    # NODE AND EDGE PROPERTIES FOR DEPENDENCY GRAPH PLOTTING
    # ...
\end{lstlisting}

This is in fact the examples:simple suite, which you can copy, study, 
and run (it is also the example used in the {\em Quick Start Guide}
(Section~\ref{QuickStartGuide}). Dependency graphs plotted from this (by
gcylc or \lstinline=cylc graph=) are shown in
Figures~\ref{fig-simple-graph-1} and~\ref{fig-simple-graph-2}.

Subsequent sections of the user guide explain important parts of the
suite.rc file in detail. To see what else can go in a suite definition
you can study the other example suites and refer to the {\em Suite.rc
Reference} (Appendix~\ref{SuiteRCReference}).

\begin{figure}
\begin{minipage}[t]{0.5\textwidth}
    \begin{center}
        \includegraphics[width=\textwidth]{../images/screenshots/simple-6-cold.png}
    \end{center}
\end{minipage}
\hfill
\begin{minipage}[t]{0.5\textwidth}
    \begin{center}
        \includegraphics[width=\textwidth]{../images/screenshots/simple-6-warm.png}
    \end{center}
\end{minipage}
\caption[Dependency graphs for a simple example suite]{\small
Dependency graphs (cold and warm start) plotted from a simple suite.rc file.}
\label{fig-simple-graph-1}
\end{figure} 

\begin{figure}
    \begin{center}
        \includegraphics[width=0.4\textheight]{../images/screenshots/simple-18-cold.png}
    \end{center}
\caption[Three cycle cold start dependency graph for the simple example
suite]{\small Three cycle cold start dependency graph plotted by `cylc
graph' from the simple example suite.rc file, showing variation
between cycles.}
\label{fig-simple-graph-2}
\end{figure} 

\clearpage

\subsubsection{Syntax Highlighting In Vim}
\label{SyntaxHighlighting}

The file \lstinline=$CYLC_DIR/conf/cylc.vim= configures 
suite.rc syntax highlighting and section folding for the
{\em vim} editor, as shown in Figure~\ref{fig-cylc-vim}.
To use this, copy the syntax file to your
\lstinline=$HOME/.vim/syntax/= directory and make some minor
modifications, as described in the file, to your
\lstinline=$HOME/.vimrc=.

%\begin{figure}
%    \begin{center}
%        \includegraphics[width=14cm]{../images/screenshots/simple-suiterc.png}]
%    \end{center}
%    \caption[Cylc suite.rc syntax highlighting in vim]{
%    Cylc suite.rc syntax highlighting and folding in the vim editior.}
%    \label{fig-cylc-vim} 
%\end{figure} 


\subsection{Validation}
\label{Validation}

Suite validation is designed to catch most suite definition errors
before run time.  First the suite.rc file is validated
against the spec file \lstinline=$CYLC_DIR/conf/suiterc.spec=, which 
is the ultimate arbiter of what's legal in a cylc suite definition
(see Section~\ref{SuiteRCReference}). Validation detects any formatting
errors, typographic errors, illegal items, and illegal values; then some
global consistency checking is done; and finally the validator attempts
to create each suite task proxy according to information parsed from the
suite.rc file.

Here's an example of a successful validation,
\begin{lstlisting}
prompt> cylc validate examples:simple
Parsing Suite Config File
Instantiating Task Proxies:
  -  ColdModel ... OK
  -  GetData ... OK
  -  Model ... OK
  -  PostA ... OK
  -  PostB ... OK
  -  Prep ... OK
Suite examples:simple validates OK.
DONE
\end{lstlisting}

\subsubsection{Validation Errors}

The validator reports the line numbers of detected errors. 

\begin{lstlisting}
prompt> cylc validate examples:simple
Parsing Suite Config File
ERROR: [[special tasks]
NestingError('Cannot compute the section depth at line 19.',)
_validate examples:simple  failed:  1
\end{lstlisting}

If the suite.rc file contains include-files, use the 
\lstinline=cylc inline SUITE= command (or the gcylc 
right-click `Edit' option) to view an inlined copy with correct line
numbers.

\subsubsection{Validation Warnings}

Several kinds of warning are emitted by the validator, principally 
if any tasks in the dependency graph are not defined in the [tasks]
section, or if any tasks defined in the [tasks] section are not used in
the dependency graph:
\begin{lstlisting}
Parsing Suite Config File
WARNING: task "PostA" is defined only by graph: it will run as a dummy task.
WARNING: task "Prep" is defined in [tasks] but not used in the graph.
Instantiating Task Proxies:
  -  ColdModel ... OK
  -  GetData ... OK
  -  Model ... OK
  -  PostA ... OK
  -  PostB ... OK
  -  Prep ...WARNING: no hours in graph or [tasks][[Prep]]; task can be 
                      'submit'ed but not inserted into the suite.
 OK
Suite examples:simple validates OK.
DONE
\end{lstlisting}

These are not necessarily errors - a task defined by graph alone will
run as a dummy task, and you can temporarily disable a defined task by
commenting it out of the dependency graph. 

\subsection{Dependency Graphs}
\label{DependencyGraphs}
 
Dependency graphs define the relationships between tasks in a suite. 
The cylc suite.rc dependency graph notation makes textual
representations of actual graphs, but it is more concise
than the real thing because sections of the graph that repeat at
different hours of the day only have to be defined once.

Figure~\ref{fig-dep-eg-1} shows a simple example alongside its graphical
representation, plotted with,
\begin{lstlisting}
prompt> cylc graph dep:example1 2011052200 2011052206
# (or use the `Graph' right-click menu item in gcylc)
\end{lstlisting}

Incidentally, the suite.rc file listed in Figure~\ref{fig-dep-eg-1} is 
a complete valid suite definition that you can run (just import a copy
from the central suite database and run it): cylc will run dummy tasks,
which sleep for a few seconds then emit an identifying message,
because no task properties have been defined. If you do try to run
Example 1, be aware that you'll need to trigger task A manually to get
the suite started. That's because A(T) depends on its own previous
instance A(T-6), and at startup there is no previous cycle to satisfy
that prerequisite.  How to handle a {\em cold start} properly is
described below.

\begin{figure}
\begin{minipage}[b]{0.5\textwidth}
%    \lstset{basicstyle=\color{basic}\scriptsize\ttfamily}
\begin{lstlisting}
# SUITE.RC
title = "Dependency Graph Example (Ch.6)"
[dependencies]
    [[0,6,12,18]] # hours
        graph = """
A => B & C   # B and C trigger off A
A(T-6) => A  # Model A restart trigger
                """
    [[6,18]] # hours
        graph = "C => X"
[visualization]
    [[node attributes]]
        X = "color=red"
\end{lstlisting}
\end{minipage}
\hfill
\begin{minipage}[b]{0.5\textwidth}
    \begin{center}
        \includegraphics[width=\textwidth]{../images/screenshots/dep-eg-1.png}
    \end{center}
\end{minipage}
\caption{Dependency Graph Example 1.}
\label{fig-dep-eg-1}
\end{figure}

\subsubsection{Graph Syntax}

Multiline graph strings may contain:
\begin{myitemize}
    \item {\bf blank lines}
    \item {\bf arbitrary white space}
    \item {\bf task names}
    \item {\bf arrows} (\lstinline@=>@) for dependencies (triggers)
    \item {\bf comments} - follow the \# character
    \item {\bf conditional operators}: \lstinline=&= (AND) and \lstinline=|= (OR)
    \item {\bf explicit task output labels} - \lstinline=foo:fail=, \lstinline=foo:out1=
    \item {\bf cycle time offsets} - \lstinline=A(T-6)=
\end{myitemize}

Each dependent pair in a graph defines how the task on the right
depends on the task on the left {\em at cycle time T}. However,
\begin{myitemize}
    \item the ``current" cycle time T is left implicit because it is
        almost ubiquitous (the vast majority of tasks typically trigger
        off other with the same cycle time)
    \item : a task may trigger off other tasks with cycle times, but not
        later ones.\footnote{Internally cylc has no
problem with \lstinline@A(T+6) => B@, for example, but it's not
currently allowed by the graph parser.} Thus only tasks on the left
of a pair can use the offset notation, e.g.\lstinline=@A(T-6) => B@.
\end{myitemize}

\subsubsection{Partitioning The Graph}

The branching tree structure of a dependency graph can be partitioned
into lines in the suite.rc graph string in any way you like. 
Entire paths through the graph can be written as a chain of 
triggers on one line, or every trigger can go on a separate line, or 
anything in between, with liberal use of white space and 
comments to make the graph structure clear.

The only rule is that each trigger must appear once, i.e.\ the
connections between tasks, but not the tasks themselves, must be unique.

\begin{lstlisting}
# SUITE.RC
# B triggers if A succeeds, then C and D trigger if B succeeds:
    graph = "A => B => C & D"
# which is equivalent to this:
    graph = """A => B => C
            B => D"""
# and to this:
    graph = """A => B
               B => C
               B => D"""
\end{lstlisting}

\subsubsection{Task Valid Hours}

The set of hours that a particular task can run at is defined by
the hour list headings of the graph sections that the task appears
in.

\subsubsection{Time Offset Notation}

\begin{lstlisting}
# SUITE.RC
[dependencies]
    [[0,6,12,18]]
        graph = "A => B"
\end{lstlisting}

This is short for ``let \lstinline=B(T)= trigger when \lstinline=A(T)=
finishes successfully'', where T can be any task cycle time with the 
hour.  The vast majority of tasks in a suite will likely only trigger
off cotemporal (same cycle time) tasks, and when the upstream task
finishes successfully. Therefore, to make graphs as clear and concise
as possible we omit the explicit cycle time and trigger state notation
for this default behaviour. {\em In fact the explicit notation is 
not allowed at the moment.}


\subsubsection{Task Succeeded Triggers}

If an upstream task name is unqualified, the downstream task will trigger 
when it finishes (assuming it has no other triggers defined elsewhere in 
the graph, of course),

\begin{lstlisting}
# SUITE.RC
# B triggers when A FINISHES:
    graph = A => B
\end{lstlisting}

\subsubsection{Task Failed Triggers}

If an upstream task name is qualified by the suffix ``:fail'', the downstream
task will trigger when it fails,

\begin{lstlisting}
# SUITE.RC
# B triggers if A FAILS:
    graph = A:fail => B
\end{lstlisting}

This can be used for certain kinds of failure recovery.
If you don't care whether a task finishes or fails,

\begin{lstlisting}
# SUITE.RC
# B triggers once A has either SUCCEEDED or FAILED:
    graph = A | A:fail => B
\end{lstlisting}

\subsubsection{Conditional Triggers}

AND operators (\lstinline=&=) can appear on both sides of an arrow, and
provide a concise alternative to defining multiple triggers separately:
\begin{lstlisting}
# SUITE.RC
# 1/ this:
    graph = "A & B => C"
# is equivalent to:
    graph = """A => C
            B => C"""
# 2/ this:
    graph = "A => B & C"
# is equivalent to:
    graph = """A => B
            A => C"""
# 3/ and this:
    graph = "A & B => C & D"
# is equivalent to this:
    graph = """A => C
            B => C
            A => D
            B => D"""
\end{lstlisting}

OR operators (\lstinline=|=), for true ``conditional triggers'',
can only appear on the left,\footnote{An OR
operator on the right doesn't make much sense in the context of a
forecasting suite: if ``B or C'' triggers off A, what exaclty should
cylc do when A finishes?}
\begin{lstlisting}
# SUITE.RC
# C triggers when either A or B finishes:
    graph = "A | B => C"
\end{lstlisting}

\paragraph{Which Task Will Be Plotted?}

In a list of alternative triggers separated by OR operators, the 
full conditional expression determines run time behaviour, but one of
the alternatives has to be singled out in order to plot the graph: the
rightmost task is plotted by default; to change this change the task
order or attach an asterisk to the chosen task:
\begin{lstlisting}
# SUITE.RC
# this will plot as C => D:
    graph = "A | B | C => D"
# but this will plot as A => D:
    graph = "A* | B | C => D"
\end{lstlisting}

{\em In the future we plan to optionally allow all tasks in a
conditional trigger to be plotted on the same graph rather than 
singling out just one.}

% TO DO: !!!!! GRAPHING BUG FOR A | B & C EXPRESSIONS!!!!!!!!

\paragraph{Complex Conditional Triggers}

You can use AND and OR operators in the same expression, but 
{\em parenthesized conditional expressions are not allowed.}
Internally cylc handles this perfectly well because it transforms 
prerequisite conditions directly into Python code and gets the 
interpreter to evaluate the result, {\em but} the cylc-3 suite.rc graph
parser cannot handle general conditionals yet. This restriction should
not be much of an impediment though because forecasting suites tend to
have very simple conditional triggers, and you can rely on operator
precedence (AND before OR) and split large expressions into multiple
small expressions on separate lines.

\begin{lstlisting}
# SUITE.RC
# D triggers when either A or (B and C) finish:
    graph = "A | B & C => D"
\end{lstlisting}

\subsubsection{Internal Triggers}

{\em This is only needed if you want a task to trigger early off an
output that the upstream task completes before it finishes.}

\begin{lstlisting}
# SUITE.RC
[dependencies]
    [[6,18]]
        # B triggers off specific OUTPUT "out1" of task A:
        graph = A:out1 => B
[tasks]
    [[A]]
        [[[outputs]]]
            out1 = "NWP products uploaded for $(CYCLE_TIME)"
\end{lstlisting}

Task A must emit this message when the actual output has been completed,
see Section~\ref{TaskMessaging}, {\em Task Messaging}.

\subsubsection{Intercycle Triggers}

Most tasks in a typical suite will trigger off other cotemporal (same
cycle time) tasks, but some may depend on tasks with earlier cycle
times. This notably applies to warm cycled forecast models, which depend
on their own previous instances (see below); but more general intercycle
dependence is not uncommon.\footnote{In NWP forecast
analysis suites parts of the observation processing and data
assimilation subsystem will typically also depend on model background
fields generated by the previous forecast.} Here's how to express this
kind of relationship in cylc:
\begin{lstlisting}
# SUITE.RC
[dependencies]
    [[0,6,12,18]]
        # B triggers off A in the previous cycle
        graph = "A(T-6) => B"
\end{lstlisting}

This notation can be used with explicit outputs too:
\begin{lstlisting}
# SUITE.RC
    # B triggers if A in the previous cycle fails:
    graph = "A(T-6):fail => B"
\end{lstlisting}
 
\subsubsection{Satisfying Intercycle Dependencies At Startup}

Considering the intercycle dependence shown just above, between tasks A
and B, it is clear that some kind of boostrapping process will be
required to get the suite going initially, because in the very first
cycle there is no previous instance of A to satisfy B's prerequisites. 
 
\paragraph{Cold Start Tasks}

A {\em cold start task} is a special oneoff task used to satisfy the
initial previous-cycle dependence of another cotemporal task. In effect, 
the cold start task masquerades as its counterpart's previous-cycle trigger. 

A cold start task may invoke real processing (to generate the files that
are normally generated by the cycling task that it masquerades as) or it
could be a dummy task that represents some external spinup process
(resulting in the same files) that has to be completed before the suite
is started (in this case the cold start task in cylc will just report
itself successfully completed, thereby satisfying the aforementioned
dependencies).

This kind of relationship can easily be expressed with a conditional
trigger:
\begin{lstlisting}
# SUITE.RC
[special tasks]
    coldstart = ColdFoo
[dependencies]
    [[0,6,12,18]]
        graph = "ColdFoo | Bar(T-6) => Foo"
\end{lstlisting}
In other words, Foo(T) can trigger off {\em either} Bar(T-6) {\em or} 
ColdFoo(T). At startup ColdFoo will do the job, before being be eliminated 
from the suite (because coldstart tasks are non-spawning), and
thereafter Bar(T-6) will do it.

In cylc, a cold task can also be inserted into the suite at run time 
to cold start just the task it is associated with, if a problem of 
some kind prevents continued normal cycling.

\paragraph{Warm Starting A Suite}

Cold start tasks have to be declared as such in the suite.rc ``special
tasks'' section so that cylc knows they are oneoff (non-spawning) tasks,
but also because they play a critical role in warm starting cylc
suites. 

{\em Warm starting} (at a particular cycle time) a suite that has
previously been shut down is an alternative to {\em restarting} it from
a previous state. Warm starts
assume the existence of a previous cycle (i.e.\ that any files from 
the previous cycle that are required by the new cycle will be in place
already). So no cold start tasks need to run {\em but} cylc itself 
doesn't know the details of the previous cycle (if it did, it would
be restarting from a previous state, not warm starting) so it still has
to solve the bootstrapping problem to get the suite started. It does
this by starting the suite with designated cold start tasks already in
the succeeded state. In other words, the cold start tasks stand for the
previous finished cycle, rather than actually running processes that
masquerade as the previous cycle.

\subsubsection{Model Restart Dependencies}

Warm cycled forecast models generate {\em restart files}, e.g.\ model
background fields, that are required to initialize the next forecast
(this is essentially the definition of ``warm cycling''). In fact
restart files will often be written for a whole series of subsequent
cycles in case the next cycle (or the next and the next-next, and so on)
cycle has to be omitted: 
\begin{lstlisting}
# SUITE.RC
[special tasks]
    sequential = A
[dependencies]
    [[0,6,12,18]]
        # Model A cold start and restart dependencies:
        graph = """
   ColdA | A(T-6) | A(T-12) | A(T-18) | A(T-24) => A
                """
\end{lstlisting}
In other words, task A can trigger off its cold start task, {\em or} off
its own previous instance, {\em or} the instance before that, and so on.
Restart dependencies are unusual because although A {\em could}
trigger off A(T-12) we don't actually want it to do so unless A(T-6)
fails and can't be fixed. {\em This is why Task A, above, is declared to be
`sequential'}.\footnote{A warm cycling model that only writes out
one set of restart files, for the very next cycle, does not need to be
declared sequential because this early triggering problem cannot arise.}
Sequential tasks do not spawn a successor until they have
succeeded (by default, tasks spawn as soon as they start running in
order to get maximum functional parallelism in a suite) which
means that A(T+6) will not be waiting around to trigger off an older
predecessor while A(T) is still running. If A(T) fails though, the
operator can force it, on removal, to spawn A(T+6), whose restart
dependencies will then automatically be satisfied by the older instance,
A(T-6). 

Forcing a model to run sequentially means, of course, that its restart
dependencies cannot be violated anyway, so we might just ignore them.
This is certainly an option, but it should be noted that there are some 
benefits to having your suite reflect all of the real dependencies
between the tasks that it is managing, particularly for complex
multi-model operational suites in which the suite operator might not be
an expert on the models. Consider such a suite in which an unfixable
failure in a driving model (e.g.\ weather) can preclude running some
cycles of the downstream models (sea state, storm surge, river flow,
\dots). If the real restart dependencies of each model are known to the
suite, the operator can just do a recursive purge to remove the subtree
of all tasks that can never run due to the failure, and then cold start
the failed driving model after a gap (skipping as few cycles as possible
until the new cold start input data are available). After
that the downstream models will kick off automatically so long as the 
gap is spanned by their respective sets of restart files, because their
restart dependencies will automatically be satisfied by the older
pre-gap instances in the suite. Managing this kind of scenario manually
in a complex suite can be quite difficult.

Finally, if a warm cycled model is declared in `models with explicit
restart outputs', instead of `sequential' tasks, and you use explicit
labeled restart outputs {\em containing the word `restart'}, then 
the task will spawn as soon its last restart output is completed so 
that successives instances of the task will be able to overlap (i.e.\
run in parallel) if the opportunity arises. Whether or not this is worth
the effort depends on the situation, of course.

\begin{lstlisting}
# SUITE.RC
[special tasks]
    models with explicit restart outputs = A
[dependencies]
    [[0,6,12,18]]
        graph = """
  ColdA | A(T-18):res18 | A(T-12):res12| A(T-6):res6 => A
                """
[tasks]
    [[A]]
        [[[outputs]]]
            r6  = restart files completed for $(CYCLE_TIME+6)
            r12 = restart files completed for $(CYCLE_TIME+12)
            r18 = restart files completed for $(CYCLE_TIME+18)
\end{lstlisting}


\subsubsection{Task Families}

A task family is a named group of tasks that appears as a single task
in the suite dependency graph. Instead of having each individual member
task trigger off one or more upstream tasks, you can just trigger the
family; and instead of triggering downstream processing off each member task, 
you can trigger off the family as a whole.

\begin{myitemize}
    \item a family enters the `running' state when its prerequisites are
        satisfied
        \begin{myitemize}
            \item this causes each of member of the family to trigger
        \end{myitemize}
    \item a family's final state is not determined until all of its
        members have succeeded or failed:
        \begin{myitemize}
            \item succeeded, if all members succeeded
            \item failed, if one or more members failed   
        \end{myitemize}
\end{myitemize}

Cylc task families are implemented as special pseudo-tasks that do not
actually submit anything to run when they enter the `running' state.
Task proxies representing families can be seen in the suite control
GUI when a suite containing families runs. 

Cylc task families can have internal dependencies, and members can also
participate in dependent relationships outside of the family.

Task families can be declared `sequential' in the suite.rc [special
tasks] section, in which case they will will run sequentially even if
their members are not sequential.

To trigger downstream processing off a family even if one or more of its 
members failed (e.g.\ a family of obs processing tasks wherein you want
to use the obs that were successfully processed even if some members 
fail) use a conditional trigger on the family:

\begin{lstlisting}
# SUITE.RC
[dependencies]
    [[ 0,6,12,18 ]]
        graph  =  "Family | Family:fail => PostProc"
\end{lstlisting}

Task families are listed in the top level of the suite.rc file, and 
then used in the suite graph just like ordinary tasks.

\begin{lstlisting}
# SUITE.RC
[task families]
    Family = one, two, three, four
[dependencies]
    [[ 0,6,12,18 ]]
        graph  =  "PreProc => Family => PostProc"
[visualization]
    show family members = True
    default node attributes = "shape=box", "color=black"
\end{lstlisting}

This simple suite is plotted, with and without family members, in
Figure~\ref{fig-fam-eg-3}.

\begin{figure}
\begin{minipage}[t]{0.4\textwidth}
    \begin{center}
        \includegraphics[width=0.4\textwidth]{../images/screenshots/family-one.png}
    \end{center}
\end{minipage}
\hfill
\begin{minipage}[t]{0.6\textwidth}
    \begin{center}
        \includegraphics[width=0.6\textwidth]{../images/screenshots/family-two.png}
    \end{center}
\end{minipage}
\caption[A simple task family example]{\small A very small suite with
a simple task family, showing the family itself on the left, and the
effective dependencies on the right (plotted with
\lstinline@SUITE.RC: [visualization] -> show family members = True@).}
\label{fig-fam-eg-3}
\end{figure} 

\paragraph{Family Failure Recovery} 

If a family member fails it will enter the `failed' state, and once 
all members have succeeded or failed, the family itself will enter
the failed state. To recover from this, assuming it is a fixable
problem,

\begin{myenumerate}
    \item fix the problem that caused the failure
    \item reset the failed member task to the `waiting' state
    \item retrigger the family itself
\end{myenumerate}
When the family triggers, the reset member task will follow suit. If the
member completes successfully this time, so will the family,
and downstream processing will proceed as normal.

\paragraph{Use Families Sparingly}

Task families should really only be used as a convenient simplification
for groups of tasks that would naturally trigger at the same time anyway
(e.g.\ multiple tasks for processing different types of observations
that are all made available at the same time) and whose outputs would
all be put to use at a similar time too. Otherwise task families will
unnecessarily constrain cylc's ability to achieve maximum functional
parallelism, because every member has to finish before downstream
processing can continue.  As an extreme example, imagine grouping all
tasks in the same forecast cycle into a single family (cylc task
families can have internal dependencies) - this would result in enforced
whole-suite sequential cycling even when catching up from a delay.


\subsection{Task Definition}
\label{Task Definition}

A {\em task} is a single schedulable unit in a cylc suite, uniquely
identified by its name and (task-specific!) cycle time.

Although ``tasks'' stand for real external processes, or groups of
processes, they are somewhat abstract entities in that they acquire a
a name and function, through the suite definition, that is distinct from 
their implementation as a real command, script, or program.  The same 
script, for example, can implement several different tasks within the
same suite, with the function they perform in the suite context being
determined by task-specific input parameters supplied by the suite.

\subsubsection{Task Names}

Behind each task lies a real command, script, or program. (however, 
the same command, script, or program can lie behind multiple tasks
even in the same suite, according to differing task-specific input
parameters supplied.


The suite.rc file defines the set of {\em tasks} to be managed by the
suite, their individual properties, and the relationships between them.
The concept of ``task'' is something of an abstraction in that the same
command, script, or program can lie behind any number of different tasks
within the same suite, or in different suites, functioning according to
task-specific input supplied by the suite


{\em Tasks} are something of an in-suite abstraction. Whilst tasks 
are implemented by real commands, scripts, or programs, they get
their names from the suite, and the exact function they perform
depends, at least in principle, on input parameters supplied by the
suite.  To rename a task, just change
its name in the suite.rc file. Cylc's messaging commands, which
report task progress back to the parent suite, do need to know the 
name and suite of the calling task, but they automatically extract this
information from the task execution environment (which is configured by
the suite; below) so that no explicit use of task names is needed
outside of the suite.rc file. Similarly, if a task needs to make use of
its own name, or that of its parent suite, (to make I/O paths task and
suite-specific, for instance) these should be extracted from the
execution environment (below) rather than hardwired, so that the suite
is flexible and portable (see
Section~\ref{TaskAndSuiteIdentityVariables}, {\em Task And Suite
Identity Variables}).

\subsubsection{Task Commandline and Environment}
\label{TaskExecutionEnvironment}

Every task has an associated commandline to initiate the processing
that it represents. The task commandline, and the environment in which
it executes, is defined in the suite.rc file, and actioned by the 
{\em task job script} that cylc uses to invoke the task (see
Section~\ref{JobScripts}, {\em Task Job Scripts}).

\paragraph{Generic Task Scripts}

If several tasks in a suite perform a similar function, e.g.\ to
move files around, they can invoke the same command, script, or program,
with task-specific input parameters provided via the environment and/or
commandline. The cylc file transfer and file housekeeping utility
programs were designed with this in mind (see 
\lstinline=cylc util help=).

\subsubsection{Task Job Scripts (How Tasks Are Invoked By Cylc)}
\label{JobScripts}

When a task is ready to run, cylc writes, and then executes via the job
submission method specified for the task (see
Section~\ref{JobSubmission}), a {\em task job script} that configures
the environment for the task and then calls its commandline.

%In more detail, the temporary ``job script'' contains:
%\begin{myitemize}
%    \item scripting to configure the execution environment for the task
%        This includes user-defined environment variables:
%        \begin{myitemize}
%            \item global environment variables
%            \item task-specific environment variables
%            \item pre- and post-command scripting
%            \item any batch queue scheduler directives
%        \end{myitemize}
%        and cylc-defined environment variables:
%        \begin{myitemize}
%            \item to identify the task and cycle time, etc.
%            \item to portably locate the suite definition directory
%            \item for access to cylc itself
%        \end{myitemize}
%    \item scripting to call the commandline defined for the task.
%\end{myitemize}
        
Cylc writes the exact command used to submit each job script to the
suite stdout stream. The following is an excerpt from example suite
stdout, with the \lstinline=background= job submission method:

\begin{lstlisting}
# CYLC STDOUT
ColdB%2011101300  READY TO RUN
SUBMITTING TASK: /tmp/cylc-ColdB%2011101300-5gRx61 </dev/null \
    1> /home/oliverh/CylcLogs/examples/userguide/ColdB%2011101300-N3pBYv.out \
    2> /home/oliverh/CylcLogs/examples/userguide/ColdB%2011101300-N3pBYv.err &
\end{lstlisting}

You can also use \lstinline=cylc submit --dry-run= to generate a task
job script for inspection: 

\begin{lstlisting}
prompt> cylc submit --dry-run examples:userguide A%2010080806 
DRY RUN: create the job script and show how it would be executed.
  * TASK JOB SCRIPT: /tmp/cylc-A%2010080806-VXQusn
  * JOB SUBMISSION METHOD: /tmp/cylc-A%2010080806-VXQusn </dev/null \
    1> /home/oliverh/CylcLogs/examples/userguide/A%2010080806-CWYM68.out \
    2> /home/oliverh/CylcLogs/examples/userguide/A%2010080806-CWYM68.err &
\end{lstlisting}

And here is the resulting job script:

\begin{lstlisting}
prompt> cat /tmp/cylc-A%2010080806-VXQusn
#!/bin/bash

# ++++ THIS IS A CYLC TASK JOB SCRIPT ++++
# Task: A%2010080806
# To be submitted by method: 'background'

# CYLC LOCATION, SUITE LOCATION, SUITE IDENTITY:
export CYLC_DIR="/home/admin/cylc"
export CYLC_MODE="submit"
export CYLC_SUITE_HOST="oliverh-33586DL.greta.niwa.co.nz"
export CYLC_SUITE_PORT="NONE"
export CYLC_SUITE_DIR="/home/oliverh/suites/examples/userguide"
export CYLC_SUITE="examples:userguide"
export CYLC_SUITE_GROUP="examples"
export CYLC_SUITE_NAME="userguide"
export CYLC_SUITE_OWNER="oliverh"
export CYLC_USE_LOCKSERVER="True"
export CYLC_DUMMY_SLEEP="10"

# TASK IDENTITY:
export TASK_ID=A%2010080806
export TASK_NAME=A
export CYCLE_TIME=2010080806

# GLOBAL VARIABLES:
export TASK_EXE_SECONDS="10"
export WORKSPACE="/tmp/$USER/$CYLC_SUITE/common"
export RUNNING="$WORKSPACE/running"

# LOCAL VARIABLES:
export INPUT_DIR="$WORKSPACE"
export OUTPUT_DIR="$WORKSPACE"
export RUNNING_DIR="$RUNNING/A"
export OPTIONS="-w $WORKSPACE -r $RUNNING_DIR"

# ACCESS TO CYLC:
. $CYLC_DIR/environment.sh

# EXECUTE THE TASK:
cylc wrap A.sh $OPTIONS

#EOF
\end{lstlisting}

\subsubsection{Task Execution Environment}
\label{TaskExecutionEnvironment}

The following subsections explain the purpose of each part of the task
job script, and how to specify the contents thereof in the suite.rc file.
The ordering of the job script sections is,
\begin{myenumerate}
    \item  cylc location, suite location, suite identity
    \item  task identity
    \item  global variables
    \item  task-specific variables
    \item  access to cylc
    \item  global and task-specific pre-command scripting (not shown)
    \item  task commandline
    \item  global and task-specific post-command scripting (not shown)
\end{myenumerate}

{\em Note that the task identity variables are defined prior to the
global variables, so even global variables can be made task- and
cycle-specific by referencing the task identity.} 

\paragraph{Suite And Task Identity Variables}
\label{TaskAndSuiteIdentityVariables}

The first sections of the job script defines variables that identify the
task name, task cycle time, suite registration (group and name), suite
host and port, and several other parameters (see the example job script
above). Executing tasks will almost certainly need to make use of their
own cycle time,
\begin{myitemize}
    \item \lstinline=$CYCLE_TIME=
\end{myitemize}

They may also need to know the location of the suite definition
directory, to access files stored there,
\begin{myitemize}
    \item \lstinline=$CYLC_SUITE_DIR= - \lstinline=/path/to/suite/definition=
\end{myitemize}

And they may need to use the task and suite identity variables (to 
make portable suites that write all output to suite-specific locations,
for instance):
\begin{myitemize}
    \item \lstinline=$CYLC_SUITE=  - e.g.\ foo:bar
    \item \lstinline=$CYLC_SUITE_GROUP=  - foo
    \item \lstinline=$CYLC_SUITE_NAME=  - bar 
    \item \lstinline=$TASK_NAME= - X
    \item \lstinline=$TASK_ID= - X\%2011051118
\end{myitemize}

These variables are also used, automatically, by the task messaging
interface, to target the right task proxy in the particular cylc
instance that is running the task's parent suite. 

\paragraph{Global And Task-Specific Environment Variables}

Generally speaking, parameters common to several tasks should be defined
once in the global environment section of the suite.rc file; and those
needed by a single task, in the task-specific environment section.
Task-specific variables can reference global variables.

Both global and task-specific environment variables are exported in
exactly the same order that they are defined in the suite.rc file, so
you can safely refer to previously defined variables.

\begin{lstlisting}
# SUITE.RC
[environment]
    # variables available to all tasks
    suite_workspace = $TMPDIR/$CYLC_SUITE/work
[tasks]
    [[TaskX]]
        command = clean-workspace $OUTPUT_DIR 
        [[[environment]]] 
            # variables available only to TaskX
            OUTPUT_DIR = $WORKSPACE/$TASK_NAME
            # (task variables can reference global variables)
\end{lstlisting}

\paragraph{Task Access To Cylc Commands}

Executing tasks need access to the cylc task messaging commands, and
possibly to cylc utility commands. Task job scripts source the cylc
environment script to allow this:

\begin{lstlisting}
# TASK JOB SCRIPT
# CYLC LOCATION, SUITE LOCATION, SUITE IDENTITY
export CYLC_DIR=/path/to/cylc/installation
# ...snip...
# ACCESS TO CYLC
. $CYLC_DIR/environment.sh   # environment.sh uses $CYLC_DIR
\end{lstlisting}

\paragraph{On Remote Hosts}

In the job script, user (suite.rc) specified environment variables are
defined prior to sourcing the cylc environment. To provide access to
cylc on remote hosts you just need to override 
\lstinline=$CYLC_DIR= with the cylc installation path on the remote 
host, in the suite.rc task environment section. 

\begin{lstlisting}
# SUITE.RC
[tasks]
    [[foo]]
        # run this task on a remote host
        host = fitzroy.niwa.co.nz
        [[[environment]]]
            # override the cylc path:
            CYLC_DIR = /path/to/remote/cylc/installation
            # override the suite definition directory path:
            CYLC_SUITE_DIR = /path/to/remote/suite/definition
\end{lstlisting}

\paragraph{Task Access To The Suite Definition Directory}

To allow tasks to run scripts or programs in the suite bin directory
the cylc environment script automatically configures \lstinline=$PATH=
for access to \lstinline=$CYLC_SUITE_DIR/bin=. Task scripts can 
also use \lstinline=$CYLC_SUITE_DIR= to portably access any files
stored under the suite definition directory.

\paragraph{On Remote Hosts}

As for \lstinline=$CYLC_DIR=, above, if a task on a remote
host needs to access scripts in the suite bin directory, or to any files
under the suite definition directory, just override 
\lstinline=$CYLC_SUITE_DIR= with the remote suite directory location, in
the suite.rc task environment section.

\paragraph{When Are Environment Variables Evaluated?}

Environment variables are {\em not} evaluated by cylc prior to 
executing the task. They are written, in unevaluated form, to the job
script that is submitted by cylc to run the task. Thus
\lstinline=$HOME=, for instance, will evaluate, at run time, to the home
directory of the account under which the task executes (which isn't
necessarily the same account, or even the same host, that is running the
suite). 

\paragraph{Pre- and Post-command Scripting}

The global and task-specific {\em pre-command scripting} and {\em
post-command scripting} suite.rc items (not shown in the example 
job script above, because they were not defined for that task) allow
you to write arbitrary scripting in a multiline string in the suite.rc
task sections, that will be written verbatim immediately before, 
and after, the task commandline. This can be used to 
construct simple tasks that are entirely scripted within the suite.rc
file, or for the occasional bit of more complex environment manipulation
than can't easily be achieved by exporting variables alone. However, use
of this feature should be restricted to simple, fast, and reliable
scripting, because it is executed outside of the task itself (i.e.\
prior to the task started message, and after the task succeeded message).
If pre-command scripting aborts, it will appear that the task is stuck 
in the `submitted' state.  If post-command scripting fails, it will fail
unnoticed by cylc (although evidence would be left in the task stdout or
stderr logs) because the task would have reported in succeeded or failed
before the scripting ran. Anything non-trivial should really go into
the task itself. A better way of scripting simple tasks entirely in the
suite.rc file is to wrap multiple commands on the task commandline using
the cylc task wrapper (below).


\pagebreak
\section{Task Implementation}
\label{TaskImplementation}

\subsection{Task Wrapping: Using Existing Scripts As Cylc Tasks}
\label{TaskWrapping}

{\em Most pre- and post-processing scripts, models, etc., can be used 
by cylc without modification.}

Specifically, any existing script, command, or program that sees all
of the processes that it initiates through from start to finish, 
can be used as a cylc task by simply executing it through the task
wrapper, \lstinline=cylc wrap=:
\begin{lstlisting}
# SUITE.RC
[tasks]
    [[foo]]
        description = a cylc task that runs foo.sh
        command = cylc wrap foo.sh $OPTIONS $ARGS
\end{lstlisting}

The wrapped script does not need to be ``cylc-aware'' because the
wrapper knows the identity of the task it represents, and its parent
suite, through the task execution environment configured by the suite,
and it automatically reports startup; success or failure according
to the exit status of the wrapped script; and, on finishing, completion
of any specific outputs registered for the task (if other tasks just
trigger off it finishing, there will be none of these). 

To avoid scripting error checks for every mundane operation, wrapped
tasks can use \lstinline=set -e= to abort on any error, and then
rely on the cylc wrapper to report the failure to cylc:
\begin{lstlisting}
#!/bin/bash
# wrapped task script (execute with: 'cylc wrap foo.sh')

set -e  # abort on error

mkdir /illegal/dir  # illegal operation: the script will abort and
                    # the cylc wrapper will report the task failed.
\end{lstlisting}

%Appendix~\ref{AnnotatedTaskScript} provides more information on
%task scripting.

For simple tasks that don't warrant an entire script of their own, 
a series of commands can be wrapped as a single cylc task, by using 
the \lstinline=-m,--multi= option. For example, here's a simple task
that deliberately fails 30 seconds into execution:

\begin{lstlisting}
# SUITE.RC
[tasks]
    [[suicidal]]
        description = a task that kills itself after 30 seconds
        command = cylc wrap -m "sleep 30; echo Goodbye cruel world; /bin/false"
\end{lstlisting}

You can test this on the commandline:
\begin{lstlisting}
prompt> cylc wrap -m "date; sleep 30; date; echo Goodbye cruel world; /bin/false"
cylc (raw - 2011/05/13 10:33:59): TASK_ID started
Fri May 13 10:33:59 NZST 2011
Fri May 13 10:34:29 NZST 2011
Goodbye cruel world
cylc (raw - 2011/05/13 10:34:29): CRITICAL TASK_ID failed
\end{lstlisting}
(when not invoked by a suite, the messaging interface just writes to stdout).
You can also use the global and task-specific {\em pre-command
scripting} and {\em post-command scripting} suite.rc items to
construct simple tasks that are entirely scripted within the suite.rc
file (see details above).

\subsection{Non-wrapped Tasks: Modifying Scripts For Cylc}
\label{Unwrapping}

{\em Tasks with initiating scripts that do not see all processing
through from start to finish} because they detach and exit immediately
after spawning internal background or batch jobs, cannot be wrapped
because the task wrapper can't know when the task is really finished. 

{\em Tasks with internal outputs that have to be reported complete 
before the task is finished}, so that others can trigger off them
early, cannot be wrapped because the wrapper only reports outputs
complete when the task is succeeded. 

Non-wrapped tasks have to be modified slightly for cylc, by inserting 
calls to the cylc task messaging interface in appropriate places (see
the next section, {\em Task Messaging}).

\subsubsection{Task Messaging}
\label{TaskMessaging}

Once submitted, a task must,
\begin{myitemize}
    \item Report that it has started executing
    \item Report completion of any outputs that other tasks depend on
        (this is automatic if they just depend on it finishing)
    \item Report successful finish, OR
    \item Report failure in case of error
\end{myitemize}
where ``report'' is short for {\em send an appropriate message to the cylc
instance that is running my suite} (there may be multiple suites
running at once).

As noted in the previous section, {\em explicit task messaging is only
for the minority of tasks that cannot be wrapped, or those with internal
outputs that have to be reported before the task is succeeded.} 
To report startup, a script should call,
\begin{lstlisting}
# acquire a task lock and report that I've started
cylc task started
# OR
cylc started
# (the command category 'task' is optional; see 'cylc help')
\end{lstlisting}

Note the lack of any sender identification or targetting information in
the command. Task messaging commands automatically deduce the calling
task's name and cycle time, and the target suite (and its host and
port), and so on, from the execution environment supplied by the suite
(through the task job script). To report registered outputs, progress
messages, warnings, etc.,
\begin{lstlisting}
# send a warning message (it will be logged by the suite):
cylc task message -p WARNING "oops, something's fishy here"
# report an output completed:
cylc task message "foo products uploaded for $CYCLE_TIME"
# report all outputs completed at once:
cylc task message --all-outputs-completed
\end{lstlisting}
To report succeeded or failed (e.g.):
\begin{lstlisting}
if $FILES_FOUND; then
    # release my task lock and report success
    cylc task succeeded
    exit 0
else
    # release my task lock and report failed
    cylc task failed "required files are missing"
    exit 1
fi
\end{lstlisting}

\subsubsection{Detect And Report All Fatal Errors}

Cylc needs to know if a task has failed, for any reason, otherwise it
will think it is still running (although timeout alerting can be
used as a safety net here). In task scripting, therefore, the success of
any important operation should be checked explicitly so that a sensible
error message can be logged on failure, e.g.:

\begin{lstlisting}
#!/bin/bash
important.exe || {
    cylc task failed "important operation failed"
    exit 1
}
\end{lstlisting}

Non-wrapped tasks can combine this with error trapping to automatically
alert cylc on any failure:

\begin{lstlisting}
#!/bin/bash
# non-wrapped task
set -e
trap 'cylc task failed "error trapped"' ERR

cylc task started
mkdir /illegal/dir   # illegal operation: will be trapped and reported
cylc task succeeded
\end{lstlisting}

Note that if you use \lstinline=set -e= to abort on error, any explicit 
error checking must be done inline:

\begin{lstlisting}
#!/bin/bash
set -e

mkdir /illegal/dir | {  # inline error detection using OR operator
    cylc task failed "important operation failed"
    exit 1
}

mkdir /illegal/dir      # this will cause an immediate abort,
if [[ $? != 0 ]]; then  # so this line will not be reached.
    cylc task failed "important operation failed"
    exit 1
fi
\end{lstlisting}

Appendix~\ref{AnnotatedTaskScript} provides more information on
task scripting.

\subsubsection{Custom Task Wrappers}

For large scientific models with idiosyncratic native job-submission
processes that can't easily be re-engineered for the sake of simplicity
and clarity, you may need to write a custom wrapper that takes input
parameters from the environment and its commandline, and then modifies
the native scripts according to task and cycle time, and to insert cylc
messaging in the appropriate places, before invoking the (now modified)
native process. The task commandline would then just invoke the custom
wrapper.

\subsection{Propagating The Task Execution Environment}

Task processing normally executes in the configured task execution
environment, even in subprocesses because the environment is exported.
However, if a task submits an internal job to a batch queue scheduler
without passing its environment in, or if a task submits an internal
job to a remote host by some means, then you must arrange for the
relevant parts of the task execution environment to be propagated into
those jobs {\em if they need to be able to report success or failure to
cylc}. In the interests of simplicity and transparency it is best not to
let your tasks indulge in this kind of complicated subterfuge (instead,
divide the job up and have cylc submit each part of it as a distinct
task, even to remote hosts). But, like the case for less extreme custom
task wrappers, there are occasionally good reasons to hack the existing
native job scripts rather than re-engineer them properly.

So, if you have to modify a task's native job submission scripts for
this kind of situation, you can write a custom task wrapper that
inserts into the right place in the native scripts, at run time, code to
reconstruct the environment when the native scripts run, before finally
invoking the native job submission processes. Here's a rough indication
of how this might be done:

\begin{lstlisting}
#/bin/bash
# CustomFoo.sh, a custom wrapper for task foo.
# (cylc messaging and error checking not shown).
# Usage:
#---------------------------------------------
# SUITE.RC
# [tasks]
#   [[foo]]
#      command = CustomFoo.sh $OPTIONS $ARGS
#---------------------------------------------
# ...
# Copy native scripts to $NATIVESCRIPTS_DIR, on the fly, so we don't
# have to hack the orginals
# ...
# Modify native script foobar.sh:
echo "export CYCLE_TIME=$CYCLE_TIME" >> $NATIVESCRIPTS_DIR/foobar.sh 
echo "export CYLC_DIR=$CYLC_DIR" >> $NATIVESCRIPTS_DIR/foobar.sh 
# (you'll probably need more sophisticated search-and-replace 
# scripting rather than simply appending to the end of the file).
# ...
# Finally, invoke the job in its own special way:
foo.sh  # presumably this results in foobar.sh being executed ...
\end{lstlisting}

\subsection{Running Local Tasks Under Other User Accounts}

If task declares an owner other than the suite owner, and does not
declare a remote host:
\begin{lstlisting}
# SUITE.RC
owned task execution method = sudo  # or ssh
[tasks]
    [[foo]]
        owner = bob
        job submission method = loadleveler
\end{lstlisting}
cylc will attempt to execute the task, by the configured 
{\em job submission method} (e.g.\ loadleveler), as the specified owner,
using the configured {\em owned task execution method}. To use sudo 
with llsubmit (loadleveler), for example, \lstinline=/etc/sudoers= must
be configured to allow the suite owner to execute the llsubmit command
as the task owner.  For ssh, passwordless ssh must be configured between
the suite owner and task owner accounts.

\subsection{Running Tasks On A Remote Host}
\label{RunningTasksOnARemoteHost}

{\em You should not need this functionality if you have a cross-platform
resource manager, such as loadleveler, that allows you to submit a job
locally to run on the remote host}.

If a task declares a remote host and owner in its suite.rc task section,
\begin{lstlisting}
# SUITE.RC
[tasks]
    [[foo]]
        owner = bob
        host = fitzroy.niwa.co.nz
        job submission method = loadleveler
\end{lstlisting}
cylc will copy the task job script to the remote host by
\lstinline=scp=, and then run it on the remote host (using the
specified job submission method for the task) by \lstinline=ssh=. 
For this to work passwordless ssh must be configured between the
suite owner on the suite host and the task owner on the remote host.

\subsubsection{Remote Host Requirements}

Cylc (and Pyro) must be installed on the remote host, so that the remote
task can communicate with its parent suite. To give the remote task
access to the remote cylc installation just override
\lstinline=$CYLC_DIR= with the remote cylc location, in the task's
suite.rc environment section.
        
To give the remote task access to any files stored in the suite
definition directory, including scripts in the suite bin directory, just
install the suite definition on the remote host and override
\lstinline=$CYLC_SUITE_DIR= with the remote suite location, in the
task's suite.rc environment section.

\pagebreak

\section{Task Execution}
\label{JobSubmission}

{\em Task Implementaion} (Section~\ref{TaskImplementation}) describes
what requirements a command, script, or program, must fulfill in order
to function as a cylc task (preview: most existing scripts etc. can
function unmodified as cylc tasks, thanks to the {\em cylc task
wrapper}, but a few may require some minor modifications).

In this section we explain how cylc arranges for such a task to be
executed once it has determined that it is ready to run (i.e.\
that the task's prerequisites are satisfied), and how create new 
task job submission methods.

\subsection{Task Job Scripts}

When a task is ready to run, cylc generates a temporary {\em task job
script} that contains commands to configure the task execution
environment before calling the task commandline.  Cylc then 
submits the job script to run by means of the {\em job submission
method} chosen for the suite or the task. Different tasks can have
different job submission methods: set a default in the suite.rc file
(see Section~\ref{SuiteRCFile}) and override it, if necessary, for
specific tasks:
 
\begin{lstlisting}
# SUITE.RC
job submission method = loadleveler  # suite default
[tasks]
   [[foo]]
        job submission method = at_now  # just for task foo
\end{lstlisting}

\subsection{Available Methods}
\label{AvailableMethods}

\lstset{language=bash}

There are two basic methods that should be available on any platform,
sufficient for running cylc's example suites if not real forecasting
systems:

\begin{myitemize}

    \item \lstinline=background= - run tasks directly in a background shell.

     \item \lstinline=at_now= - submit tasks to the rudimentary
         \lstinline=at= scheduler (\lstinline=atd= must be running).

\end{myitemize}

Tasks in a real forecasting system should be submitted to a batch queue
scheduler or cross-platform resource manager such as {\em loadleveler}
(IBM). Methods currently available are:

\begin{myitemize} 
    
    \item \lstinline=loadleveler= - This method submits general
        (non loadleveler-specific) task scripts to loadleveler. 
        Any {\em directives} you provide in the 
        suite.rc file 
        will be written to the job script, which will then 
        be submitted to run via \lstinline=llsubmit=. 

    \item \lstinline=ll_raw= - This method submits loadleveler-ready
        scripts (i.e.\ scripts containing hardwired directives) to
        loadleveler.  This may be necessary for complex (e.g.\
        multi-step) jobs. The original script is copied to
        make the temporary job script, and cylc environment
        scripting is inserted into it immediately after the loadleveler
        directives.

    \item \lstinline=ll_ecox= - This is derived from the basic 
        \lstinline=loadleveler= method. It automatically adapts certain
        task parameters (such as owner username) to NIWA's EcoConnect
        operational environment so that the same suite definition
        can be used in distinct {\em oper}, {\em test,} and {\em devel}
        environments in which the suite and task owners, and their home
        directories, vary accordingly.

\end{myitemize}


\subsection{Whither Task stdout And stderr?}

When a task is ready to run cylc generates task-specific stdout and
stderr filenames containing the task name, cycle time, and a random
component so that rerunning the task won't overwrite the old output,
e.g.:

\begin{lstlisting}
ColdB%2011101300-N3pBYv.out
ColdB%2011101300-N3pBYv.err
\end{lstlisting}

You can set the location for these task output logs in the
suite.rc file; the default is,
\begin{lstlisting}
# SUITE.RC
job submission log directory = $HOME/CylcLogs/$CYLC_SUITE_GROUP/$CYLC_SUITE_NAME
\end{lstlisting}

How the stdout and stderr streams are directed into these files depends
on the job submission method. The \lstinline=background= method just uses
appropriate output redirection on the commandline. The
\lstinline=loadleveler= method writes appropriate directives to the job
script submitted to that is submitted to loadleveler.

Cylc obviously has no control over the stdout and stderr streams of
complex tasks that do their own internal output management (e.g.\ tasks 
that resubmit sub-jobs and direct the output thereof to other files). 
But otherwise these job logs will capture all stdout and stderr for your
tasks, and they can be viewed in real time in the suite control GUI. 

\subsection{Defining New Job Submission Methods}

Defining a new job submission method requires some minimal amount of
Python programming.  You can derive (in the sense of object oriented
programming inheritance) new methods from one of the existing ones, or
directly from cylc's job submission base class,
\begin{lstlisting}
$CYLC_DIR/src/job-submission/job_submit.py
\end{lstlisting}
using the existing methods as examples. Most often this should be
merely be a matter of defining the commandline used to execute the
aforementioned job scripts, using the provided stdout and stderr file
paths appropriately. For example, here is the entire class code for 
the \lstinline=background= method:

\lstset{language=Python}

\begin{lstlisting}
#!/usr/bin/env python

import os, re
import tempfile
from job_submit import job_submit

class background( job_submit ):
    """
Run the job script directly in a background shell. 
    """
    def construct_jobfile_submission_command( self ):
        # stdin redirection allows background execution on remote hosts
        self.command = self.jobfile_path + " </dev/null" + \
                " 1> " + self.stdout_file + " 2> " + self.stderr_file + " &"
# EOF
\end{lstlisting}

Here is the \lstinline=at_now= method:

\begin{lstlisting}
#!/usr/bin/env python

import os, re
import tempfile
from job_submit import job_submit

class at_now( job_submit ):
    """
Submit the job script to the 'at' scheduler, to run 'now'.
    """
    def construct_jobfile_submission_command( self ):
        self.command = 'at now <<EOF\n' + self.jobfile_path + \
                ' 1> ' + self.stdout_file + ' 2> ' + self.stderr_file + '\nEOF'
# EOF
\end{lstlisting}

Finally, even the \lstinline=loadleveler= method is quite simple:

\begin{lstlisting}
#!/usr/bin/env python

import os, re
import tempfile
from job_submit import job_submit

class loadleveler( job_submit ):
    """
Minimalist loadleveler job submission.
    """
    def set_directives( self ):
        self.directive_prefix = "# @ "
        self.final_directive  = "# @ queue"

        defaults = {}
        defaults[ 'job_name' ] = self.task_id
        defaults[ 'output'   ] = self.stdout_file
        defaults[ 'error'    ] = self.stderr_file

        defaults[ 'shell'    ] = '/bin/ksh'

        # in case the user wants to override the above defaults:
        for d in self.directives:
            defaults[ d ] = self.directives[ d ]
        self.directives = defaults

    def construct_jobfile_submission_command( self ):
        self.command = 'llsubmit ' + self.jobfile_path
# EOF
\end{lstlisting}

To use your new method, save it in a source file with the same name
as the job submission class (see examples above), install it in the cylc
source tree,
\begin{lstlisting}
$CYLC_DIR/src/job-submission/MyNewJobSubmitMethod.py
\end{lstlisting}
and,  in the spec file \lstinline=$CYLC_DIR/conf/suiterc.spec=, 
add its name to the list of allowed values for the 
{\em job submission method} items, at the top level and in the 
tasks section.

\pagebreak


\section{Running Suites}
\label{RunningCylcSuites}

TBD:

\begin{myitemize}
    \item cold starting, warm starting, stopping, and restarting suites.
    \item running single tasks outside or inside suites
    \item intervening in suites - stopping, removing, and inserting tasks, \dots
    \item discovery - getting information from running suites
    \item where to look for output - suite log, suite stdout/stderr, task stdout/stderr
    \item understanding cylc suite evolution, particular in catchup operation
    \item how to recover from certain kinds of failure
    \item the cylc lockserver 
    \item suite security - use of secure passphrases
    \item automatic state dump backups, named pre-intervention statedumps
    \item centralized alerting and timeouts
\end{myitemize}

For the moment, all cylc commands are comprehensively documented - see
the command reference section; all suite.rc entries are
comprehensively documented - see the suite.rc reference section; and
the gcylc help panels should explain most available functionality too.


%\subsection{Understanding Suite Evolution}
%\label{UnderstandingSuiteEvolution}
%
%On a coldstart all tasks (including oneoff tasks) in the sytem will be
%instantiated at the initial cycle time, or at the next subsequent valid
%cycle time for the task. Any tasks that have no prerequisites (and, if
%they are contact tasks, have reached their trigger time) will submit to
%run immediately. Any cycling (i.e.\ non oneoff) tasks that have no
%prerequisites (and, if they are contact tasks, have reached their
%trigger time) will rapidly spawn ahead until stopped by the suite's
%runahead limit (observe task X in the user guide example suite).
%Thereafter, each task will, of its own accord, submit to run as soon as
%its prerequisites have been satisfied by other tasks already running or
%succeeded in the suite (and trigger time etc.).  Each task spawns a
%successor at a point in its lifecycle that depends on its type: tied
%tasks spawn has soon as their restart prerequisites have been completed,
%and free tasks spawn at the instant they start running.  Once a task
%exists it is free to run as soon as its prerequisites are satisfied,
%thus successive instances of a free task can run entirely in parallel,
%and successive instances of a tied task can overlap if the opportunity
%arises (other prerequisites allowing).

%\subsection{Automatic State Dumps}
%\label{AutomaticStateDumps}
%
%Cylc updates its configured state dump file (e.g.\
%\lstinline=$HOME/cylc-state/state=) every time the task of a task
%changes. Previous states are maintained in a rolling archive 
%(length specified in the {\em suite.rc} file):
%
%\begin{lstlisting}
%nwp_oper> ls .cylc/state/SUITE/
%state       # current state
%state-1     # most recent previous state
%state-2     # next most recent previous state
%...
%state-N     # oldest state dump; will be deleted at next update
%\end{lstlisting}
%
%In addition, immediately prior to any system intervention a special
%uniquely named state dump file is created and logged, e.g.:
%
%\begin{lstlisting}
%2010/03/30 14:54:29 WARNING main - pre-purge state dump: state.2010:3:30:14:54:29
%\end{lstlisting}
%
%If you accidentally intervene wrongly in a suite, just shut it down
%and restart from the pre-intervention state dump:
%
%\begin{lstlisting}
%cylc restart SUITE state.2010:3:30:14:54:29
%\end{lstlisting}

%\subsection{Suite Log Files}
%\label{SuiteLogFiles}
%
%Earlier versions of cylc created a main suite log file and a
%task-specific log for every task. However, because when all logged
%events were made to percolate up to the main log the task-specific logs
%became superfluous. Instead, cylc provides facilities for filtering the
%main log for task-specific messages (or you can just use
%\lstinline=grep= for this purpose).
%
%\lstset{language=,
%basicstyle=\color{basic}\scriptsize\ttfamily,
%}
%\begin{lstlisting}
%$ tail $HOME/cylc-logs/userguide/log
%2010/03/28 00:33:50 INFO main.F - [2010010312] disconnected (spent; general)
%2010/03/28 00:33:52 INFO main.C - [2010010400] storm surge fields ready for 2010010400
%2010/03/28 00:33:52 INFO main.A - [2010010412] surface wind fields ready for 2010010412
%2010/03/28 00:33:52 INFO main.C - [2010010400] C%2010010400 completed
%2010/03/28 00:33:52 INFO main.C - [2010010400] C%2010010400 succeeded
%2010/03/28 00:33:52 INFO main.A - [2010010412] surface pressure field ready for 2010010412
%2010/03/28 00:33:52 INFO main.A - [2010010412] level forecast fields ready for 2010010412
%2010/03/28 00:33:53 INFO main.A - [2010010412] A%2010010412 completed
%2010/03/28 00:33:53 INFO main.A - [2010010412] A%2010010412 succeeded
%2010/03/28 00:33:53 CRITICAL main - ALL RUNNING TASKS SUCCEEDED
%\end{lstlisting}
%
%\lstset{language=,
%basicstyle=\color{basic}\footnotesize\ttfamily,
%}

%Each entry shows the time of logging, the name and cycle time of the
%reporting task (in square brackets), and the logged message.
%
%In dummy mode, the logged time is the dummy mode accelerated clock time, not 
%real time.
%
%Existing log files are automatically rotated at start up and,
%individually, when they reach a size of 10 MB.  This maximum file 
%size should be configurable, but it is currently hardwired in
%\lstinline=$CYLC_DIRsrc/pimp_my_logger.py=.

\subsection{Dummy Mode} 
\label{DummyMode}

If you start a suite in dummy mode (a command line option for the cold-,
warm-, raw-, and re-start commands, and a checkbutton in the gcylc suite
start panel) then cylc will run on an accelerated clock and submit dummy
programs instead of the real tasks. These masquerade as the real tasks
by reporting the correct outputs complete after a short interval,
reporting success, and then exiting. This is essentially
indistinguishable, to cylc, from real operation. Dummy mode was, and
remains, an important aid to cylc development because it allows
testing of every aspect of scheduling without having to run real
tasks in real time. Prior to cylc-3 it was also a useful aid to suite
development - a dummy run would quickly identify any mismatch between
the user-defined prerequisites and outputs across the suite, so you
could get the scheduling right without running the real tasks. Post
cylc-3.0 this is less important because task prerequisites and outputs
are implicitly defined by the dependency graph and, short of a bug in
cylc, the suite will run according to the graph.

\subsubsection{Clock Rate and Offset}

Dummy mode suites run on an accelerated clock so that you can test
things very quickly. You can set the clock rate and offset with respect
to the initial cycle time with options to the \lstinline=cylc coldstart=
command. An offset of 10 hours, say, means that the dummy mode clock
starts at 10 hours prior to the suite's initial cycle time.  You can
thus simulate the behaviour of the suite as it catches up from a delay
and transitions to real time operation.  By default, the clock runs at a
rate of 10 seconds real time to 1 hour suite time, and with an initial
offset of 10 hours. 

%\subsubsection{Practice Mode}
%
%Practice mode allows quick and easy testing of potentially complex
%suite interventions, with complete safety.
%
%\begin{lstlisting}
%cylc restart --practice examples:userguide
%\end{lstlisting}
%
%This will start a dummy mode clone of an existing suite from the
%current state of that suite (which may be paused, still running, or
%halted), but using different state and log files so that the original
%suite will not be corrupted by the clone.
%
%{\em At startup in practice mode, failed tasks are not reset to waiting}
%because the whole point of practice mode is to ``practice'' how to
%recover from failures.
%
%Note that other cylc commands for monitoring or interacting with the
%suite must also use the \lstinline=--practice= option in order to
%target the practice suite and not the real one. Be sure to set
%\lstinline=cylc lock= on the original suite first, to avoid
%accidentally messing with it (even if you do screw up, however, cylc's
%automatic pre-intervention state dumps will save you!).
%
%
%\subsubsection{Roll Your Own Practice Mode}
%
%A less automated way to ``practice'' on a copy of an existing suite
%that starts up from the current (or previous) state of that suite, 
%\lstinline=cylc coldstart --practice= is this:
%
%\begin{myitemize}
%    \item register your suite again under a different name. This allows
%        you to run a dummy mode copy of the same suite without
%        interfering with the original suite (it also allows you to run
%        a copy of the real mode suite without interference, but only if
%        the real suite tasks are configured to use the registered
%        suite name in all important input and output filenames and/or
%        directory paths - see {\em Command Reference} Section~\ref{register}).
%
%    \item start up the newly registered suite in dummy mode using:
%        \begin{lstlisting}
%cylc restart --dummy-mode SUITE PATH
%        \end{lstlisting}
%        where PATH is a state dump file from the original suite. The
%        absolute path is required here because the default state
%        dump location depends on the registered suite name (so that
%        different suites don't interfere with each other's state
%        dumps).
%
%\end{myitemize}
%
%\subsection{Diagnosing A Stalled Suite}
%\label{DiagnosingAStalledSuite}
%
%In certain situations a suite may appear to be ``stuck'', i.e.\ no
%tasks are running and nothing appears to be happening. There are several 
%possible reasons for this (it does not necessarily indicate a problem!):
%
%\begin{myitemize}
%    \item In {\em normal real time operation}, when all running tasks
%        have finished for the most recent cycle, nothing will happen
%        until the one or more contact tasks in the suite trigger at the
%        start of the next cycle. \lstinline=cylc show= tells if a
%        contact task has yet to reach its trigger time.
%
%    \item if every task in the suite has one or more unsatisfied
%        prerequisites, the suite will be stalled. This could happen,
%        for example, if you start a suite that contains tied (forecast
%        model) tasks without the corresponding oneoff coldstart tasks to
%        satisfy their initial restart prerequisites.
%
%\end{myitemize}
%
%The following problems will eventually cause a suite to get stuck at
%the {\em runahead limit} (which by default is 24 hours: i.e.\ the
%fastest task in the suite is only allowed to get 24 hours ahead of the
%slowest) because cylc does not automatically remove failed tasks from
%the system.  Operational suites should have automated means of
%alerting the operators to any failure that occurs, but in the
%unlikely event that the failure is not noticed until the system stalls
%at the runahead limit, then to get things moving again the operator must
%either remove the failed task or reset (and thereby rerun) it after
%fixing the problem that cause the failure.
%
%\begin{myitemize}
%    \item If the system operator, perhaps in a post-task-failure
%    intervention, kills some tasks that are required to satisfy the
%    prerequisites of other tasks that still exist in the system, then 
%    the suite will eventually stall as a result of these tasks being
%    unable to run. Solution: insert tasks (possibly oneoff cold start
%    tasks) to get the suite running again.
%
%    \item If some task in the suite has a cycling interval long than
%        the runahead limit, the suite will stall (e.g.\ if
%    you have a task that runs 24-hourly at 00Z, but set the runahead
%    limit to just 12 hours). This could also happen if you purge enough
%    cycles that the difference between the pre- and post-purge tasks
%    is greater than the runahead limit. Solution: ensure your runahead
%    limit is large enough to span these gaps.
%
%    \item If a failed task has not yet been removed or reset by the
%    system operator it will eventually stall the suite. Solution:
%    Fix, or otherwise deal with, failed tasks as quickly as possible.
%
%    \item If through a suite design error error, a task exists that
%        cannot get its prerequisites satisfied by any other task in the
%        suite, that task will never run and will eventually cause the
%        suite to stall.  Solution: test the suite in dummy mode to 
%        check that all prerequisites and outputs, suite-wide, are 
%        compatible.
%
%    \item If a misconfigured external task does not report an output
%        that it is supposed to (i.e.\ as registered in its task proxy
%        definition file), then its task proxy will not record that 
%        output as complete and cylc will set it to the 'failed' state
%        when it finishes without completing a registered output. A
%        failed task will eventually stall the suite, as explained above, 
%        if it is not fixed and re-run, or removed from the suite.
%        Solution: ensure all external tasks report their outputs
%        correctly.
%
%\end{myitemize}
%
%To confirm that the runahead limit is causing a stall, you can use 
%\lstinline=cylc verbosity= to set the debug logging level: any task
%that is not spawning a successor only because it has exceeded the
%runahead limit will report that to the log.
%
%
%\subsection{Failure Recovery Scenarios}
%\label{FailureRecoveryScenarios}
%
%\begin{myitemize}
%    \item {\em One forecast cycle runs into the next, after a delay in
%        operations}. This is never a problem for cylc; every task runs
%        as soon as it can run, regardless of forecast cycle, and any
%        task that can't run before it's predecessor has finished will
%        wait.
%
%    \item {\em A delayed parallel trial or case study catches up to real
%        time operation}. This is no problem for cylc; any cylc suite
%        will seamlessly transition in and out of ``normal real time
%        operation'' (distinct cycles triggered by the wall clock) as needed.
%
%    \item {\em An external task fails, but can be fixed}. For example, a
%        forecast model aborts trying to read a corrupted data file that
%        can be regenerated correctly. The failed task will be noted by
%        cylc, and its downstream dependants will not be able to run,
%        but other tasks will carry on as normal while you address the
%        problem. When fixed, use `cylc reset' to get the failed task to
%        run again, after which it and its downstream dependants will
%        catch up to the rest of the suite as quickly as possible.
%
%    \item {\em An important external task fails, but cannot be fixed.}
%        In this case, if the task has a lot of downstream dependants,
%        you will presumably need omit one or more cycles of the affected
%        tasks, and cold start their part of the suite at a the earliest
%        possible subsequent cycle.  To do this, insert the relevant cold
%        start task, or task group, at the later cycle, then purge the
%        failed task and everything that depends on it (and on them, and
%        so on) down to the cold start time.  Other downstream forecast
%        models will be able to pick up immediately so long their most
%        recent previous instance (i.e.\ just before the gap) wrote out
%        sufficient restart outputs to bridge the gap (otherwise they,
%        or perhaps the entire suite, will need to be cold started). 
%
%    \item {\em HELP, I attempted a drastic intervention in a complex
%        suite, using the horrifying purge command, and this time I
%        really screwed the pooch!} Before any operation that alters the
%        sytem state, cylc automatically writes out a special state dump
%        file and reports the filename in the main log. Shut the suite
%        down and restart it from its pre-intervention state (just
%        cut-and-paste the state dump filename from the main log file -
%        the file path is not required because the file will be in the
%        configured suite state dump directory).  Then {\em retry your
%        intervention in practice mode} before doing it for real!
%
%\end{myitemize}
%
%\subsection{Dead Suite Cleanup}
%%\label{DeadSuiteCleanup}
%
%\subsubsection{Normal Shutdown}
%
%Cylc waits for any currently running tasks to finish before shutting
%down cleanly. There will be nothing to clean up. 
%
%\subsubsection{Shutdown NOW or Controlled Abort}
%
%If a critical error of some kind, or use of \lstinline=cylc stop --now=,
%results in an immediate suite shutdown while there are still external
%tasks running, any subsequent cylc messaging calls made by the
%still-running tasks will fail because the parent suite no longer
%exists. Depending on the exact circumstances this may result in some 
%orphaned processes that need to be killed manually.
%
%\subsubsection{Uncontrolled Suite Abort}
%
%(To Do, check: currently no ill effects - maybe sockets (ports) remain
%tied up until they time out?).
%
%
%
%\pagebreak


\section{Advanced Topics}

TBD

\begin{myitemize}
    \item spin-up processes via temporary tasks and adding prerequisites
        on-the-fly
    \item recursive purge
    \item instant dummy mode clones of a running suite
    \item fuzzy prerequisites
    \item asynchronous tasks
    \item subsuites:
\begin{lstlisting}
[tasks]
    [[foo]]
        command = cylc wrap \"cylc run --warm SUITE $CYCLE_TIME $CYCLE_TIME\"
\end{lstlisting}
\end{myitemize}

\pagebreak

\section{Suite Design Principles And Suggestions}

Matters pertaining to simplicity, flexibility,
efficiency, and portability of cylc suites.

\subsection{Use Cylc's Cycle Time Offset Utilities}
TBD

\subsection{Make Fine-Grained Suites} 
\label{Granularity}

A suite can contain a small number of large, internally complex tasks; a
large number of small, simple tasks; or anything in between. Cylc can
easily handle a large number of tasks, however, so there are definite
advantages to fine-graining:

\begin{myitemize}
    \item a more modular and transparent suite.

    \item better functional parallelism (multiple tasks running
        at the same time).

    \item faster debugging and failure recovery: rerun just the tasks(s)
        that failed. 

    \item code reuse: similar tasks can often call the same script or
        command with differing task-specific input parameters
        (consider tasks that move files around, for example).

\end{myitemize}

\subsection{Use Include-Files For Groups Of Related Tasks}

Suite.rc include-files can be used just to help organise tasks into
convenient groups in very large suites (and with \lstinline=cylc edit= 
you can edit a temporarily inlined file to get a global view). 
But they are most useful for handling the repetitive definition of
groups of similar tasks, because the same inclusion can be used multiple
times in the same suite.rc file.  See {\em Include Files}
(Section~\ref{IncludeFiles}).


\subsection{Make Tasks Rerunnable}

It should be possible to rerun a task by simply resubmitting it for the
same cycle time. In other words, failure at any point during execution
of a task should not render a rerun impossible by corrupting the state
of some internal-use file, or whatever. It's difficult to overstate the
usefulness of being able to rerun the same task multiple times,
either outside of the suite with \lstinline=cylc submit=, or by
retriggering it within the running suite, when debugging a problem.

\subsection{Make Models Rerunnable} 

If a warm-cycled model simply overwrites its restart files in each
run, the only cycle that can subsequently run is the next one. This
is dangerous because if, accidentally or otherwise, the task runs for the
wrong cycle time, its restart files will be corrupted such that the
correct cycle can no longer run (probably necessitating a cold start).
Instead, consider organising restart files by cycle time, through a file
or directory naming convention, and keep them in a simple rolling
archive (cylc's filename templating and housekeeping
utilities can easily do this for you). Then, given availability of 
any external inputs, you can easily rerun the task for any cycle still
in the restart archive.

\subsection{Limit Previous-Instance Dependence} 

Cylc does not require that successive instances of the same task run 
sequentially. In order to task advantage of this and achieve maximum
functional parallelism whenever the opportunity arises (usually when 
catching up from a delay) you should ensure that tasks which in
principle do not depend on their own previous instances (the vast
majority of tasks in most suites, in fact) do not do so in practice. In
other words, they should be able to run as soon as their prerequisites
are satisfied regardless of whether or not their predecessors have
finished yet.  This generally just means ensuring that all file I/O
contains the generating task's cycle time in the file or directory name
so that there is no interference between successive instances. If this
is difficult to achieve in particular cases, however, you can declare
the offending tasks to be ``sequential'' (see
Section~\ref{SuiteRCReference}). 

% MAYBE SHOULD INCLUDE THE FOLLOWING HERE:
%Warm-cycled forecast models {\em do} depend on their own previous
%instances (through their ``model background'' restart prerequisites).
%These can be made to run sequentially (i.e.\ with maximal previous
%instance dependence) but you can have cylc suite launch the next model,
%assuming other prerequisites are satisfied, as soon as the previous one
%has completed its restart prerequisites (minimal previous instance
%dependence, maximal throughput).

\subsection{Put Task Cycle Time In All Output File Paths}
\label{PutCycleTimeinIO}

Having all filenames, or perhaps the names of their containing
directories, stamped with the cycle time of the generating task greatly
aids in managing suite disk usage, both for archiving and cleanup. It
also enables the previous task rerunnability recommendation by avoiding
overwrite of important files from one cycle to the next. Cylc has a
powerful utilities for cycle time offset based filename templating and
housekeeping.

\subsection{How To Manage Input/Output File Dependencies}
\label{HandlingDependencies}

Dependencies between tasks usually, though not always, take the form of
files generated by one task that are used by other tasks. There are
several ways to manage these files across a suite.

\begin{myitemize}

\item {\bf Use A Common I/O Workspace}

This may be the easiest way to run small suites: have all tasks read and
write from a common workspace.  Don't hardwire the workspace location
into the tasks; have them take it dynamically from an environment
variable defined in the suite.rc file. 

\item {\bf Add Connector Tasks To The Suite} 

If your tasks have idiosyncratic default I/O locations that are not easy
to change (this would hardly be unprecented when it comes to large
scientific models) you could leave them alone and add additional tasks
to the suite to move files around as needed (from A's output directory
to B's input directory and so on). This is not ideal either because
it could add many extra tasks to the suite.  However, it is a 
relatively minor issue that the connector tasks require knowledge of
suite context because they are very simple tasks: they can probably all
call the same generic file-transfer script or command, with differing
task-specific input parameters, and their cross-task configuration can
be confined to the suite.rc file.

\item {\bf Make The Tasks Responsible}

Perhaps the obvious solution is to configure each task with
knowledge of its role in the suite: i.e.\ to have task B know to read
its input from A's output directory, or to have A know to write its
output directly to B's input directory, and so on.  However, it is a bad
idea to hardwire this information into the real tasks - requiring some
tasks to know specific configuration details of other tasks ultimately
makes the suite less flexible.

\item {\bf Dynamic Configuration Of I/O Paths}

The best solution is probably to have all tasks take common I/O paths
from common environment variables defined once in the
suite.rc file. Tasks can thus be configured as if to run
standalone, with the knowledge of how they interact within the context of
the suite confined to the suite.rc file, and no connector
tasks have to be added to the suite. This can be implemented reasonably
easily even if the tasks involved run on different hosts (use ssh or ftp
URLs for the common I/O locations instead of local paths). 

\end{myitemize}

\subsection{Use Generic Task Scripts}

If your suite contains multiple logically distinct tasks that actually
have similar functionality (e.g.\ for moving files around, or for 
generating similar products from the output of several similar models)
have the corresponding cylc tasks all call the same command, script, or
executable - just provide different input parameters
via the commandline and/or execution environment (both defined in the
suite.rc file.


\subsection{Make Suites Portable}

If every task in a suite is configured to put its output under
`\lstinline=$HOME=' (i.e.\ the environment variable, literally, not the
explicit path to your home directory; and similarly for temporary
directories, etc.) then other users will be able to copy the suite and
run it immediately, after merely ensuring that any external input files
are in the right place.

For the ultimate in portability, construct suites in which all task I/O
paths are dynamically configured to be user and suite (registration)
specific, e.g.
\begin{lstlisting}
$HOME/output/$CYLC_SUITE_GROUP/$CYLC_SUITE_NAME/
\end{lstlisting}
(these variables are automatically exported to the task execution
environment by cylc). Then you can run multiple instances of the suite
at once (even under the same user account) without changing anything,
and they will not interfere with each other.

You can test changes to a portable suite safely by making a quick copy
of it in a temporary directory, then modifying and running the test copy 
without fear of corrupting the output directories, suite logs, and 
suite state, of the original. 


\subsection{Make Tasks As Self-Contained As Possible}

Where possible, no task should rely on the action of another task,
except for the prerequisites embodied in the suite dependency graph that
it has no choice but to depend on. If this rule is followed, your suite
will be as flexible as possible in terms of being able to run single
tasks, or subsets of the suite, whilst debugging or developing new
features.\footnote{The `cylc submit' command runs a single task exactly
as its parent suite would, in terms of both job submission method and
execution environment.}  For example, every task should create its own
output directories if they do not already exist, instead of assuming
their existence due to the action of some another task; then you will be
able to run single tasks without having to manually create output
directories first. 

\begin{lstlisting}
# manual task scripting:
  # 1/ create $OUTDIR if it doesn't already exist:
  mkdir -p $OUTDIR
  # 2/ create the parent directory of $OUTFILE if it doesn't exist:
  mkdir -p $( dirname $OUTFILE )

# OR using the cylc checkvars utility:
  # 1/ check vars are defined, and create directories if necessary:
  cylc util checkvars -c OUTDIR1 OUTDIR2 #...
  # 2/ check vars are defined, and create parent dirs if necessary:
  cylc util checkvars -p OUTFILE1 OUTFILE2 #...
\end{lstlisting}

\subsection{Make Suites As Self-Contained As Possible}

The only compulsory content of a cylc suite definition directory is the
suite.rc file (and you'll almost certainly have a suite
\lstinline=bin= sub-directory too). However, you can store whatever you
like in a suite definition directory;\footnote{If you copy a suite using
cylc commands or gcylc, the entire suite definition directory
will be copied.} other files there will be ignored by cylc but
suite tasks can access them via the
\lstinline=$CYLC_SUITE_DIR= variable that cylc automatically 
exports into the task execution environment. Disk space is cheap - if
all programs, ancillary files, control files (etc.) required by the
suite are stored in the suite
definition directory instead of having the suite reference external
build directories (etc.), you can turn the directory into a revision
control repository and be virtually assured of the ability to exactly
reproduce earlier versions as required, regardless of suite
complexity.

Note that if your suite includes remote tasks that refer to files in the
suite definition directory you'll need to copy the directory to the
remote host and, in the suite.rc task-specific environment
sections of the remote tasks, override \lstinline=$CYLC_SUITE_DIR= with
the remote path - just as for \lstinline=$CYLC_DIR= which, for remote
tasks, must point to the remote cylc installation).

\subsection{Orderly Product Generation?}
\label{OrderlyProductGeneration}

Correct scheduling is not equivalent to ``orderly generation of products
by cycle time''.  Under cylc, a product generation task will trigger as
soon as its prerequisites are satisfied (i.e.\ when its input files are
ready, generally) regardless of whether other tasks with the same cycle
time have finished or have yet to run. If your product delivery or
presentation system demands that all products for one cycle time are
uploaded (or whatever) before any from the next cycle, then be aware
that this may be quite inefficient if your suite is ever faced with
catching up from a significant delay or running over historical data.

\subsubsection{Use Of Artificial Dependencies}

If you must, you can introduce artificial dependencies into
your suite to ensure that the final products never arrive out of
sequence.  One way of doing this would be to have a final ``product
upload'' task that depends on completion of all the real product
generation tasks at the same cycle time, and then declare that final
task to be sequential so that successive instances of it cannot run out
of sequence, or in parallel, even if the opportunity arises.

\subsection{Clock-triggered Tasks Should Wait On External Data}

All tasks in a cylc suite know their own private cycle time, but most
don't care about the wall clock time - they just run when their
prerequisites are satisfied. The exception to this is {\em
clock-triggered} tasks, which wait on a wall clock time expressed as an
offset from their own cycle time, in addition to any other
prerequisites. The usual purpose of these tasks is to retrieve real time
data from the external world, triggering at roughly the expected time of
availability of the data. Triggering the task at the right time is up to
cylc, but the task itself should go into a check-and-wait loop in case
the data is delayed; only on successful detection or retrieval should
the task report success and then exit (or perhaps report failure and
then exit if the data has not arrived by some cutoff time). 

\subsection{Do Not Treat Real Time Operation As Special} 

Cylc suites, without modification, can handle real time and delayed
operation equally well.

In real time operation clock-triggered tasks (see above) constrain the
behaviour of the whole suite, or at least of all tasks situated
downstream of them in the dependency graph.

In delayed operation (due to an actual delay in an operational suite or
because you're running an historical case study) clock-triggered will 
not constrain the suite at all, and cylc's multi-cycling abilities
come to the fore, because their trigger times have already passed. 
But if a clock-triggered task happens to catch up to the wall clock, it
will automatically wait again. In this way a cylc suite naturally
transitions from delayed operation into real time operation. 

\pagebreak

\appendix
\section{Suite.rc Reference}
\label{SuiteRCReference}

This section documents all legal entries in a suite.rc file.
The information is extracted from the specification file
\lstinline=$CYLC_DIR/conf/suiterc.spec= during document processing, so
that the user guide is automatically kept up to date.  Section 
headings are generated with the same nested structure as the file itself
to make it easy to get at the documentation you need by clicking on 
hyperlinks in the PDF document contents page.

Most suites will only need a few of these settings - most items have
default values that will be sufficient, some are probably only needed
for critical operational suites (e.g.\ secure passphrases and task event
hooks), and some are primarily used for cylc development (e.g.\ dummy
mode configuration). In general your suite.rc files shouldn't be a whole
lot more complicated than those of the cylc example suites.

\subsection{Overview}

Details of suite.rc syntax are described in
Section~\ref{SuiteRCFile}. For this section it suffices to say that
every entry in the file is of the form:
\begin{lstlisting}
item = value
\end{lstlisting}
where \lstinline=item= may be a phrase containing spaces, and
\lstinline=value= may be an integer, float, boolean (True/False),
string, multiline string, or a comma-separated list of any of the
former.  suite.rc files are validated against
\lstinline=$CYLC_DIR/conf/suiterc.spec=, which defines what
items are allowed, and places constraints on what values are legal for
each item.

\input{suiterc.spec.tex}

\pagebreak

\section{Command Reference}
\label{CommandReference}

%This section is auto-generated from the self-documenting command set.
  
\lstset{ basicstyle=\color{basic}\footnotesize\ttfamily }
\lstset{language=usage}
\input{commands.tex}
\pagebreak

\pagebreak
%\pagebreak

\pagebreak

\section{An Annotated Cylc Task Script}
\label{AnnotatedTaskScript}

The following annotated cylc task script shows how to handle cylc
messaging manually. As explained in Section~\ref{Unwrapping}, {\em 
this is only required for tasks that are not overseen by a single 
script that sees all processing through from start to finish; and
tasks with internal outputs that have to be reported complete before the
task is finished so that other tasks can trigger off them early.} 
Otherwise save yourself the trouble (not that it is very difficult) and
just use the cylc task wrapper (Section~\ref{TaskWrapping}).

\lstset{language=bash}
\lstinputlisting{annotated-task-script.sh}

\pagebreak


%\pagebreak

%\section{Network Issues}
%
%Cylc can control tasks on a distributed system (multiple hosts).  If you
%do have a distributed suite, in any or all of these ways, be aware of
%the following issues: 
%
%\begin{myitemize}
%
%    \item In addition to the cylc host, cylc must be installed on all
%        task hosts; and the remote task scripts must
%        themselves be installed on their host machines.  Refer to {\em
%        Running Tasks On A Remote Host}
%        (Section~\ref{RunningTasksOnARemoteHost}) for more on this.
%
%    \item Pyro must be installed on every host used by the suite.
%         Ideally all relevant machines should have the same version of
%         Pyro, but you can easily check for Pyro cross-version
%         compatibility by attempting to run one of the cylc example
%         system.
%        
%\end{myitemize}
%
%Other notes relevant to the last point above: the \lstinline=--host=
%cylc command option defaults to Python \lstinline=socket.getfqdn()=,
%which retrieves the fully qualified domain name of the local host
%if possible.  But \lstinline=/etc/hosts= may cause this to return
%just the hostname, which locally may resolve to the local-only IP
%address that is not accessible on the network.  Short of reconfiguring
%the hosts file, you may be able to workaround these problems by:
%
%\begin{myitemize}
%
%    \item and, get cylc to configure the Pyro daemon 
%        with \lstinline@Pyro.config.PYRO_DNS_URI = True@ 
%        
%    \item and, use the \lstinline=--host= cylc command option where
%        required.
%
%\end{myitemize}

        
\subsection{Cylc Development History}
\subsubsection{Pre-3.0}

Early versions of cylc were focused on developing and testing the new 
scheduling algorithm, and the suite design interface at the time was
essentially the quickest route to that end. A suite was a collection
of ``task definition files'' that encoded the prerequisites and outputs
of each task in a direct reflection of cylc's internal task proxies. 
This way of defining suites exposed cylc's self-organising nature to the
user, and it did have some nice properties. For instance a group of
tasks could be transferred directly from one suite to another by simply
copying the taskdef files over (and checking that prerequisite and
output messages where consistent with the new suite). However, ensuring
consistency of prerequisites and outputs across a large suite could be
tedious; a few edge cases associated with suite startup and forecast
model restart dependencies were, arguably, difficult to understand; and
the global structure of a suite was not readily apparent until run time
(although to counter this cylc 2.x could generate run-time resolved
dependency graphs very quickly in dummy mode).

\subsubsection{Post-3.0}

At version 3.0 we implemented an entirely new suite design interface
that, in essence, defines the suite dependency graph and the commandline
and execution environment for each task, in a single structured,
validated, config file - the suite.rc file.  This {\em really} makes
suite structure apparent at a glance, and task prerequisites and outputs
(and some other important parameters besides) no longer need to be specified
by the user because they are implied by the graph.



\section{Pyro} 
\label{Pyro}

Pyro (Python Remote Objects) is a widely used open source objected
oriented Remote Procedure Call technology, see {\em
http://pyro.sourceforge.net}.

Earlier versions of cylc used the Pyro Nameserver to handle marshalling
of communication between client programs (tasks, commands, viewers,
etc.) and their target suites. This worked well, but in principle it
provided a route for one suite or user on the subnet to bring down 
all running suites by killing the nameserver. Consequently cylc now
uses Pyro simply as a lightweight object oriented wrapper for
direct network socket communication between client programs and their
target suites - all suites are thus entirely isolated from one another. 

%\section{Known Limitations}
%
%\begin{myitemize}
%    \item {\em The minimum cycle time granularity for a task is
%        currently one hour}.
%
%Note that this is only loosely connected to when a task actually runs,
%and then only in real time operation: clock-triggered tasks trigger at
%some interval beyond their nominal cycle time, which in real time
%operation will be at most hourly for a given task. Aside from this, tasks
%can run as soon as their prerequisites are satisfied regardless of their
%nominal cycle time. This minimum granularity could be extended to
%minutes and seconds if necessary.  
%
%    \item {\em Every task must run at least once per day} (of cycle
%        time, not real time, although the first implies the second in
%        real time operation). 
%
%This could be extended to allow less frequent tasks, e.g.\ once per
%week, if required. 
%
%\end{myitemize}

%\section{Miscellaneous Notes}
%\label{MiscellaneousNotes}
%
%%\subsection{Cycle Dependent Prerequisites}
%%It may be better to split a task into two (or more) than use this 
%%capability. NOT FOR FORECAST MODELS WITH RESTART OUTPUTS!

%\subsection{Catching Up}
%labelsubsection{CatchingUp}
%
%The state of being ``caught up'' or not is a property of individual
%tasks, not the whole suite, and additionally it should only matter to
%external contact tasks, i.e.\ those that wait on external data that is
%available at a wall clock time of T (task cycle time) + o (some offset
%insterval). Where this matters an external task can detect whether or
%not it has caught up (and signal this to its proxy object in cylc) by
%comparing its cycle time (and offset) to the wall clock time.  


\section{Acknowledgements}

Bernard Miville and Phil Andrews (NIWA), and David Matthews (Met
Office UK), for discussion, bug finding, and many suggestions that have
improved cylc's usability and functionality.

\section{GNU GENERAL PUBLIC LICENSE v3.0}
\input{gpl-3.0}

\end{document}
