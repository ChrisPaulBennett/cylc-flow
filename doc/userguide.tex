%\documentclass[11pt,a4paper]{report}
\documentclass[11pt,a4paper]{article}
%\documentclass[11pt,a4paper]{amsart}

% 1 inch margins
\usepackage{fullpage}
\usepackage{framed}
\usepackage{listings}
  \usepackage{courier}
\usepackage{amsmath}
\usepackage{verbatim}
\usepackage{graphicx}             % latex, eps
%\usepackage[pdftex]{graphicx}    % pdflatex, png, jpg, pdf
\usepackage[dvips,usenames,dvipsnames]{color}   % dvips here screws up graphicx png version, above
\usepackage[dvipdf]{hyperref}
%\usepackage{titletoc}
\usepackage{tocloft}

% prevent double digit sub-sections crowding the toc line
\addtolength\cftsubsecnumwidth{0.5em}  % see tocloft manual

\definecolor{codeblock}{rgb}{0.95,0.98,1.0}
%\definecolor{keywords}{rgb}{1.0,0.3,0.0}
\definecolor{keywords}{rgb}{1.0,0.1,1.0}
%\definecolor{comments}{rgb}{0.0,0.7,0.8}
\definecolor{comments}{rgb}{1.0,0.0,0.0}
\definecolor{identifiers}{rgb}{0.1,0.0,1.0}
\definecolor{strings}{rgb}{0.0,0.6,0.0}
\definecolor{basic}{rgb}{0.0,0.4,0.0}

\definecolor{shadecolor}{rgb}{0.9,0.9,0.1}

\lstset{
language=,
%xleftmargin=2em,
%frame=single,
backgroundcolor=\color{codeblock},
basicstyle=\color{basic}\footnotesize\ttfamily,
identifierstyle=\color{identifiers},
keywordstyle=\color{keywords},
commentstyle=\color{comments},
stringstyle=\color{strings},
showstringspaces=false,
%numbers=left,
%numberstyle=\color{Gray}
}

\lstset{
language=bash,
numbers=left,
}

\lstdefinelanguage{cylctaskdef}
{
morekeywords={NAME,DESCRIPTION,TYPE,CONTACT_DELAY,OWNER,REMOTE_HOST,CYCLES,TASK,ENVIRONMENT,COMMANDLINE,DIRECTIVES,ESTIMATED_RUN_TIME,PREREQUISITES,STARTUP_PREREQUISITES,OUTPUTS,ESTIMATED_RESTART_OUTPUT_TIMES,NO_NONCOTEMPORAL_DEPENDANTS,ONEOFF_FOLLOW_ON},
sensitive=false,
morecomment=[l]{\#},
morestring=[b]\",
numbers=left,
}

\lstdefinelanguage{usage}
{
%morekeywords={configure, register, unregister, start, pause, resume, stop, insert, reset, kill, purge, task-dump, what-is, run-task, message, set-level, nudge, monitor },
string=[b]{"},
sensitive=false,
morecomment=[l]{Usage:},
morecomment=[l]{USAGE:},
morecomment=[l]{Arguments:},
morecomment=[l]{Options:},
morecomment=[l]{Commands:},
morecomment=[l]{usage:},
morecomment=[l]{arguments:},
morecomment=[l]{command-options:},
morecomment=[l]{COMMANDS:},
morecomment=[l]{options:},
morecomment=[l]{\#}
}

\title{Cylc \linebreak 
A Self-Organising Optimal Multicycle Scheduler \linebreak 
For Complex Forecasting Systems \linebreak 
{\em \small Version THIS IS NOT A VERSIONED RELEASE} \linebreak
{\small Copyright (c) NIWA, 2008-2010} }

\author{Hilary Oliver}

\begin{document}


\maketitle

\pagebreak

\input{abstract.tex}

\pagebreak
\tableofcontents
\listoffigures
%\listoftables

\pagebreak
\section{How Cylc Works} 
\label{HowCylcWorks}

\subsection{Scheduling Forecast Systems} 
\label{SchedulingForecastSystems}

Environmental forecasting systems generate forecast products at regular
intervals using potentially large sets of scientific models and
associated data processing tasks. They are constrained by availability
of external driving data, typically real time observations and/or model
data from an external forecasting system, which one or more tasks depend
on, and these drive other ``downstream'' tasks, and so on. The
dependency diagram for a single forecast cycle in such a system 
is a {\em Directed Acyclic Graph} as shown in Figure~\ref{fig-dep-one}
(a {\em forecast cycle} is comprised
of tasks with a common {\em cycle time}, namely the nominal analysis
time or start time of the forecast models in the group). Normal real
time operation necessarily consists of a series of distinct forecast
cycles that are each initiated, after a gap in processing, by arrival of
new external driving data.

From a job scheduling perspective task execution order must be carefully
controlled in order to avoid dependency violations. Ideally, each task
should be queued for execution at the instant its last prerequisite is
satisfied; this is the best that can be done even if queued tasks are
not able to execute immediately because of resource contention.


\subsection{EcoConnect} 
\label{EcoConnect}

This work was motivated by the EcoConnect Forecasting System at NIWA
(National Institute of Water and Atmospheric Research, New Zealand). As
of 2009, EcoConnect takes real time atmospheric and stream flow
observations, and operational global weather forecasts from the Met
Office (UK), and uses these to drive global sea state and regional data
assimilating weather models, which in turn drive regional sea state,
storm surge, and catchment river models, plus tide prediction, and a
large number of associated data collection, quality control,
preprocessing, postprocessing, product generation, and archiving
tasks.\footnote{Future plans for EcoConnect include additional
deterministic regional weather forecasts and a statistical ensemble.}
The global sea state forecast runs once daily.  The regional weather
forecast runs four times daily but it supplies surface winds and
pressure to several downstream models that run only twice daily, and
precipitation accumulations to catchment river models that run on an
hourly cycle assimilating real time stream flow observations and using
the most recent available regional weather forecast.  EcoConnect runs on
heterogenous distributed hardware, including a massively parallel
supercomputer and several Linux servers. 

\subsection{Intracycle Dependencies} 
\label{IntracycleDependencies}

Because real time operation consists of a series of distinct forecast
cycles, it is natural to consider dependencies that occur between tasks
within a single forecast cycle. A sea state forecast, for example, might
depend on surface wind fields generated by a weather forecast over the
same forecast range, and a postprocessing task clearly cannot run before
its input data has been generated. Figure~\ref{fig-dep-one} shows the
dependency diagram for a single forecast cycle of a simple example
system consisting of three forecast models ({\em a, b,} and {\em c}) and
three post processing or product generation tasks ({\em d, e} and {\em
f}).  A scheduler capable of handling this must manage, within a single
forecast cycle, multiple parallel streams of execution that branch when
one task generates output for several downstream tasks, and merge when
one task takes input from several upstream tasks. 

\begin{figure}
    \begin{center}
        \includegraphics[width=6cm]{inkscape-svg/dep-one-cycle} 
    \end{center}
    \caption[Single cycle dependency graph for a simple system]{\small
    The dependency graph for a single forecast cycle of a simple example
    system. Tasks {\em a, b,} and {\em c} represent forecast models,
    {\em d, e} and {\em f} are post processing or product generation
    tasks, and {\em x} represents external data that the upstream
    forecast model depends on.}
    \label{fig-dep-one} 
\end{figure} 

\begin{figure}
    \begin{center}
        \includegraphics[width=8cm]{inkscape-svg/timeline-one}
    \end{center}
    \caption[Single cycle job schedules for real time operation]{\small
    The optimal job schedule for two consecutive cycles of our example
    system during real time operation, assuming that all tasks trigger 
    off upstream tasks finishing completely. The horizontal extent of
    a task bar represents its execution time, and the vertical blue
    lines show when the external driving data becomes available.}
    \label{fig-time-one}
\end{figure}

Figure~\ref{fig-time-one} shows the optimal job schedule for two
consecutive cycles of the example system in real time operation, given
execution times represented by the horizontal extent of the task bars.
There is a time gap between cycles as the system waits on new external
driving data.  Each task in the example system happens to trigger off
upstream tasks {\em finishing}, rather than off any intermediate output
or event; this is merely a simplification that makes for clearer diagrams.

\begin{figure}
    \begin{center}
        \includegraphics[width=10cm]{inkscape-svg/dep-two-cycles-linked} 
    \end{center}
    \caption[What if the external data is available early?]{\small If
    the external driving data is available in advance, can we start
    running the next cycle early?} 
    \label{fig-dep-two-linked}
\end{figure}

\begin{figure}
    \begin{center}
        \includegraphics[width=6cm]{inkscape-svg/timeline-one-c} 
    \end{center}
    \caption[Attempted overlap of consective single-cycle job
    schedules]{\small A naive attempt to overlap two consecutive cycles
    using the single-cycle dependency graph. The red shaded tasks will
    fail because of dependency violations (or will not be able to run
    because of upstream dependency violations).} 
    \label{fig-overlap}
\end{figure} 

\begin{figure}
    \begin{center}
        \includegraphics[width=8cm]{inkscape-svg/timeline-one-a} 
    \end{center}
    \caption[The only safe multicycle job schedule?]{\small The best that
    can be done {\em in general} when intercycle dependencies are
    ignored.} 
    \label{fig-job-no-overlap}
\end{figure} 

Now the question arises, what happens if the external driving data for
upcoming cycles is available in advance, as it would be after a
significant delay in operations, or when running a historical case
study?  The forecast model {\em a} depends only on the external data
and, implicitly at this stage of the discussion, on its own previous
instance for a model ``background state''. Thus, as alluded to in
Figure~\ref{fig-dep-two-linked}, task {\em a} could in principle start
immediately its predecessor has finished.  Figure~\ref{fig-overlap}
shows, however, that starting a whole new cycle at this point is
dangerous - it results in dependency violations in half of the tasks in
the simple example system. In fact the situation is even worse than this
- what if task {\em b} in the first cycle is delayed for any reason {\em
after} the second cycle has been launched? Clearly we must consider
handling intercycle dependencies explicitly in order to solve this
problem, or else agree never to start the next cycle early, as
is illustrated in Figure~\ref{fig-job-no-overlap}.


\subsection{Intercycle Dependencies} 
\label{IntercycleDependencies}

In any non-trivial system dependencies between tasks in different cycles
exist. Forecast models typically depend on their own most recent
previous forecast for an initial ``background state'', and different
types of tasks in different forecast cycles can also be linked (e.g.\
the complicated relationship between the weather and river models in
EcoConnect). In real time operation these intercycle dependencies
can be ignored because they are automatically satisfied when each cycle
necessarily finishes before the next one begins. This is just as well
because they dramatically increase the complexity of the dependency
graph of even the simplest systems, by destroying the clean boundary
between forecast cycles. Figure~\ref{fig-dep-multi} illustrates the
problem for our simple example system assuming the minimal likely
intercycle dependence: the forecast models ($a$, $b$, and $c$) each
depend on their own previous instances.

For this reason, and because we tend to imagine that forecasting systems
always run in distinct cycles, existing schedulers (as far as the author
is aware!) ignore intercycle dependencies and therefore {\em require} a
series of distinct cycles at all times. While this does not affect
normal real time operation it can be a serious impediment when advance
availability of external driving data makes it possible, in principle,
to run some tasks from upcoming cycles before the current cycle is
finished - as suggested at the end of the previous section. This occurs
after delays (late arrival of external data, system maintenance, etc.)
and, to an even greater extent, in historical case studies, and parallel
test systems that are delayed with respect to the main operation. It is
a serious problem, in particular, for systems that have little downtime
between forecast cycles and therefore take many cycles to catch up
after a delay. Without taking account of intercycle dependencies, the
best that can be done, in general, is to reduce the gap between cycles
to zero as shown in Figure~\ref{fig-job-no-overlap}. A limited crude
overlap of the single cycle job schedule may be possible for specific
task sets but the allowable overlap may change if new tasks are added,
and it is still dangerous: it amounts to running different parts of a
dependant system as if they were not dependant and as such it cannot be
guaranteed that any unforeseen delay occuring in one cycle after the 
next has begun (e.g.\ due to resource contention or task failures) won't
result in dependency violations in the next.

\begin{figure}
    \begin{center}
        \includegraphics[width=8cm]{inkscape-svg/dep-multi-cycle} 
    \end{center}
    \caption[Complete multicycle dependency graph]{\small The complete
    dependency graph for the example system, assuming the least possible
    intercycle dependence: the forecast models ($a$, $b$, and $c$)
    depend on their own previous instances. The dashed arrows show
    connections to previous and subsequent forecast cycles.} 
    \label{fig-dep-multi}
\end{figure}

\begin{figure}
    \begin{center}
        \includegraphics[width=6cm]{inkscape-svg/timeline-two-cycles-optimal} 
    \end{center}
    \caption[Optimal two-cycle job schedule]{\small Optimal two cycle
    job schedule when the next cycle's driving data is available in
    advance, possible in principle when intercycle dependencies are
    handled explicitly.} 
    \label{fig-optimal-two}
\end{figure} 

Figure~\ref{fig-optimal-two} shows, in contrast to
Figure~\ref{fig-overlap}, the optimal two cycle job schedule obtained by
respecting all intercycle dependencies. It must be noted, however, that
this job schedule assumes ideal conditions with no delays due to
resource contention or anything else - i.e.\ every task is able to run
in its alotted time as soon as it is ready to run. The scheduler running
this system must be able to adapt dynamically to external conditions 
that impact on multicycle scheduling in the presence of
intercycle dependencies or else, again, risk bringing the system down
with dependency violations.

\begin{figure}
    \begin{center}
        \includegraphics[width=12cm]{inkscape-svg/timeline-three} 
    \end{center}
    \caption[Post delay comparison of job schedules]{\small Job
    schedules for the example system after a delay of almost one whole
    forecast cycle, when intercycle dependencies are
    taken into account (above the time axis), and when they are not
    (below the time axis). The colored lines indicate the time that
    each cycle is delayed, and normal ``caught up'' cycles
    are shaded gray.} 
    \label{fig-time-three}
\end{figure} 

\begin{figure}
    \begin{center} 
        \includegraphics[width=8cm]{inkscape-svg/timeline-two}
    \end{center} 
    \caption[Optimal job schedule when all external data is
    available]{\small Job schedules for the example system in case study
    mode, or after a long delay, when the external driving data are
    available many cycles in advance. Above the time axis is the optimal
    schedule obtained when the system is constrained only by its true
    dependencies, as in Figure \ref{fig-dep-two-linked}, and underneath
    is the best that can be done, in general, when intercycle
    dependencies are ignored.} 
    \label{fig-time-two}
\end{figure} 

To further illustrate the potential benefits of proper intercycle
dependency handling, Figure~\ref{fig-time-three} shows an operational
delay of almost one whole cycle in a system with little downtime between
cycles. Above the time axis is the optimal schedule that is possible, in
principle, when intercycle dependencies are taken into account, and
below is the only safe schedule possible {\em in general} when they are
ignored.  In the former case, even the cycle immediately after the delay
is hardly affected, and subsequent cycles are all on time, whilst in the
latter case it takes five full cycles to catch up to normal real time
operation.
%Note that simply overlapping the single cycle schedules of
%Figure~\ref{fig-time-one} from the same start point would have resulted
%in dependency violation by task {\em c}.

Similarly, Figure~\ref{fig-time-two} shows example system job schedules
for an historical case study, or when catching up after a very long
delay; i.e.\ when the external driving data are available many cycles in
advance.  Task {\em a}, which as the most upstream forecast model is
likely to be a resource intensive atmosphere or ocean model, has no
upstream dependence on cotemporal tasks and can therefore run
continuously, regardless of how much downstream processing is yet to be
completed in its own, or any previous, forecast cycle (actually, task
{\em a} does depend on cotemporal task {\em x} which waits on the
external driving data, but that returns immediately when the external
data is available in advance, so the result stands). The other forecast
models can also cycle continuously or with short gap between, and some
post processing tasks, which have no previous-instance dependence, can
run continuously or even overlap (e.g.\ {\em e} in this case). Thus,
even for this very simple example system, tasks from three or four
different cycles can in principle run simultaneously at any given time. 
In fact, if our tasks are able to trigger off internal outputs of 
upstream tasks, rather than waiting on full completion, successive
instances of the forecast models could overlap as well (because model
restart outputs are generally be completed early in the forecast) for an
even more efficient job schedule. 

Finally, we note again that a good job scheduler should be able to
dynamically adapt to delays in any part of the system due to resource
contention, varying run times, or anything else that will inevitably
modify the depicted job schedules. 

\subsection{The Cylc Scheduling Algorithm} 
\label{TheCylcSchedulingAlgorithm}

\begin{figure}
    \begin{center} 
        \includegraphics[width=8cm]{inkscape-svg/task-pool}
    \end{center} 
    \caption[The cylc task pool]{\small How cylc sees the task pool, in
    contrast to the full dependency diagram of Figure~\ref{fig-dep-two-linked}.} 
    \label{fig-task-pool}
\end{figure} 

This section explains how cylc achieves the optimal multicycle
scheduling described above. 

Cylc manages a pool of proxy objects that represent real tasks in the
forecasting system. A task proxy object can run the real task when its
prerequisites are satisfied, and can receive reports of completed
outputs from the real task as it runs. There is no global cycling
mechanism to advance the system in time; instead each individual task
proxy has a private cycle time and spawns its own successor at the right
time (which depends only on the task's own type and state). Task proxies
are self-contained and do not know what other tasks exist in the system,
they just know their own prerequisites and outputs.  Prerequisites can
equally represent intra- and intercycle dependencies, and the task pool
can be populated with tasks having many different cycles. Now,
whenever any task proxy changes state (as a result of an output
completion message, for example) cylc gets the entire pool to interact
indiscriminately, {\em regardless of cycle times}, in an attempt to
match unsatisfied prerequisites with completed outputs.\footnote{In fact
this dependency negotiation goes through a middleman or broker object,
which reduces the interaction scaling from $n^2$ to $n$, where $n$ is
the number of task proxies.} 

Thus without using global cycling mechanisms, and treating all
dependencies equally, cylc in effect gets a set of individual tasks to
self-organise by negotiating their own dependencies: optimal scheduling,
as illustrated in the previous section, emerges naturally at run time.

In addition, cylc makes no distinction between delayed and real time
operation. In delayed operation the tasks that gather the system's
external driving data will return immediately (because the data is
already available) and the system will only be constrained by its
internal dependencies. In real time operation, the data gathering tasks
will return only when the external data becomes available (normally at
some known time interval after the task's nominal cycle time), delaying
downstream tasks until then, by which time the previous forecast cycle
will have completed. A cylc system thus transitions seamlessly from
optimal multicycle scheduling to ``normal'' distinct forecast cycles as
it catches up to real time operation.

Note that in addition to achieving optimal scheduling, this algorithm is
extremely simple. The operator does not have to construct a special
``suite'' in which order of execution or explicit dependency
relationships are specified (except implicitly, in that each task's
prerequisites must be matched by someone's outputs). Instead the entire
forecasting system is defined by a simple list of tasks each of which,
in effect, thinks it is alone in the world (even a standalone task must
know its own prerequisites and outputs).

%\footnote{However, you can still use explicit task dependence if you
%wish: just make a task depend on an explicitly named upstream supplier
%{\em finishing} rather than on the upstream output that is the actual
%prerequisite of interest. However, framing prerequisites in terms of
%required input filenames, or similar, results in a more flexible
%system: tasks can easily be ``hot replaced'' by others that generate
%similar outputs.}

Perhaps the most difficult problem encountered during cylc
implementation was how to arrange that every task proxy object exists by
the time it is needed, but not too much earlier, and does not die too
long after it is no longer needed. This engendered no small amount
of hair pulling and teeth gnashing, but once achieved the complexities
therein are entirely hidden from the user.

%In other words the task pool must include waiting tasks whose
%prerequisites may {\em soon} be satisfied (but preferably no waiting
%tasks whose prerequisites will not be satisfied for some time yet),
%tasks that are currently running, and finished tasks whose outputs
%could still be needed by any current or future waiting task (but
%preferably not any finished tasks whose output will no longer be needed
%by anyone). 



\pagebreak
\section{The Cylc Command Set}

The complete cylc command set is listed below, autogenerated by 
\lstinline=cylc help=. Subsequent sections of the userguide
explain how to use cylc, and the full {\em Command Reference} 
is given in Section~\ref{CommandReference}.

\lstset{language=usage}
\lstinputlisting{command-usage/help.txt}

\pagebreak
\section{Installation And Testing} 
\label{InstallationAndTesting}

\subsection{Requirements} 
\label{Requirements}

\begin{itemize}
    \item Unix or Linux
    \item Python
    \item Pyro (Python Remote Objects)
\end{itemize}

Cylc has been tested with Python~2.6, and Pyro~3.9 and 3.10,
but it should work with any recent versions of Python~2 and Pyro.
As yet neither cylc nor Pyro are compatible with Python~3. 

\subsection{Getting Cylc} 
\label{GettingCylc}

See Appendix~\ref{Pyro} for Pyro download directions.

Cylc is currently maintained using {\em darcs} (http://darcs.net), a
distributed revision control system. If you need to develop cylc you can
request access to clone the central repository, otherwise you will
receive a cylc release tarball. 

\subsection{Installation} 
\label{Installation}

Pyro installs easily into the standard Python modules path on your
system; follow Pyro's own installation instructions.

Cylc is designed to be installed into a normal user account: simply
unpack the tarball, or move the repository, to the location of your
choice. There is no ``build'' required because cylc is written in Python
(plus a few small bash scripts).

\subsection{Environment} 
\label{Environment}

\lstset{language=bash} 

The cylc bin directory must be in your executable search path, to
provide access to cylc commands, and the cylc source directory must be
in your Python module search path, to provide access to the cylc core
modules. To configure your current command shell for cylc, source 
the environment script \lstinline=cylc-env.sh= from the directory it
resides in (i.e.\ the top level of your cylc installation):

\begin{lstlisting}
$ . cylc-env.sh
\end{lstlisting}

Or for automatic access, put the following in your (sh-style) login
script:

\begin{lstlisting}
# CYLC
export CYLC_DIR=$HOME/cylc  # (the install location)
. $CYLC_DIR/cylc-env.sh
\end{lstlisting}


\subsection{Testing} 
\label{Testing}

Test the new installation by running the packaged ``userguide'' example
system, and compare the results with the scheduling diagrams in
Section~\ref{TheCylcSchedulingAlgorithm}. The packaged examples should
work ``out of the box'' in real and dummy mode, using the simple
sequence of commands presented in the Quick Start Guide, from {\em
Prepare For Scheduling} (Section~\ref{QuickPreparingForScheduling})
onward.  For detailed information on the example systems refer
to {\em A Complete Working Example}
(Section~\ref{ACompleteWorkingExample}), and {\em Other Working Examples} 
(Section~\ref{OtherWorkingExamples}).  

\pagebreak
\section{Quick Start Guide} 
\label{QuickStartGuide}

\lstset{language=bash}

This section is intended as a quick introduction to, or reminder of,
basic cylc functionality. The specific command line listings below use
the packaged cylc ``userguide'' example system. Refer to 
\lstinline=cylc help=, the {\em Command Reference}
(Section~\ref{CommandReference}), and
upcoming sections of this document for more detailed information on
available commands, options, and operations.  {\em A Complete Working
Example} (Section~\ref{ACompleteWorkingExample}) describes the
userguide example system in detail.

\subsection{Starting A Pyro Nameserver}
\label{QuickStartingAPyroNameserver}

Pyro (Appendix~\ref{Pyro}) is the object oriented Python RPC framework
that allows system tasks to communicate with their proxy objects inside
a cylc scheduler. First check to see if there is already a Pyro
nameserver (\lstinline=pyro-ns=) running on your network segment:

\begin{lstlisting}
# search for a Pyro nameserver on the network
$ pyro-nsc ping
Locator: searching Pyro Name Server...
Locator: retry 1
Locator: searching Pyro Name Server...
Locator: retry 1
Trying host oliverh-33191VL
Locator: contacting Pyro Name Server...
NS is at 127.0.0.2 (oliverh-33191VL.greta.niwa.co.nz) port 9090
NS is up and running!

# search for a Pyro nameserver on a specific host
$ pyro-nsc -h localhost ping
Locator: contacting Pyro Name Server...
NS is at 127.0.0.1 (localhost) port 9090
NS is up and running!
\end{lstlisting}

If not, start one up as follows:

\begin{lstlisting}
# start a Pyro nameserver
$ pyro-ns
*** Pyro Name Server ***
Name server listening on: ('0.0.0.0', 9090)
Broadcast server listening on: ('255.255.255.255', 9090)
URI is: PYRO://192.168.56.146:9090/c0a838921e021d8a88b563c085c323e5f4
URI written to: /home/oliverh/Pyro_NS_URI
Name Server started.
\end{lstlisting}

Note that you can start the nameserver with the \lstinline=nohup=
command (\lstinline=man nohup=) to prevent it dying when you log out of
your terminal session.

\subsection{Defining A Task Set} 
\label{QuickDefiningATaskSet}

Before you can run a forecast system with cylc, you need to define the
interface between the scheduler and your real system tasks.  This
is covered in detail in {\em System Definition}
(Section~\ref{SystemDefinition}), but in summary it requires:

\begin{itemize}
    \item defining {\em prerequisites} and {\em outputs} for each task,
        and encoding these in a simple {\em task definition file} for
        each task.

    \item ensuring that each task reports its outputs using cylc's
        messaging mechanism.  This may involve writing new {\em task
        scripts}, or slightly modifying existing task execution scripts,
        or using cylc's automatic {\em task wrapping} mechanism
        (Section~\ref{TaskWrapping}) to run unmodified existing tasks.
\end{itemize}


\subsection{Preparing For Scheduling}
\label{QuickPreparingForScheduling}

\subsubsection{System Configuration}
\label{QuickConfiguration}

The configuration process generates
system-specific Python modules in the {\em system definition directory}
(Section~\ref{SystemDefinition}). This
must be done initially, and thereafter whenever the system's task
definition files have been changed:

\begin{lstlisting}
cylc configure $CYLC_DIR/systems/userguide
\end{lstlisting}

\subsubsection{System Registration}
\label{QuickSystemRegistration}

Registration associates a name with a configured system, for a
particular user. This is required in order to {\em run} a system but you
can monitor or otherwise interact with running systems that have been
registered and started up by other users.

\begin{lstlisting}
cylc register --system=$CYLC_DIR/systems/userguide userguide 
\end{lstlisting}

To see your current system registrations, use 
\lstinline=cylc register --print=.

\subsection{Starting The Scheduler}
\label{QuickStartingTheScheduler}

To begin scheduling a registered system (see {\em Running Cylc Systems},
Section~\ref{RunningCylcSystems}):

\begin{lstlisting}
cylc start --at=2009082312 userguide
\end{lstlisting}

In real mode (as opposed to {\em dummy mode}, Section~\ref{DummyMode})
{\em do not choose a start time in the future}, or nothing will happen
until the start time comes up!

You can run multiple systems at once, even multiple instances of the
same system (so long as it is registered under multiple names, and the
external tasks are configured to use the registered name in all input
and output file paths, etc.; the userguide example system is capable of
this). 

\subsection{Following System Progress}
\label{QuickFollowingSystemProgress}

\subsubsection{System Monitors}
\label{QuickSystemMonitors}

\begin{figure}
    \begin{center}
        \includegraphics[width=8cm]{monitor-1} 
    \end{center}
    \caption{\small The main terminal-based cylc system monitor}
    \label{fig-monitor} 
\end{figure} 

\begin{figure}
    \begin{center}
        \includegraphics[width=10cm]{monitor-2} 
    \end{center}
    \caption{\small Another terminal-based cylc system monitor}
    \label{fig-monitor-r} 
\end{figure} 


Cylc currently includes two terminal-based monitors, which are effective
but somewhat primitive.  The standard monitor (Figure~\ref{fig-monitor})
shows the current state of all task proxy objects in the task pool:

\begin{lstlisting}
# in a new terminal!
cylc monitor --align userguide
\end{lstlisting}

The \lstinline=--align= option causes tasks to be displayed in columns
(which is only useful for small systems in which all task names can fit
on a single line).  Another system monitor (Figure~\ref{fig-monitor-r})
shows the progress of just the running tasks in the pool:

\begin{lstlisting}
# in a new terminal!
cylc monitor-r userguide
\end{lstlisting}

Section~\ref{SystemMonitors} discusses the limitations of the
current system monitors, and plans for future development.

\subsubsection{System Log Files}
\label{QuickSystemLogFiles}

You can also follow progress by viewing (e.g.\ with 
\lstinline=tail -F FILE=) the {\em System Log Files},
Section~\ref{SystemLogFiles}. By
default these are located under \lstinline=$HOME/cylc-logs/SYSTEM-NAME=.
Each task has its own log file for task-specific events and the
\lstinline=main= log file records all events in sequence.


\pagebreak
\lstset{language=}
\subsubsection{Getting Task State Information}
\label{QuickGettingTaskStateInformation}

To display the current state of a particular task (choose one that
currently exists in the system, according to the monitor):

\begin{lstlisting}
% cylc task-dump -t X%2010010112 userguide
_______________________________
Task X%2010010112 in userguide:
 + => prerequisite satisfied, or output completed
 - => prerequisite NOT satisfied, or output NOT completed
______________
Prerequisites:
(None)
________
Outputs:
 + X%2010010112 completed
 + X%2010010112 finished
 + X%2010010112 started
 + obs data ready for 2010010112
______
Other:
delayed start time reached ... True
\end{lstlisting}

\lstset{language=bash}
\subsection{Shutting A System Down}
\label{QuickShuttingASystemDown}

\lstset{language=bash}

Before shutting a system down - or indeed using any of the other cylc
commands that can change the state of a running system but are not 
covered in this Quick Start Guide (reset, kill, purge, pause, etc.) -
you need to unlock the system:

\begin{lstlisting}
# unlock:
cylc unlock userguide
# shutdown:
cylc stop userguide
\end{lstlisting}

\subsection{Restarting A System}
\label{QuickRestartingASystem}

You can restart a system from a previous state:

\begin{lstlisting}
cylc start --restart userguide
\end{lstlisting}

Cylc automatically dumps extra time-stamped state files prior to any
system intervention, so that if necessary you can easily restart the
system in its pre-intervention state.  See {\em Restarts}
(Section~\ref{Restarts}) for more information.


\pagebreak
\section{System Definition} 
\label{SystemDefinition}

%Cylc sees a forecasting system as an evolving, self-organising pool of
%tasks with clearly defined {\em prerequisites} and {\em outputs}, as
%explained in {\em The Cylc Scheduling Algorithm} (Section~\ref{TheCylcSchedulingAlgorithm}). 

Your system must be divided into tasks with clearly defined
prerequisites and outputs (Section~\ref{TaskPrerequisitesAndOutputs}). Then
the properties of each task that are relevant to scheduling must be
declared in {\em Task Definition Files}
(Section~\ref{TaskDefinitionFiles}). One such property is the script or
executable that should be called to run the real task when
it is ready to run. These {\em Task Scripts} (Section~\ref{TaskScripts})
can be located anywhere, but if you are creating a new system you may
wish to keep them in a central location along with the system task
definition files.  By convention, but not necessarily, {\em cylc system
definition directories} reside under \lstinline=$CYLC_DIR/systems=, for
example:

\lstset{language=bash}

\begin{lstlisting}
# system userguide:
$CYLC_DIR/systems/userguide/

   task_classes.py     # AUTOGENERATED by `cylc configure' 
   task_list.py        # AUTOGENERATED by `cylc configure' 
   system_config.py    # autogenerated once by `cylc configure' (customizable)
   system_info.py      # autogenerated once by `cylc configure' (customizable)
   job_submit.py       # autogenerated once by `cylc configure' (customizable)

   taskdef/            # TASK DEFINITION FILES, e.g.:
      A.def              # defines task A
      B.def              # defines task B
      #...

   scripts/            # TASK SCRIPTS (if external tasks not called directly):
      A.sh               # called by cylc to execute task A
      B.sh               # called by cylc to execute task B
      #...
\end{lstlisting}

Several example systems are maintained in the cylc source repository.
External systems should be maintained elsewhere in their own version
control repositories, with tags to indicate compatibility with
particular versions of cylc.

\subsection{Granularity} 
\label{Granularity}

A system can contain a small number of large, internally complex tasks;
a large number of small, simple tasks; or anything in between. However,
cylc can easily handle large task numbers, and is entirely self
organising, so there are advantages fine-graining a system:

\begin{itemize}
    \item a more modular and transparent system.

    \item better functional parallelism: multiple processes running
        at the same time.

    \item faster failure recovery: rerun just the tasks(s) that failed. 

    \item the same external task script (e.g.\ for moving files around)
        can often be invoked, with different arguments, for multiple
        tasks.

\end{itemize}





\subsection{External Task Requirements} 
\label{ExternalTaskRequirements}

\subsubsection{Restartability}

It should be possible to restart a failed task (after fixing the
problem) by simply resubmitting it for the same cycle time. In other
words, failure at any point during task execution should not render a
restart impossible by corrupting the state of some internal-use files,
or similar. 

\subsubsection{Previous Instance Dependence} 

A task that in principle does not depend on a previous instance of
itself (i.e.\ on the same task at a previous cycle time) should be able
to run as soon as its prerequisites are satisfied, even if one or more
of its predecessors has not finished (or even started) yet.  Post
processing tasks are typically of this type - they should be able to run
as soon as the files they process exist, regardless of whether or not
the processing of files from any previous cycles has occurred yet.

Similarly, a warm-cycled forecast model, which depends on a previous
instance via its restart prerequisites, should be able to run as soon as
its prerequisites (including the restart ones) are satisfied.

If this is not the case in practice, perhaps because of the task in
question makes use of a temporary workspace that is not labelled by
cycle time, then cylc's sequential task type modifier see {\em Task
Types} (Section~\ref{TaskTypes}) can easily force sequential execution
of particular tasks, but the resulting system will be somewhat less
efficient than it could be.

\subsubsection{Multicycle Restartability} 

A warm-cycled forecast model's restart files, which are written in
one cycle and read in the next, should not simply be overwritten with
each new run. Otherwise these files could be corrupted if the task is
accidentally invoked at the wrong cycle time, thereby breaking the task
for the correct cycle (and a cold start will subsequently be required).
Instead, consider organising restart files by cycle time, through a file
or directory naming convention, and keep them in a simple cycle-time
based rolling archive. Then (given all other cycle time dependent
inputs) the task can easily be rerun for any cycle still in the archive.

\subsubsection{Reporting Outputs and Failures}

All outputs that other tasks may depend on must be reported via cylc's
simple messaging interface, which is explained in {\em Prerequisites and
Outputs} (Section~\ref{TaskPrerequisitesAndOutputs}). Similarly, fatal
errors must be reported by the same mechanism, otherwise cylc will think
the failed task is still running. 

Ideally, important errors should be checked for explicitly, and lesser
fatal errors (e.g.\ failure to create an output directory) can be
trapped by the shell and handled with an automatic message. The
userguide example task script listings of
Section~\ref{ACompleteWorkingExample} show how to do this.

\subsubsection{Contact Tasks Must Wait On Data}

Most tasks in a cylc system know their own cycle time, but they don't
know or care what the wall clock time is.  They just run when their
prerequisites are satisfied, i.e.\  when other tasks say their input
files (usually) are ready for use. The only connection between cylc
systems and the real world are the {\em contact tasks} (see {\em Task
Types}, Section~\ref{TaskTypes} for more on this) which in addition to
their other prerequisites, if any, wait on a particular wall clock time
relative to their cycle time before running.  For example, a weather
model that assimilates real time observations should have an associated
contact task whose job is to report when those observations are ready
for use.  If in real time operation at nominal analysis time T, the obs
are expected at, say, T+3 hours, then the contact task should be
configured to launch at 3 hours past its cycle time (again, at the
earliest because its other prerequisites must also be satisfied).
If the system is delayed by more than three hours, so that T+3 hours 
has already passed, then the contact task will launch immediately.
If there's any chance that the obs could in fact be ready at T+2 hours,
then the contact delay interval should be changed to 2 hours.  To allow
for possible late arrival of obs, which likely will happen on occasion,
the real contact task should have a wait loop in it: once running it
should check for the existence of the expected data immediately. If the
data isn't there the task must keep checking until it shows up, and only then
report its output completed to cylc. 


\subsection{Incremental System Construction} 
\label{IncrementalSystemConstruction}

You can get the {\em scheduling} of a complex system right without ever
having to run the real tasks, by testing incrementally in cylc's {\em
Dummy Mode} (Section~\ref{DummyMode}) as you define each task. Then (or
in parallel with the task definition process) you can also test the real
system incrementally as you write its task scripts (by which cylc runs
the real tasks) by turning off all the tasks that you're not yet
interested in (this can be done through the \lstinline=--include= and
\lstinline=--exclude= scheduler options, or by commenting task names out
of the configured task list; see {\em System Config Files},
Section~\ref{SystemConfigFiles}).

Start by defining tasks at the top of the single-cycle dependency graph,
and testing in dummy mode each time a new task is added. This checks
that prerequisites and outputs match correctly. When the whole system is
defined, begin writing the real task scripts in the same order, and test
in real mode with the as yet unimplemented tasks turned off (comment
them out of the task list in the system config module, or use the
scheduler command line options provided for this purpose). 


\subsection{Task Prerequisites And Outputs}
\label{TaskPrerequisitesAndOutputs}

Cylc's scheduling algorithm matches one task's completed outputs with
another's unsatisfied prerequisites
(Section~\ref{TheCylcSchedulingAlgorithm}).  

Each task definition file must specify a list of prerequisites that have
to be satisfied before the task can run, and a list of outputs that will
be completed as the task runs. {\em These are just literal text
strings - messages that running tasks must send to their proxy objects,
inside the cylc scheduler, whenever they complete a registered output}.

\begin{itemize}
    \item A task proxy considers a registered output ``completed''
        if it has received a matching message from its external task.

    \item A task proxy considers a registered prerequisite ``satisfied''
        if another task proxy reports that it has a matching completed
        output.

\end{itemize}

A task with no prerequisites can start running immediately (i.e.\ as soon
as the proxy object is created) {\em unless} it is a ``contact task''
(below), which must also wait on a wall clock time relative to its cycle time.

{\em Every system must contain at least one task with no prerequisites
to get things up and running}. These will normally be special oneoff
startup tasks (e.g.\ to clean out a full-system workspace) and contact
tasks that wait on external input for each cycle.


\lstset{language=cylctaskdef} 

\subsubsection{Cycle Time}

{\em Prerequisites and outputs should always contain a cycle time} to
distinguish between different instances of a task (at different 
forecast cycles) that may coexist in the task pool at any time. 

Prerequisites that reflect same-cycle dependencies, which is the usual
case, should mention the host task's own cycle time, expressed as
\lstinline=$(CYCLE_TIME)= in task definition files.

For intercycle dependencies, the cycle time in a prerequisite message
should be expressed as some offset from the task's own cycle time, e.g.\
\lstinline=$(CYCLE_TIME - 6)=. However, the only intercycle dependencies
you are likely to encounter (see the TopNet model in EcoConnect,
Section~\ref{EcoConnect}, for a counter example) are the restart
dependencies of your warm cycled forecast models, and the prerequisites
and outputs for these are now registered automatically by cylc.

\subsubsection{Message Form}

The exact form of the messages does not matter so long as the
prerequisites match their corresponding and outputs. For example, if
the message, 
\begin{lstlisting}
"storm surge forecast fields ready for $(CYCLE_TIME)"
\end{lstlisting} 
is registered as an output by the task that generates said forecast
fields, then the exact same message should be registered as a
prerequisite by any task that requires that data as input
(presumably storm surge postprocessing tasks in this case). 

\subsubsection{Message Content}

Prerequisites and outputs typically refer to the completion of a file or
a group of files, but it can be any event that a task could conceivably
trigger off: database interactions, download of data from a network,
copying or archiving of files, etc.

For single file outputs the cylc message could include the actual
filename:
\begin{lstlisting}
"file surface-pressure-$(CYCLE_TIME).nc ready for use"
\end{lstlisting}
but there is no need to do this (see {\em Message Truth} below); you
might as well adopt a message format that applies equally well to
more general events and multi-file outputs:
\begin{lstlisting}
"surface pressure fields ready for $(CYCLE_TIME)"
\end{lstlisting}


\subsubsection{Message Truth}

{\em Cylc does not check that incoming messages are true.}  For example,
if the message refers to completion of a particular output file, cylc
does not check that the file actually exists as the reporting task
claims it does. There are two reasons for this: (1) cylc does not place
any restriction on the kind of event that can be used as a task trigger,
so it would be next to impossible for it to verify outputs in general,
and (2) there is actually no need for cylc to check because the tasks
themselves must necessarily do it, and they must immediately report
problems back to cylc before aborting (or in the worst case, neglect to
check and then fail for lack of required inputs, with the same result).


\subsubsection{Uniqueness}

Prerequisites need not be unique; i.e.\ multiple tasks can trigger off
the same event.

Outputs should probably be unique; otherwise a task that depends on a
particular output will trigger off the first task to provide it.


\subsection{Task Types} 
\label{TaskTypes}

In cylc, every task (sans cycle time, which is a task type parameter) is
a member of its own class, which is defined in the \lstinline=task_classes.py=
module generated by \lstinline=cylc configure= when it parses the system
taskdef files.  Each task, via the taskdef \lstinline=TYPE= key, must
declare itself to be derived from one of two base classes that define
its main properties:

\begin{itemize} 
    
    \item A \lstinline=free= task does not depend on outputs generated
        by a previous instance of its own class, which means successive
        instances of it can run in parallel if the opportunity arises
        (i.e.\ prerequisites allowing).  To allow this to happen, a free
        task spawns a successor as soon as it enters the {\em running}
        state\footnote{Spawning any earlier than this would bring no
        advantage, in terms of parallel execution, at the cost of
        unrestrained task breeding.}. Most non-forecast model tasks (pre
        and post processing tasks, etc.) should be of this type.

    \item A \lstinline=tied= task {\em does} depend on outputs generated
        by a previous instance of its own class. These are typically
        warm cycled forecast models which depend on ``restart'' files
        generated by the previous forecast, e.g.\ ``model background''
        data used in part to initialise the new forecast.
        Other prerequisites allowing, cylc can run successive forecast
        models as soon their restart files are available {\em if}
        those restart outputs are reported as soon as they are
        generated. However, successive instances of a forecast model will
        often run in sequence at best because of resource limitations,
        or because the model executable has not been modified to report
        mid-run outputs back to cylc at the time they occur (in which
        case all restart outputs will be reported complete at once when
        the model run finishes).

%    # *(2) A FORECAST_MODEL depends on a previous instance of the same
%    # task to provide special `restart' prerequisites: during a
%%    # forecast, a warm-cycling model will write out a state dump valid
%    # at the start time of the next forecast, for use in initialising
%    # it. Multiple restart outputs may be generated to allow one or more
%    # subsequent forecasts to be omitted if necessary. A forecast_model
%    # registers how many of these are generated, which cylc assumes are
%    # intended for use by the next N valid start times for the task and
%    # automatically adds special outputs and prerequisites to represent
%    # them in the system. 
%    # A forecast model cannot start running until
%    # its restart prerequisite is satisfied, but the same prerequisite
%    # can potentially be satisfied by a restart output from any of the
%    # previous N forecasts. This allows cylc to continue running when
%    # one or more cycles of a particular model have to be omitted
%    # because of problems. But in normal operation we only want a model
%    # to trigger off the most recent previous forecast, which means that
%    # a forecast model cannot spawn a successor until its *last* restart
%    # output is completed (otherwise there is a chance the next-plus-one
%    # instance could come into existence and trigger before the the
%    # current instance, and so on, in normal operation). 
 
\end{itemize}


\subsubsection{Task Type Modifiers} 

A task may also declare one or more {\em modifiers}, after the main
type, that alter its behaviour to some extent:

\begin{itemize}
    \item A \lstinline=oneoff= task never spawns a successor, once it
        has finished and is no longer needed it will be removed from the
        system. This can be used for tasks that clean out a system 
        workspace, for example, and {\em cold start} tasks that supply
        initial restart inputs to warm cycled forecast models. See also
        the \lstinline=STARTUP_PREREQUISITES= task definition key, below.

    \item A \lstinline=sequential= task does not spawn a successor until it is
        finished. You can use this to force successive instances of a
        free or tied task to run in sequence if multiple instances of
        the real external task cannot be allowed to run at the same
        time (perhaps because they would interfere with each other
        through use of the same temporary files, or similar).

    \item A \lstinline=contact= task waits on an external event, such as
        incoming external data, i.e.\ it ``makes contact'' with the
        external world.  The event is expected at some defined time
        interval after the task cycle time (e.g.\ observational data
        might come 3.5 hours after its nominal validity time); see
        \lstinline=CONTACT_DELAY= below. In real time operation a contact task will
        not begin running until the clock time has reached this delayed
        start time. In catchup operation a contact task will begin
        running immediately (other prerequisites allowing) because the
        delayed start time has already passed.  
        
    \item A \lstinline=catchup_contact= task maintains awareness,
        through a class variable (i.e.\ not per instance), of whether or
        not it has `caught up' yet.  This can be used for rare occasions
        when some dependant task needs to behave differently according
        to whether its upstream contact task has caught up or not (in
        EcoConnect, only the TopNet river model).

    \item A \lstinline=dummy= task always invokes the cylc dummy task
        program, even when operating in real mode.  The dummy task
        program masquerades as the task it represents by reporting its
        registered outputs completed at the right times. This can be
        used to ``fake'' provision of initial restart prerequisites to a
        forecast model whose real initial inputs have been put in place
        by some external means (perhaps a long ``spin up'' process)
        prior to starting the whole system.

\end{itemize}

\subsection{Timed Outputs}

Outputs have to be registered with an {\em estimated time of completion}.
The timing information is currently only used in dummy mode to simulate
the correct task run time, so accuracy isn't critical. In the future
it may also be used to check system progress against expected behaviour.

\subsection{Automatic Started And Finished Outputs}

\lstinline=cylc configure= automatically registers special {\em started}
and {\em finished} outputs for every task: 

\begin{lstlisting}
"0 min:                  foo%$(CYCLE_TIME) started"
"[estimated run length]: foo%$(CYCLE_TIME) finished"
\end{lstlisting}

And \lstinline=cylc message= has special options allowing external
tasks to send these messages automatically, so you don't have to worry
about typos in the message.

Be aware that triggering off these messages introduces explicit
dependence on specific tasks, rather than on outputs that could be
provided, in principle, by any task, so this makes the system somewhat
less flexible.


\subsection{Failure Messages}

A {\em failed} message should be reported by external tasks, using 
\lstinline=cylc message --failed=, whenever the task fails. This is 
not an ``output'' to be registered in the taskdef file because the
completion time is unknown at best (at what point in a tasks execution
does a failure occur?) and more usually undefined (hopefully the task
will not fail). 

\subsection{Completion Messages}

\lstinline=cylc message= automatically sends a special {\em completed}
message whenever a tasks reports {\em success or failure}:
\begin{lstlisting}
"foo completed for $(CYCLE_TIME)"
\end{lstlisting}
 
This can be useful if you want to trigger off an upstream task whether
or not it succeeded (e.g.: a data assimilation program that triggers
when a handful of separate obs processing programs have finished or
failed, where failure occurs if no obs of a particular type happen to be
available for the forecast cycle in question).


\subsection{Forecast Model Restart Outputs}

Task of the tied type (i.e.\ forecast models) must declare, in their
task definition files, the number (and expected output times) of
the restart outputs that they generate to satisfy the previous-instance
dependence of their successors. {\em Cylc configure then automatically
generates special restart outputs and prerequisites for the task class}.
For example, consider a forecast model {\em foo} that runs on a
6 hour cycle and generates restart dumps for the next 2 cycles at
approximately 5 and 10 minutes into the forecast. If this information 
is put into the task definition file for task foo, it will
(automatically) result in the following prerequisite:

\begin{lstlisting}
"foo restart files ready for $(CYCLE_TIME)"
\end{lstlisting}

and the following two outputs:

\begin{lstlisting}
"5 min:  foo restart files ready for $(CYCLE_TIME + 6)"
"10 min: foo restart files ready for $(CYCLE_TIME + 12)"
\end{lstlisting}

\lstinline=cylc message= also has special options for reporting restart
outputs so that you do not have to worry about typos in the message. 

\subsubsection{Restart Gotchas}

Note that while cylc automates registration of restart prerequisites and 
outputs for convenience, behind the scenes they are still nothing more
than ordinary cylc output messages, and there are currently a couple
of situations where you still need to register these messages manually:

\begin{itemize}

    \item oneoff cold start tasks that provide initial restart inputs
        for other tasks (the working example systems show this clearly!).

    \item a task that behaves differently at different times should be 
        handled using conditional prerequisites and outputs. For
        example, a forecast model that does a long forecast at 06 and
        18Z and a short forecast at other times. An alternative approach
        though would be to split the task into two separate tasks that 
        run in different cycles. If you want to do it this way then one
        task will be providing restart outputs for the other, and vice
        versa, which can be achieved by manually registering the same
        restart output messages in the two tasks. 

\end{itemize}

In both of these cases manual registration of restart messages is
required because the usual automatic method automatically uses the name
of the host task in the message, which is not what's needed here.


\subsubsection{Why Use Restart Outputs?}

If they seem overly complicated, you don't have to use them! You could
instead declare all your forecast models to be of the  
\lstinline=free, sequential= type. Such tasks cannot start until their
previous instances have finished, so any restart prerequisites are
implicitly satisfied.

However, if you do use restart outputs, you gain the following advantages:

\begin{itemize}

    \item a more efficient system: forecast model tasks that can start
        up before their previous instances have finished (other
        prerequisites allowing).  
    
    \item automatic post-intervention recovery from nasty system
        failures, because cylc will know about the actual restart
        dependencies of your real tasks. For example, in the userguide
        example system, if the weather model (task A) fails requiring a
        cold start 12 hours later, insert the cold start task into the
        system (at failure time + 12) and purge all downstream dependants of 
        the failed task through to the cold start cycle. Then, tasks
        B and C will carry on as normal because their restart
        prerequisites will be satisfied automatically by their
        predecessors from several cycles ago, before the gap caused by
        the failure.

\end{itemize}

\pagebreak
\subsection{Task Scripts}
\label{TaskScripts}

Cylc automatically has access (via \lstinline=$PATH=) to executable
files in the \lstinline=scripts= sub-directory of the system definition
directory. It is a central location in which to keep scripts that
execute external tasks (models etc.), which often have an independent
existence outside of the forecasting system, within the context of the
forecasting system.
Typically the task specified in the \lstinline=TASK=
key of a task definition file will be a script in this directory which,
once invoked by cylc, will itself launch the external process(es) and
handle all cylc messaging. In that case it may not be necessary to
modify the external task at all for use within cylc. That said, you can
if you wish specify an external script in the task definition file, in
which case the external script will have to be modified to do the cylc
messaging, OR uses cylc's task wrapping mechanism, which automatically
handles the former case but sets all outputs, including internal ones,
completed only after the external script finishes.  Scripts in the
scripts sub-directory are automatically made accessible, via 
\lstinline=$PATH=, to tasks launched by cylc. 

\subsubsection{Task Messages}

The external tasks, or the scripts that execute them, need to report
their outputs back to cylc as they run. Section~\ref{message} shows
how to add cylc messaging to tasks.  Ideally this reporting should be
done as soon as each output is completed throughout the run. This is
easy to achieve for scripted data processing tasks, for instance, but
you may not want to do it for model executables (it should be noted that
forecast models don't normally complete their major outputs until the
end of a run - except for restart outputs!). If that is the case a task
can simply report all outputs completed at once before it finishes.
Cylc in fact has a task-wrapping mechanism that does this automatically
(Section~\ref{TaskWrapping}), allowing you schedule a set of existing
tasks without modifying them at all.  

Each external task must:

\begin{itemize}
\item report (to cylc) when the task has started
\item report when the task has finished
\item report when every other registered task output has
completed
\end{itemize}

(Technically, the `started' and `finished' messages are just
outputs too, but they are special in that every task
must have them). In addition, tasks can optionally:

\begin{itemize}
\item report any arbitrary unregistered (i.e.\ non-output)
messages, for debugging, logging, or progress monitoring purposes.
\end{itemize}

All incoming messages are logged by cylc, but only output messages can
affect the state of other task objects.

Task messages don't necessarily have to originate from top level task
control scripts. It's a probably a good idea to do this if possible, but
lower level scripts that are invoked as the task runs can communicate
directly with cylc if necessary.

\subsection{Task Wrapping}
\label{TaskWrapping}

If you have a task that for some reason you cannot, or do not want to,
modify to send the startup, output, and failure or completion messages, 
you can have cylc wrap the task in a special script that does the following:

\begin{itemize}
    \item reports task startup
    \item invokes the wrapped task, and checks for success or failure
    \item if the task failed, it reports the failure. 
    \item if the task succeeded, it automatically reports all the task's
        registered outputs complete, and then reports success.
\end{itemize}

Note the assumption that successful completion of an external task
implies all registered outputs were completed by it.

If you wrap all tasks like this you can run an entire system without
modifying the tasks at all to accommodate cylc. There is a downside to
task wrapping, however:

\begin{itemize}
    \item you can't add extra internal messages (i.e.\ additional to the
        registered outputs) to a task, for progress monitoring or
        debugging purposes.
    \item all registered task outputs are reported complete only
        when the wrapped task finishes, not at the time they are actually
        completed. This means successive instances of a `tied' (forecast
        model) task cannot run in parallel, or overlap, if the
        opportunity arises (because the restart outputs, which are
        normally created early in the forecast, won't be reported until
        the end of the forecast).
\end{itemize} 

Of course forecast models are usually monolithic executables that are not
well suited to spawing external messaging processes, so these problems
may be of no consequence in practice.

\pagebreak

\subsection{Task Definition Files} 
\label{TaskDefinitionFiles}

A simple {\em Task Definition File} must be written for each task.
\lstinline=cylc configure= parses these and generates a Python module
that defines the task proxy classes for the system. {\em Task
Definition Files define just the properties of tasks that matter from a
scheduling perspective: name, external task, valid cycle times,
prerequisites, outputs.} 

Other task-specific configuration settings that are not relevant to
scheduling (e.g.\ numerical method choices, MPP
domain decomposition, input and output directory locations, and so on)
belong in the external location where the real task resides, or possibly
in the cylc task scripts that run the external tasks (ideally these
should contain configuration details specific to running an external
task within the wider system, but there's nothing to stop you putting
more than that in them). However, there is one minor exception to this
rule. If your system has several tasks that essentially do the same
thing you can get them all to invoke the same external program with
task-specific input parameters supplied through environment variables
that are specified in the Task Definition Files. Forecasting systems
commonly have to move a lot of files around (from the output
directory of one task to the input directory of another, for
instance). See Section~\ref{HandlingRealDependencies}, and cylc's
{\em file-move} example system. 

\subsection{Examples}

Listed immediately below are two example task definitions, one for a
``forecast model'', and the other not (e.g.\ post processing). All tasks
in a typical forecasting system can be defined as simply as these
(advanced TopNet scheduling the only exception in EcoConnect). 
But see {\em Master Task Definition Template},
Section~\ref{MasterTaskDefinitionTemplate} for full Task Definition
documentation. Please refer also to the task definitions in the packaged
example systems, which show the effect of the task type modifiers as well
(particularly oneoff and contact, which will be required to some extent
in all systems).


\pagebreak
\subsubsection{Free Task Example}

The following listing shows an example task definition for a
typical non-forecast-model task.
\lstset{language=cylctaskdef}

{
\lstinputlisting{../systems/userguide/taskdef/D.def}
}

\pagebreak
\subsubsection{Forecast Model Example}

The following listing shows an example task definition for a
typical {\em tied} (forecast-model) task.

\lstset{language=cylctaskdef}

{
\lstinputlisting{../systems/userguide/taskdef/A.def}
}


\pagebreak
\subsection{More Complex Task Behaviour}
\label{MoreComplexTaskBehaviour}

If you require task behaviour that cannot be represented in the current 
task definition files you will need to derive a new task class manually.
Use the auto-generated task classes as a starting point. Raw python 
task class definitions stored in Python source files can be 
kept in the system taskdef sub-directory alongside the taskdef files,
and will be transferred verbatim to the new task definition file on 
configuring the system. 

Out of the entire EcoConnect operation, only the highly unusual
scheduling behaviour of the TopNet river model requires a custom task
class (it keeps up with real time streamflow observations and uses
the {\em most recent} regional weather forecast output). 

\subsubsection{Fuzzy Prerequisites}

EcoConnect's Topnet model (just mentioned above) runs hourly and
triggers off the most recent regional weather forecast available.
The cycle time interval between the two tasks can vary. This makes 
use of cylc's {\em fuzzy prerequisites}, which the task definition
parser is not currently aware of.


\pagebreak


\pagebreak
\section{Job Submission}
\label{JobSubmission}

Cylc can use different job submission methods to launch different tasks. 
Set a default method in the system config file (see
Section~\ref{SystemConfigFiles}):
 
\lstset{language=Python}

\begin{lstlisting}
# By default, submit tasks to run in a background shell
self.items['job_submit_method'] = 'background'
\end{lstlisting}
 
And override the default method for specific tasks as needed:

\begin{lstlisting}
# But submit tasks A, B, and C to run using 'at now'
self.items['job_submit_overrides']['at_now'] = [ 'A', 'B', 'D' ]
\end{lstlisting}

\subsection{Available Methods}
\label{AvailableMethods}

\lstset{language=bash}

There are two basic methods, available on any platform, that are
sufficient for running cylc's example systems (they could also be used
for small tasks within a real forecasting system): 

\begin{itemize}

    \item \lstinline=background= - run a task in a background shell
        (\lstinline=foo &=). 

     \item \lstinline=at_now= - submit a task to run immediately via the
         unix 'at' command (a rudimentary batch queue scheduler that
         reports job output to the user by email).

\end{itemize}

Most tasks in a real forecasting system will need to be submitted to a
proper batch queue scheduler or cross-platform resource manager such as
{\em loadleveler} (IBM). Methods currently available are:

\lstset{language=cylctaskdef}

\begin{itemize} 
    
    \item \lstinline=ll_basic= - submit a task to loadleveler. Some
        default loadleveler directives are provided; these can be used
        as is, overridden, or added to, via the taskdef file
        \lstinline=%DIRECTIVES= section.

    \item \lstinline=ll_raw= - submit a task that already contains all
        the loadleveler directives it needs. Useful for complex (e.g.
        multi-step) tasks already configured to use loadleveler.

    \item \lstinline=ll_basic_eco= and \lstinline=ll_raw_eco= - these
        adapt the generic loadleveler methods above to NIWA's EcoConnect
        operational environment so that the exact same system definition
        can be used in distinct {\em oper}, {\em test,} or {\em devel}
        areas (where the task owner usernames and home directories vary
        accordingly).

\end{itemize}


\subsection{How It Works}
\label{HowItWorks}

When a task is ready to run cylc writes a temporary {\em task execution
script} which it submits by the method specified for the task. The task
execution script explicitly defines the execution environment before
invoking the task itself. Other information (e.g.\ loadleveler
directives) may be written to the task execution script too, depending
on the job submission method.

The task execution environment must provide access to the task itself,
to cylc and any environment variables it needs to run, and to any
environment variables required by the task as it runs. See {\em Task
Execution Environment} (Section~\ref{TaskExecutionEnvironment}) for how
to set environment variables in cylc.

\lstset{language=bash}

You can use \lstinline=cylc run-task= to generate a task execution script
for inspection. For example:

%, if you have configured the userguide example system, registered it
%under the name ``userguide'', and left the default job submission
%method unchanged

\begin{lstlisting}
oliverh:~/cylc % cylc run-task --dry-run --task=E%2009112318 userguide
  > TASK EXECUTION SCRIPT: /tmp/cylc-IU0DDH
  > JOB SUBMISSION METHOD: /tmp/cylc-IU0DDH </dev/null > E%2009112318-$$.log 2>&1 &
  
oliverh~/cylc % cat /tmp/cylc-IU0DDH
  #!/bin/bash
  
  # TASK EXECUTION ENVIRONMENT: system-wide variables
  export CYLC_MODE="run-task"
  export CYLC_DIR="/home/oliverh/cylc"
  export CYLC_SYSTEM_DIR="/home/oliverh/cylc/systems/userguide"
  export CYLC_SYSTEM_NAME="userguide"
  export CYLC_NS_HOST="NOT USED BY RUN-TASK"
  export CYLC_NS_GROUP="NOT USED BY RUN-TASK"
  export CYLC_TMPDIR="/tmp/oliverh/userguide"
  export REAL_TIME_ACCEL="360"
  
  # TASK EXECUTION ENVIRONMENT: task-specific variables:
  export CYCLE_TIME="2009112318"
  export TASK_NAME="E"
  export TASK_ID="E%2009112318"
  
  # CONFIGURE CYLC ENVIRONMENT
  . $CYLC_DIR/cylc-env.sh
  
  # EXECUTE THE TASK
  E.sh 
  
  #EOF
\end{lstlisting}

\subsection{Defining New Methods}

New job submission methods can be derived from the \lstinline=job_submit=
base class in:

\begin{lstlisting}
$CYLC_DIR/src/job-submission/job_submit.py
\end{lstlisting}

and then imported into the \lstinline=job_submit_methods= module:

\begin{lstlisting}
$CYLC_DIR/src/job-submission/job_submit_methods.py
\end{lstlisting}

This is easy to do; most of the required functionality already exists in
the base class and you can model new sub-classes on existing ones. To
illustrate, here is the entire derived class code for the two simplest
job submission methods, \lstinline=background= and \lstinline=at_now=:

\lstset{language=Python}

\begin{lstlisting}
#!/usr/bin/python
from job_submit import job_submit

class at_now( job_submit ):
    # This class overrides job submission command construction so that
    # the cylc task execution file will be submitted to the Unix 'at'
    # scheduler ('at -f FILE now').

    def construct_command( self ):
        self.command = 'at -f ' + self.jobfile_path + ' now'
\end{lstlisting}

\begin{lstlisting}
#!/usr/bin/python
from job_submit import job_submit

class background( job_submit ):
    # This class overrides job submission command construction so that
    # the cylc task execution file will run in a background shell.
    
    def construct_command( self ):
        # Redirection of stdin here allows "background execution" of the
        # task even on a remote host (if one is specified in the taskdef
        # file) - ssh can exit immediately after invoking the job
        # script, without waiting for the remote process to finish.

        log = self.task_id + '-$$.log'
        self.command = self.jobfile_path + " </dev/null > " + log + " 2>&1 &" 
\end{lstlisting}

To interface with more sophisticated schedulers other base class methods
in addition to \lstinline=construct_command()= may need to be overridden.
Take a look at the source code for the loadleveler job submit classes,
and ensure you understand {\em How Job Submission Works},
Section~\ref{HowItWorks}.

\subsection{Running Local Tasks Under Other Usernames}
\label{RunningLocalTasksUnderOtherUsernames}

\lstset{language=cylctaskdef}

A task that runs on the local host and declares an owner in the taskdef
file \lstinline=%OWNER= section will be submitted via the Unix
\lstinline=sudo= command:  

\lstset{language=bash}

\begin{lstlisting}
sudo -u OWNER [SUBMISSION-COMMAND]
\end{lstlisting}

For this to work \lstinline=/etc/sudoers= must be configured to allow
the cylc user to invoke the relevant job submission commands as the task
owner.  This might be difficult to arrange for the background execution
method (wherein task execution scripts are invoked directly) but is
otherwise easy to do: for the 'at' or loadleveler methods, for instance,
the cylc user only needs \lstinline=sudo= access, as the task owner, to
\lstinline=at= or \lstinline=llsubmit= respectively.

\subsection{Running Jobs On A Remote Host}
\label{RunningJobsOnARemoteHost}

If a task declares a \lstinline=%REMOTE_HOST= section in the taskdef
file, its execution script will be copied to the specified host by 
\lstinline=scp=, and then invoked on the remote machine (using the
correct job submission method for the task) by \lstinline=ssh=. 

For this to work {\em you must have passwordless ssh configured, as 
the cylc user, between the local and remote hosts}. Once so configured
you should be able to do the following, on the command line, without
supplying a password:

\begin{lstlisting}
cylc-user% ssh REMOTE_HOST hostname
\end{lstlisting}

If the task additionally declares an \lstinline=%OWNER= section in the
taskdef file owner, the task execution file will be copied to and
invoked on the remote host as the task owner; thus {\em you must have
passwordless ssh configured, as the cylc user, to the remote host, as
the task owner}:

\begin{lstlisting}
cylc-user% ssh OWNER@REMOTE_HOST hostname
\end{lstlisting}

Note that you may not need this functionality if you have a
cross-platform resource manager such as loadleveler that allows 
you to submit a job on the local host to run on the remote host.

\subsubsection{Remote Host Requirements}

\begin{itemize}

    \item Cylc (and Pyro) must be installed on the remote host, so that 
        the task can use \lstinline cylc message= to communicate with
        its controlling scheduler.
        
    \item The task itself must be installed on the remote host (the task
        execution script that is copied to the remote host is what
        invokes the task, but is not the task itself. 

    \item The task execution environment, as specified in the task
        execution script, must provide access to the remote cylc
        installation (for \lstinline=cylc message=) and to the remote
        task.

\end{itemize}

\lstset{language=cylctaskdef}

To provide access to the remote cylc installation, override the 
\lstinline=CYLC_DIR= environment variable in the taskdef
\lstinline=%ENVIRONMENT= section:

\begin{lstlisting}
CYLC_DIR         /path/to/cylc/installation
\end{lstlisting}

If you have installed your entire system definition directory on the
remote platform (it is not necessary to do this, but it may be
convenient) then you can also override \lstinline=$CYLC_SYSTEM_DIR= to
point to that location. Then, if the remote task script resides in the
system definition scripts sub-directory, the task execution script will
automatically be able to find it after the cylc environment is
configured.

\begin{lstlisting}
CYLC_SYSTEM_DIR  /path/to/system/definition/directory
\end{lstlisting}

(\lstinline=CYLC_DIR=  and \lstinline=CYLC_SYSTEM_DIR= are inserted
into your \lstinline=PATH= by \lstinline=cylc-env.sh=, which is sourced
in the task execution script before executing the task).

Alternatively, you could specify the full path to the task script:

\begin{lstlisting}
%TASK
    /remote/path/foo.sh
\end{lstlisting}

or explicitly configure your \lstinline=PATH= variable in the taskdef
\lstinline=%ENVIRONMENT= section by making use of cylc's ``delayed
evaluation'' environment variables (see {\em Task Execution
Environment}, Section~\ref{TaskExecutionEnvironment}):

\begin{lstlisting}
%TASK
    foo.sh

%ENVIRONMENT
    PATH     /remote/path:$[PATH]
\end{lstlisting}

\subsubsection{Remote Host Example}

See cylc's ``Distributed'' example system, Section~\ref{Distributed}.


\subsection{Task stdout And stderr}
\label{TaskstdoutAndstderr}

Where job stdout and stderr ends up depends entirely on the job
submission method. These will normally end up as log files in the user's
home directory (or perhaps elsewhere if the job submission method allows
this to be configured). Submitting jobs via 'at' results in stdout and
stderr being emailed to the user when the completes.

\pagebreak
\section{Task Execution Environment}
\label{TaskExecutionEnvironment}

As described in Section~\ref{JobSubmission}, {\em Job Submission}, cylc
writes a special {\em task execution script} that it submits (by the correct
job submission method for the task) to execute the task. This script
explicitly defines the execution environment before executing the task
itself, regardless of the job submission method used. 

\subsection{System Wide Variables}
\lstset{language=bash}

\subsubsection{Automatic}
The following environment variables are automatically defined by cylc
for all tasks:


\begin{lstlisting}
  CYLC_MODE         # tells 'cylc message' what invoked a calling task
  CYLC_DIR          # path to the local cylc installation
  CYLC_SYSTEM_DIR   # path to the system defintion directory
  CYLC_SYSTEM_NAME  # registered name of the running system 
  CYLC_NS_HOST      # host running the Pyro nameserver
  CYLC_NS_GROUP     # group name used by this system in the Pyro nameserver
\end{lstlisting}

Most of these are used by implicitly by cylc and need not concern the user,
except in the case of tasks that must run on a remote platform; see 
{\em Submitting Jobs To A Remote Host}, 
Section~\ref{SubmittingJobsToARemoteHost}.

\subsubsection{User Defined}
\label{SystemWideVariables}

Environment variables defined in the system config file will be made
available to every task in the system; see 
{\em System Config Files}, Section~\ref{SystemConfigFiles}, e.g:

\lstset{language=Python}

\begin{lstlisting}
self.items['environment']['FOO'] = 'foo'
self.items['environment']['MY_TMPDIR'] = '/tmp/${CYLC_SYSTEM_NAME}'
\end{lstlisting}


\subsection{Task-specific Variables}
\lstset{language=bash}

\subsubsection{Automatic}

The following task-specific environment variables are automatically
defined by cylc:

\begin{lstlisting}
  export CYCLE_TIME="2009112318"
  export TASK_ID="E%2009112318"
  export TASK_NAME="E"
\end{lstlisting}

Executing tasks will almost certainly need to use
\lstinline=$CYCLE_TIME= to determine what forecast cycle to run,
but they don't need to know the name or ID used by cylc to identify
them. \lstinline=$TASK_ID= is used by \lstinline=cylc message= to 
identify which task is sending a message and therefore which task proxy
object to communicate the message to.


\subsubsection{User Defined}
\label{TaskSpecificVariables}

\lstset{language=cylctaskdef}

Environment variables defined in a task definition file
\lstinline=ENVIRONMENT= section will be made available
to just the one task; see {\em Task Definition Files}, 
Section~\ref{TaskDefinitionFiles}, e.g.:

\begin{lstlisting}
%ENVIRONMENT
    FOOBAR           foo bar
    ANALYSIS_TIME    $CYCLE_TIME
    OUTPUT_FILE      foo-${TASK_NAME}-${CYCLE_TIME}.nc
    NEXT_CYCLE_TIME  $(CYCLE_TIME + 6)   # NOTE round parentheses!
    REMOTE_HOME      $[HOME]             # NOTE square brackets!
\end{lstlisting}

\lstset{language=bash}

Note the two unusual cases above. \lstinline=$(CYCLE_TIME + 6)= is 
special notation that gives access to cylc's internal datetime arithmetic.
With no arithmetic, \lstinline=$(CYCLE_TIME)= is equivalent to 
the normal shell variables \lstinline=$CYCLE_TIME= and
\lstinline=${CYCLE_TIME}=. The square brackets are explained 
below in {\em Delayed Evaluation Variables},
Section~\ref{DelayedEvaluationVariables}.

\subsection{Referring To Other Variables}
\label{ReferringToOtherVariables}

\lstset{language=bash}

You can refer to other environment variables in the values of
system-wide or task-specific environment variables, and in task command
line arguments, as shown in the examples above. These will be explicitly
interpolated by cylc prior to writting the task execution script (i.e.
the variables will be replaced by their values). The distributed example
system (Section~\ref{Distributed}) exploits this to define task-specific
I/O sub-directories underneath a top level working directory that is
defined by a global environment variable that includes the registered
system name.

\subsubsection{Precedence}

In {\em system-wide variable} definitions, cylc looks for a match
amongst other defined system-wide variables, then in the local
environment (in which cylc is running).

In {\em task-specific variable} definitions, cylc looks for a match
amongst other task-specific variables, then amongst the system-wide
variables, and finally in the local environment (in which cylc is
running).

Environment variables found in {\em task commandline argument}
definitions are interpolated as for those in task-specific variable
definitions.

\subsubsection{Nested Definitions}

In the values of variables you define, you can refer to other variables,
which refer to other variables, and so on; these will be interpolated
out to the final value by cylc.  Circular definitions, however, will
raise a warning.

\subsection{Delayed Evaluation Variables}
\label{DelayedEvaluationVariables}

Environment variables that appear in the definition of other system-wide
or task-specific environment variables, or in task command line arguments,
enclosed in square brackets, e.g.\ \lstinline=$[FOO]=, will be rewritten as 
proper environment variables, literally \lstinline=${FOO}=, in the task
execution script, and will thus only be evaluated at execution time.

This allows user or host specific environment information to be used in 
constructing file paths (for example) even for tasks that will run under
other usernames and/or on remote hosts. \lstinline=$[HOME]=, for instance,
will evaluate at run time as the home directory of the task owner on the
host that runs the task, not as the home directory of the cylc user on 
the host that is running cylc.

\pagebreak
\section{Handling Real Dependencies}
\label{HandlingRealDependencies}

Cylc's prerequisite and output messages are somewhat abstract, but the
fact remains that most of the time they correspond directly to real 
files (or groups of files) that are generated by one task and used by
other tasks.

Each task, when considered in isolation, could in principle be
configured to use almost any location and filenaming convention for its
input and output files. But in the context of the wider forecasting
system they must all work together, so the question arises, {\em how do
we ensure that tasks always know where to find their input files, and
should the scheduling system have anything to do with this?} 

There are several ways of dealing with this in cylc (in fact they can
be mixed and matched as you wish). 

\subsection{(a) Make The External Tasks Responsible }

The standard way of doing this is to configure the external tasks with
knowledge of their role in the full system: each task knows where to
look for its input files because it knows where they come from, and/or
it knows where to put its output files because it knows who is going to
use them. Doing this by means of a system-wide convention for input and
output file and directory names (etc.) for the major tasks (principally
the scientific models) makes it easy to know where files should end up
at all times (e.g.\ model X's output goes in /oper/X/output or similar).

In this case, cylc task proxies (via their task definition files) do not
need to know anything about input and output file locations. If a task's
prerequisites are satisfied it automatically implies that the
corresponding input files exist {\em and} they are in the right location
for use.

\subsection{(b) Add Connector Tasks To The System} 

Large scientific models typically have their own idiosyncratic
configuration methods and defaults. You could leave each model
configured in its own ``natural'' way, as if unaware of the wider
forecasting system, and then add additional ``connector'' tasks to move
files around as needed (e.g.\ to transfer files from X's output
directory to Y's input directory).

To do this in cylc, you can either:

\begin{itemize}
    \item have a separate task script for every connector task, with the
        relevant locations hardwired into them; in this case the task
        definition files still do not need to know the locations.
    \item OR have all connector tasks call the same generic ``file
        transfer'' task script, in which the directory locations can be
        specified as environment variables in the connector task
        definition files (and the generic transfer script should be read
        them from the environment).
\end{itemize}

Cylc comes with a generic file transfer script, \lstinline=file_transfer.sh= that
is copied into your system definition \lstinline=scripts= sub-directory 
by \lstinline=cylc configure=. It is used be the {\em file-move} and {\em distributed}
example systems ({\em Other Working Examples}, Section~\ref{OtherWorkingExamples}).

\subsection{(c) Dynamic Configuration Of External Tasks}

You could configure your external tasks to set their input and output
directories or filenames dynamically, according to input taken from
environment variables defined in the corresponding cylc task definition
files. This would result in a system that has no need for extra
``connector'' tasks that move files around, and yet the external tasks
do not need to know their place in the wider system.

%\subsubsection{Alternative Method 3}
%
%Finally, in principle extra information could be attached to cylc output
%messages so that actual file locations could be passed dynamically from
%to whichever tasks use the output. Cylc currently cannot do this (you
%can put actual file locations in the messages, but the receiver has to
%have the exact matching message and therefore would have to know the
%location in advance). This is a possible future development, but is 
%probably not worth the effort because configuring the external tasks 
%to report this information takes more effort than putting the same
%information into the cylc task definition files. The cylc setup
%would remain entirely context-independent, which is nice, and would
%automatically pass on changes to the external input / output config of
%the system.





\pagebreak
\pagebreak
\section{System Config Files}
\label{SystemConfigFiles}

An initial customizable config file, \lstinline=system_config.py=, is
written into the system definition directory by 
\lstinline=cylc configure= the first time you configure a system.
Subsequent reconfiguration will not overwrite the file unless you force
it, in which case the original will be backed up. The config file is a
Python source module, but it is simply structured and should be easy for
non-programmers to adapt (it is just a matter of the changing the
existing default values, for the most part). 

Configurable items are stored in a single {\em dict} (a Python
associative array). Technically, the system config file is a class
derived from the main cylc config class; you can see the default
values of all configurables items at the top of
\lstinline=$CYLC_DIR/src/config.py=.

\lstset{language=Python}
\begin{lstlisting}
self.items['item'] = value
\end{lstlisting}

\subsection{Configurable Items}
\label{ConfigurableItems}

\begin{itemize} 
    
    \item {\bf task list}: this refers to an autogenerated list of task
        names that is now kept separately in another file,
        \lstinline=task_list.py=. Each task in the list will be
        instantiated at system startup.  For testing and debugging you
        can turn off specific tasks by simply commenting them out of the
        task list (or, preferably, use the start command's include and
        exclude options).
        
        \begin{lstlisting}
self.items['task_list'] = task_list
        \end{lstlisting}

    \item {\bf task groups}: you can group several related tasks under a
        single name in order to insert them all at once into the running
        system. For example, you could define a group to hold all the
        tasks needed to cold start a particular model.

        \begin{lstlisting}
self.items['task_groups']['cold_start_foo'] = [ 'bar', 'baz', ...]
        \end{lstlisting}

    \item {\bf job submit method}: the default job submission method 
        for the system.

        \begin{lstlisting}
self.items['job_submit_method'] = 'background'
        \end{lstlisting}

        To override the default method for task `foo' use:

        \begin{lstlisting}
self.items['job_submit_overrides']['foo'] = 'background2'
        \end{lstlisting}

        See {\em Job Submission} (Section~\ref{JobSubmission}) for
        available methods, and information on how to add new methods.


    \item {\bf state dump directory}: the location of cylc's state
        dump files, absolute or relative directory path.
        
        \begin{lstlisting}
self.items['state_dump_dir'] = '/foo/bar/baz/state'
        \end{lstlisting}


    \item {\bf logging directory location}: 
        This items sets the location of the system's log files, absolute
        or relative path.

        \begin{lstlisting}
self.items['logging_dir'] = '/foo/bar/baz/logging'
        \end{lstlisting}

    \item {\bf logging verbosity}: Cylc's logging subsystem is based on
        the standard Python logging module (see
        Section~\ref{SystemLogFiles}). The 'info' level logs messages
        relevant to task execution and scheduling, while the more
        verbose 'debug' level adds messages that trace the execution of
        cylc itself.

        \begin{lstlisting}
self.items['logging_level'] = logging.INFO
        \end{lstlisting}

    \item {\bf environment variables}: You can export variables into the 
        environment of all external tasks that the system runs. Note that
        this can also be done, via task definition files, on a per-task
        basis.

        \begin{lstlisting}
self.items['environment'][ 'VARNAME1' ] = 'value1'
        \end{lstlisting}

    \item {\bf maximum runahead time} - this is a global constraint that
        limits how far the fastest task can get ahead of the slowest, 24
        hours by default.
        
        \begin{lstlisting}
config['max_runahead_hours'] = 24
        \end{lstlisting}


    \item {\bf system title} and {\bf information}: 

        \begin{lstlisting}
self.items['system_title'] = 'System X'
self.items['system_info'] = info
        \end{lstlisting}
        where `info' is now imported from a separate file, 
        \lstinline=system_info.py= in the system definition directory.
        This is intended to be descriptive information about the system,
        perhaps details the user needs to know in order to run it (see
        for example the information given for the {\em userguide}
        example system).

    \item {\bf restricted startup hours:} setting this will cause 
        the system to abort with an error message if you attempt to
        start it for any cycle time with an hour value that is not in a given
        list of hours (e.g. 6 or 18Z). This is useful if your system 
        can only start at certain cycles because of external constraints
        such as availability of model start dumps. The {\em SCS Demo}
        example system is in this category.

    \begin{lstlisting}
self.items['legal_startup_hours'] = [ 6, 18 ]
# for a single value you must still enclose in list brackets: [ 6 ] 
    \end{lstlisting}

\end{itemize}


\pagebreak

%\subsection{Example Config File}
%\label{ExampleConfigFile}
%
%This is the config defaults file for the ``userguide'' example system
%distributed with cylc: 
%
%\lstset{ language=Python }
%{
%\lstinputlisting{../systems/userguide/system_config.py}
%}

\lstset{language=}


\pagebreak
\section{Running Cylc Systems}
\label{RunningCylcSystems}

\subsection{Cold Starts}

To cold start a system you need to specify an initial cycle time, e.g.:

\begin{lstlisting}
cylc start --at=2009101218 SYSTEM
\end{lstlisting}

\subsubsection{Oneoff Coldstart Tasks}

A special {\em oneoff coldstart task} should be defined for any task
that has different input requirements in the initial cycle than it does
subsequently. This generally applies to warm-cycling forecast models
that need to have their initial restart prerequisites satisfied somehow. 

Oneoff coldstart tasks can launch actual coldstart forecasts (e.g.\ an
initial regional weather forecast initialised from a lower resolution
global model), or they can represent some external spinup process that
has to be completed before the system is started. In the latter case
they should be declared as TYPE \lstinline=oneoff, dummy= in the taskdef
file so that they will simply report their outputs complete immediately
and allow the first warm-start forecast to run (and the system operator
guarantees that the actual spinup process has taken place prior to
startup).

A oneoff coldstart task can also be inserted into a running system to
get its associated forecast model restarted after a failure that results
in one of more omitted cycles. See {\em Failure Recovery Scenarios}
(Section~\ref{FailureRecoveryScenarios}) for an example of this. 

See also {\em Task Definition Files}
(Section~\ref{TaskDefinitionFiles}), and the userguide example system
implementation, for more on oneoff cold start tasks.

\subsection{Restarts}
\label{Restarts}

Cylc's automatic {\em state dump files} (described below in
Section~\ref{AutomaticStateDumps}) allow you to restart a system
that has previously been shut down, either from 
its most recent previous state:

\begin{lstlisting}
cylc start --restart SYSTEM
\end{lstlisting}

OR from a particular previous state:

\begin{lstlisting}
cylc start --restart-from=FILE SYSTEM
\end{lstlisting}

where FILE is a named state dump file. If the state dump file resides in
the configured state dump directory for the system, e.g.\  
\lstinline=$HOME/cylc-state/SYSTEM/=, then just the file name is required 
(not the full path).

Default restart behaviour is to automatically reset unfinished (i.e.\
submitted, running, or failed) tasks to waiting ({\em practice mode}
restarts are an exception to this - see below).  This is the only
sensible thing to do because cylc cannot know if any unfinished tasks
completed successfully after the scheduler was shut down.  

The \lstinline=--no-reset= option stops failed task being reset to 
waiting (and is the default for a {\em practice mode} restart, below), 
which would allow a system to be restarted before a failed task has been
fixed. To prevent a previously unfinished task that had not failed from
being rerun, {\em if you know that it completed successfully after the
system was shutdown}, you currently have to edit the state dump file
prior to the restart.  This is easy to do, but it unlikely to be
required because a cylc system does not shut down, unless forced to, until
all currently running tasks have finished.


\subsection{Understanding System Evolution}
\label{UnderstandingSystemEvolution}

At startup (in a coldstart) any oneoff tasks in the sytem will be
created at the initial cycle time, or at the next subsequent valid cycle
for the task. Any tasks that have no prerequisites (and, if they are
contact tasks, have reached their trigger time) will submit to run
immediately. Any cycling (i.e.\ non oneoff) tasks that have no
prerequisites (and, if they are contact tasks, have reached their
trigger time) will rapidly proliferate ahead until stopped by the
system's runahead limit (task X in the userguide example system
is of this type).  Thereafter, each task will, of its own accord, submit
to run as soon as its prerequisites have been satisfied by other tasks
already running or finished in the system (and trigger time etc.). 
Each task spawns a successor at a point in its lifecycle that depends on
its type: tied tasks spawn has soon as their restart prerequisites have
been completed, and free tasks spawn at the instant they start running. 
Once a task exists it is free to run as soon as its prerequisites are
satisfied, thus successive instances of a free task can run entirely in
parallel, and successive instances of a tied task can overlap, 
if the opportunity arises (i.e.\ other prerequisites allowing).

\subsection{Automatic State Dumps}
\label{AutomaticStateDumps}

Cylc updates its configured state dump file (e.g.\
\lstinline=$HOME/cylc-state/state=) after every pass through the task 
processing loop.

In addition, immediately prior to any dangerous system invention a 
special state dump file with a unique name is created, and an alert is
logged, e.g.:

\begin{lstlisting}
2010/03/30 14:54:29 WARNING main - pre-purge state dump: state.2010:3:30:14:54:29
\end{lstlisting}

If the system intervention does not have the desired effect, shut the system 
down immediately and restart it from the pre-intervention state dump:

\begin{lstlisting}
cylc start --restart-from=state.2010:3:30:14:54:29 SYSTEM
\end{lstlisting}

\subsection{System Log Files}
\label{SystemLogFiles}

Each task has its own rotating log file for task-specific events,
including incoming task messages, and the \lstinline=main= log file
records all events in sequence.

\lstset{language=,
basicstyle=\color{basic}\scriptsize\ttfamily,
}
\begin{lstlisting}
$ tail $HOME/cylc-logs/userguide/main
2010/03/28 00:33:50 INFO main.F - [2010010312] disconnected (spent; general)
2010/03/28 00:33:52 INFO main.C - [2010010400] storm surge fields ready for 2010010400
2010/03/28 00:33:52 INFO main.A - [2010010412] surface wind fields ready for 2010010412
2010/03/28 00:33:52 INFO main.C - [2010010400] C%2010010400 completed
2010/03/28 00:33:52 INFO main.C - [2010010400] C%2010010400 finished
2010/03/28 00:33:52 INFO main.A - [2010010412] surface pressure field ready for 2010010412
2010/03/28 00:33:52 INFO main.A - [2010010412] level forecast fields ready for 2010010412
2010/03/28 00:33:53 INFO main.A - [2010010412] A%2010010412 completed
2010/03/28 00:33:53 INFO main.A - [2010010412] A%2010010412 finished
2010/03/28 00:33:53 CRITICAL main - ALL RUNNING TASKS FINISHED
\end{lstlisting}

\lstset{language=,
basicstyle=\color{basic}\footnotesize\ttfamily,
}

Each entry shows the time of logging, the name and cycle time of the
reporting task (in square brackets), and the logged message.

In dummy mode, the logged time is the dummy mode accelerated clock time, not 
real time.

Existing log files are automatically rotated at start up and,
individually, when they reach a size of 1 MB.  This maximum file 
should be configurable, but it is currently hardwired in
\lstinline=$CYLC_DIRsrc/pimp_my_logger.py=.

\subsection{Dummy Mode} 
\label{DummyMode}

If you start a system in dummy mode, e.g.\:

\begin{lstlisting}
cylc start --dummy-mode --at=2009081118 userguide
\end{lstlisting}

then in place of each real task cylc will launch an external program
that masquerades as the real thing by reporting that task's registered
outputs complete at the appropriate times. This is essentially
indistinguishable, to cylc, from real operation, and is a complete test
of scheduling for the configured task set (so long as the real tasks
report their registered outputs completed as they are supposed to). 

This is a powerful aid in constructing new systems, because it allows
you to get the scheduling right without having to deal with all the
complications of running the real tasks.

\subsubsection{Clock Rate and Offset}

Dummy mode systems run on an accelerated clock so that you can test
things very quickly. You can set the clock rate and offset with respect
to the initial cycle time with options to the \lstinline=cylc start=
command. An offset of 10 hours, say, means that the dummy mode clock
starts at 10 hours prior to the system's initial cycle time.  You can
thus simulate the behaviour of the system as it catches up from a delay
and transitions to real time operation.  By default, the clock runs at a
rate of 10 seconds real time to 1 hour system time, and with an initial
offset of 10 hours. 

\subsubsection{Practice Mode}

Practice mode allows quick and easy testing of potentially complex
system interventions, with complete safety.

\begin{lstlisting}
cylc start --restart --practice userguide
\end{lstlisting}
(You can also use \lstinline=--restart-from=)

This will start a dummy mode clone of an existing system from the
current state of that system (which may be paused, still running, or
halted), but using different state and log files so that the original
system will not be corrupted by the clone.

{\em At startup in practice mode, failed tasks are not reset to waiting}
because the whole point of practice mode is to ``practice'' how to
recover from failures.

Note that other cylc commands for monitoring or interacting with the
system must also use the \lstinline=--practice= option in order to
target the practice system and not the real one. Be sure to set
\lstinline=cylc lock= on the original system first, to avoid
accidentally messing with it (even if you do screw up, however, cylc's
automatic pre-intervention state dumps will save you!).


\subsubsection{Roll Your Own Practice Mode}

A less automated way to ``practice'' on a copy of an existing system
that starts up from the current (or previous) state of that system, 
\lstinline=cylc start --practice= is this:

\begin{itemize}
    \item register your system again under a different name. This allows
        you to run a dummy mode copy of the same system without
        interfering with the original system (it also allows you to run
        a copy of the real mode system without interference, but only if
        the real system tasks are configured to use the registered
        system name in all important input and output filenames and/or
        directory paths - see {\em Command Reference} Section~\ref{register}).

    \item start up the newly registered system in dummy mode using:
        \begin{lstlisting}
cylc start --dummy-mode --restart-from=FILE SYSTEM
        \end{lstlisting}
        where FILE is a state dump file from the original system. The
        absolute filepath is required here because the default state
        dump location depends on the registered system name (so that
        different systems don't interfere with each other's state
        dumps).

\end{itemize}

\subsection{Diagnosing A Stalled System}
\label{DiagnosingAStalledSystem}

In certain situations a system may appear to be ``stuck'', i.e.\ no
tasks are running and nothing appears to be happening. There are several 
possible reasons for this (it does not necessarily indicate a problem!):

\begin{itemize}
    \item In {\em normal real time operation}, when all running tasks
        have finished for the most recent cycle, nothing will happen
        until the one or more contact tasks in the system trigger at the
        start of the next cycle. \lstinline=cylc task-dump= shows if a
        contact task has yet to reach its trigger time.

    \item if every task in the system has one or more unsatisfied
        prerequisites, the system will be stalled. This could happen,
        for example, if you start a system that contains tied (forecast
        model) tasks without the corresponding oneoff coldstart tasks to
        satisfy their initial restart prerequisites.

\end{itemize}

The following problems all cause a system to {\em eventually} get stuck 
at the {\em runahead limit} (which is 24 hours between the
fastest and slowest tasks, by default), because cylc does not
automatically remove failed tasks from the system.  Real operational
systems should have automated means of alerting the system operator to
any failure that occurs, but in the unlikely event that the failure 
is not noticed until the system stalls at the runahead limit, then to
get things moving again the operator must either remove teh failed task
or reset (and thereby rerun) it after fixing the problem that cause the
failure.

\begin{itemize}
    \item if the system operator, perhaps in a post-task-failure
    intervention, kills some tasks that are required to satisfy the
    prerequisites of other tasks that still exist in the system, then 
    the system will eventually stall at the runahead limit as a
    result of these tasks being unable to run (solution: insert
    appropriate oneoff cold start tasks).

    \item if the runahead limit is shorter than the cycling
    interval for some task in the system the system will stall (e.g. if
    you have a task that runs 24-hourly at 00Z, but set the runahead
    limit to 12 hours). This could also happen if you purge enough
    cycles that the difference between the pre- and post-purge tasks
    is greater than the runahead limit.

    \item if a failed task has not yet been removed or reset by the
    system operator, it will obviously delay its direct downstream
    dependants, but it will also cause the entire system to stall,
    eventually, at the {\em runahead limit}.  

    \item if a system design (task definition) error results in creation
    of a task that cannot get its prerequisites satisfied by any other
    task in the system, then this task will never run and will
    eventually cause the system to stall at the runahead limit.

    \item if a misconfigured external task does not report an output
    that it is supposed to (i.e.\ as registered in its task proxy
    definition file), then any other task depending on that output will
    not run, and will eventually cause the system to stall at the
    runahead limit.

\end{itemize}

To confirm that the runahead limit is causing a stall, you can use 
\lstinline=cylc set-level= to set the verbose logging level, then
\lstinline=cylc nudge= to invoke the task processing loop - any task
that is not spawning a successor only because it has exceeded the runahead
limit will report that to the log.


\subsection{Failure Recovery Scenarios}
\label{FailureRecoveryScenarios}

\begin{itemize}
    \item {\em One forecast cycle runs into the next, after a delay in
        operations}. This is never a problem for cylc; every task runs
        as soon as it can run, regardless of forecast cycle, and any
        task that can't run before it's predecessor has finished will
        wait.

    \item {\em A delayed parallel trial or case study catches up to real
        time operation}. This is no problem for cylc; any cylc system
        will seamlessly transition in and out of ``normal real time
        operation'' (distinct cycles triggered by the wall clock) as needed.

    \item {\em An external task fails, but can be fixed}. For example, a
        forecast model aborts trying to read a corrupted data file that
        can be regenerated correctly. The failed task will be noted by
        cylc, and its downstream dependants will not be able to run,
        but other tasks will carry on as normal while you address the
        problem. When fixed, use `cylc reset' to get the failed task to
        run again, after which it and its downstream dependants will
        catch up to the rest of the system as quickly as possible.

    \item {\em An important external task fails, but cannot be fixed.}
        In this case, if the task has a lot of downstream dependants,
        you will presumably need omit one or more cycles of the affected
        tasks, and cold start their part of the system at a the earliest
        possible subsequent cycle.  To do this, insert the relevant cold
        start task, or task group, at the later cycle, then purge the
        failed task and everything that depends on it (and on them, and
        so on) down to the cold start time.  Other downstream forecast
        models will be able to pick up immediately so long their most
        recent previous instance (i.e.\ just before the gap) wrote out
        sufficient restart outputs to bridge the gap (otherwise they,
        or perhaps the entire system, will need to be cold started). 

    \item {\em HELP, I attempted a drastic intervention in a complex
        system, using the horrifying purge command, and this time I
        really screwed the pooch!} Before any operation that alters the
        sytem state, cylc automatically writes out a special state dump
        file and reports the filename in the main log. Shut the system
        down and restart it from its pre-intervention state (just
        cut-and-paste the state dump filename from the main log file -
        the file path is not required because the file will be in the
        configured system state dump directory).  Then {\em retry your
        intervention in practice mode} before doing it for real!

\end{itemize}

\subsection{Dead System Cleanup}
\label{DeadSystemCleanup}

\subsubsection{Normal Shutdown}

Normally cylc waits for any currently running tasks to finish, then
unregisters its own objects from the Pyro nameserver before shutting
down. There will be nothing to clean up. 

\subsubsection{Shutdown NOW or Controlled Abort}

If the system operator uses \lstinline=cylc stop --now SYSTEM=, or the
system shuts down after detecting some know error condition, cylc will
unregister its objects from the Pyro nameserver before shutting down
immediately, even if there are still tasks running. After shutdown any
calls to \lstinline=cylc message= made by still-running tasks will
fail, because the system being targetted by the messages no longer
exists.  Consequently the system operator may need to manually kill some
left over tasks or zombie \lstinline=_cylc-message= processes. 

\subsubsection{Uncontrolled System Abort}

In this case, in addition to the possible existence of spawned tasks
that are still running (above), the system may have left zombie objects
in the Pyro nameserver. In this case \lstinline=cylc list-all= will
report that the system is still in use, and cylc will refuse to restart
the system until you delete the left over objects from the nameserver:

\begin{lstlisting}
pyro-nsc delete-group {USER}_{SYSTEM}
\end{lstlisting}

\subsubsection{A Stalled System}

If, for instance, you try to run a system whose task scripts do not have 
executable permissions, cylc may stall indefinitely with one or more
tasks in the ``submitted'' state. \lstinline=cylc stop --now= can be
used to shut the system down cleanly (the \lstinline=--now= option is
required because by default cylc will wait for any submitted or running
jobs to complete before shutting down).


\pagebreak
\section{Monitoring And Alerting}
\label{SystemMonitors}

Cylc registers a {\em system state summary} object, which is constantly
updated as the system evolves, with the Pyro nameserver. This provides a
general mechanism for remote system monitoring. Monitor programs can
connect to this object, extract whatever information they want from it,
and ignore the rest. It is anticipated that monitors utilizing more
sophisticated gui front ends will be developed in the future (we already
have one web-based monitor, but it isn't quite ready for inclusion in
the cylc repository). For the moment, the existing terminal based
monitors are adequate, although they would need modification if there
were too many tasks to display in a maximized terminal window at once.
Terminal line-wrapping does allow a large number of tasks to be
displayed, however (it's not pretty but it works!). 

\begin{figure}
    \begin{center}
        \includegraphics[width=14cm]{eco-monitor} 
    \end{center}
    \caption[monitor view of EcoConnect]{\small The main terminal-based
    cylc system monitor viewing the entire EcoConnect system.}
    \label{fig-monitor-eco} 
\end{figure} 

Screenshots of the two current system monitors can be seen in
Figures~\ref{fig-monitor} and~\ref{fig-monitor-r}, and
Figure~\ref{fig-monitor-eco} shows a view of the entire ecoconnect operation.

\subsection{Automated Alerting}

A real forecasting system probably needs an automated alerting system  
to let the system operators know of task failures or time outputs, e.g.\ 
by email, SMS, or pager.  EcoConnect currently uses {\em Nagios}
(http://www.nagios.org) for this purpose.  Each part of the forecasting
system can raise its own alerts {\em or} alerting could be handled
centrally through cylc via a minor change to the messaging interface,
\lstinline=$CYLC_DIR/bin/_cylc-message= (e.g.\ to automatically notify 
nagios as well as cylc whenever a CRITICAL message comes in).


\pagebreak
\section{A Complete Working Example}
\label{ACompleteWorkingExample}

This section contains complete taskdef and task implementation listings
for the example system used to illustrate the scheduling discussion in
{\em How Cylc Works} (Section~\ref{HowCylcWorks}). The example system
is located in:

\begin{lstlisting}
$CYLC_DIR/system/userguide/
\end{lstlisting}

 While this is clearly not a real forecasting system, it does have the
 properties of a real system as far as scheduling is concerned.  

\input{../systems/userguide/README.tex}

\lstset{ basicstyle=\color{basic}\scriptsize\ttfamily }

\pagebreak
\input{example-system.tex}

\section{Other Working Examples}
\label{OtherWorkingExamples}

\subsection{Nested}

In this example system, {\em task C} from the userguide system has been
replaced by a task called {\em userguide}, behind which is an entire
sub-system (the userguide example system) running a single cycle under
its own scheduler.

To run this, configure and register both the userguide and nested
systems. Then start two system monitors, one to follow each system,
before starting the scheduler on the nested system. You should see that 
whenever a new `userguide' task runs in the nested system, a separate
instance of the entire userguide example system will start up and run
for a single cycle. When the subsystem finishes and exits, the
corresponding task in the main system will drop into the finished state.

This example is included because it rather nicely illustrates the power
and flexibility of cylc. That said, the author cannot think of any good
reason why you would actually want to do this in a real forecasting
system! It would almost certainly be better to include the sub-system
tasks in the main system.

\subsection{File-Move}

This example system illustrates use of a generic task script, which in
this case transfers files between locations, to implement a particular
system task, with task-specific inputs provided through environment
variables defined in the task definition file.  More generally, it shows
how to move real input/output files around to connect tasks at the
control system level, rather than expecting the external tasks
themselves to know about the wider system (i.e.\ where to get input
files that are generated by another task, or where to put output files
that will be used by another task).  See {\em Handling Real
Dependencies} (Section~\ref{HandlingRealDependencies} for more
on this).

\subsection{Distributed}
\label{Distributed}

This example system is a variant of the file-move system in which the
two forecast model tasks execute on another machine on the network.  The
{\em file-transfer} script is invoked twice, once to put input files on
the remote machine, and once retrieve output files from the remote
machine (these connector tasks would be unnecessary if the forecast
tasks themselves knew where to get and put their input and output files,
respectively). The forecast model restart outputs reside on the remote
machine.

The distributed example system serves to illustrate:

\begin{itemize}
    \item control of a system having tasks distributed across a network.
    \item use of different job submission methods for different tasks.
\end{itemize}

Unlike the other example systems, this one will not quite work ``out of
the box''. You will need to:

\begin{itemize}
    \item set the hostname of your remote machine in the
        \lstinline=$SUPERCOMPUTER= variable that is defined in 
        \lstinline=systems/distributed/system_config.py=
    \item configure passwordless ssh access to the remote machine.
    \item ensure the Pyro nameserver is accessible from the local and
        remote machines (it can run on either machine, or somewhere else
        entirely).
    \item install the remote task scripts on the remote machine.
    \item install cylc on the remote machine (the remote task must be
        able to call \lstinline=cylc message=).
\end{itemize}

The distributed example system is part of cylc, so the last two items above
can be achieved by simply installing cylc on the remote machine.  Note that
the remote task scripts, if their absolute paths are not supplied in the
taskdef TASK key, must be in the PATH environment set in the taskdef
file (and likewise for the remote cylc bin directory).

The \lstinline=background_remote= job submission class assumes the local
and remote user names are the same.  If not, the taskdef OWNER key can
be used, and a slightly modified version of
\lstinline=background_remote= derived to use the correct remote
username.

The distributed example can also be tested using the local machine as
the remote machine, in which case the forecast model tasks will be
submitted locally by the \lstinline=background_remote= job class, and
you will require passwordless ssh self-access on the machine.


\pagebreak
\subsection{SCS Demo}

This example system, which resides in 
\lstinline=$CYLC_DIR/systems/scs-demo=,
demonstrates how to set up a single Met Office
UM-based forecast analysis suite that would normally be run by SCS.
Features that distinguish this system are:

\begin{itemize}

    \item dummy mode only - no tasks scripts have been implemented.

    \item restricted start time (see the system config file) - the
        system can cold start at 06Z only

    \item not all tasks run in all cycles - see arch, g\_lbc, post2

    \item intercycle dependence other than forecast model restart 
        dependencies - g\_lbc outputs are used by two subsequent UM\_nz
        tasks.

    \item UM\_nz behaves differently in different cycles - 00,12Z short
        forecast, 06,18Z long forecast.

    \item the VAR task depends on the OPS tasks {\em completing} - i.e.\
        succeeding OR failing, because obs processing is expected to
        fail sometimes.  Try this with:

        \begin{lstlisting}
cylc start -d --fail-out=OPS1%YYYYMMDDHH ...
        \end{lstlisting}

        VAR will not be delayed, but the failed OPS task does have to be
        killed or it will eventually stall the system at the maximum
        runahead time (see {\em System Config Files},
        Section~\ref{SystemConfigFiles}).
        
\end{itemize}

Here's some more information from the system README file:

\lstset{language=}
\lstinputlisting{../systems/scs-demo/README.txt}

\subsubsection{Finishing It Off}

Configure the OPS, VAR, and UM tasks as standalone jobs via their
respective UIs, then perform some minor surgery the resulting
job scripts so that they take \lstinline=$CYCLE_TIME= from the
environment, and add cylc messaging to report startup, finish, failure,
and completed outputs.

\pagebreak
\section{Command Reference}
\label{CommandReference}

The information in this section is auto-generated from
the current command set during document processing, using  
\lstinline=cylc COMMAND --help=. 
Command self-documentation, however, is intended as a minimalist
on-the-fly usage reminder so additional information is appended in
some cases.
  
\lstset{ basicstyle=\color{basic}\footnotesize\ttfamily }
\lstset{language=usage}

\input{commands.tex}

\pagebreak
\section{Master Task Definition Template}
\label{MasterTaskDefinitionTemplate}

Listed below is the full task definitition template with all items
documented.

\lstset{language=cylctaskdef}

\lstinputlisting{../templates/taskdef/master.def}

\lstset{language=}

\pagebreak
\section{Master Task Script Templates}
\label{MasterTaskScriptTemplates}

\input{../templates/scripts/README.tex}

\lstset{language=bash}

\pagebreak
\subsection{Free Tasks}
\lstinputlisting{../templates/scripts/free-task.sh}

\pagebreak
\subsection{Tied Tasks}
\lstinputlisting{../templates/scripts/tied-task.sh}

\pagebreak
\section{Orderly Product Generation}
\label{OrderlyProductGeneration}

Note that ``correct scheduling'' is not equivalent to ``orderly
generation of products by cycle time''.  Under cylc, a product
generation task will trigger as soon as its prerequisites are satisfied 
(i.e.\ as soon as its input files are available) regardless of
whether other tasks with the same cycle time have finished or have yet
to run. 

If your product presentation or delivery system demands that all
products for one cycle time are uploaded before any from the next
cycle, then:

\begin{itemize}
    \item this is inefficient because cylc is capable of generating products 
        for each part of your system independently at the earliest
        possible time - maybe you should fix your delivery system!
    \item if you must, you can introduce artificial dependencies into
        your system to ensure that the final forecast products are never
        delivered ``out of sequence'' even if some are available early
        than others.  One way of doing this would be to have a final
        ``product upload'' task that depends on completion of all the
        real product generation tasks at the same cycle time.
\end{itemize}

\pagebreak
\section{How Cylc Interacts With Batch Queue Schedulers}
\label{HowCylcInteractsWithBatchQueueSchedulers}

Cylc dynamically adapts, at the level of individual tasks, to any
external situation that affects when a task can run. This includes
post-submission delays due to computational resource contention. Cylc
just decides when a task is {\em ready} to run - i.e.\ when its
prerequisites are satisfied.  If the external task is delayed because of
resource contention, it will not be able to report its outputs complete
until it does run, and no dependent downstream tasks will trigger until
that comes about.


\pagebreak
\appendix

\section{Object Oriented Programming}
\label{ObjectOrientedProgramming}

Cylc relies heavily on Object Oriented Programming (OOP) concepts,
particularly the {\em polymorphic} nature of the task proxy objects.
An absolutely minimal explanation of this follows; 
please refer to an OOP reference for more detail.

A {\bf class} is a generalisation of data type to include behaviour
(i.e.\ functions or methods) as well as state. 

%For example, a $shape$ class could define a $position$ data member to
%hold the location of a shape object, a $move()$ method that by which
%a shape object can alter its position, and a $draw()$ method that
%causes it to display itself on screen.

An {\bf object} is a more or less self contained specific instance
of a class. This is analagous to specific integer variables being 
instances of the integer data type.

A {\bf derived class} or {\bf subclass} {\em inherits} the properties
(methods and data members) of its parent class. It can also override
specific properties, or add new properties that aren't present in the
parent. Calling a particular method on an object invokes the object's
own method if one is defined, otherwise the parent class is searched,
and so on down to the root of the inheritance graph. 

%For example, we could derive a $circle$ class from $shape$, adding a
%`radius' data member and overriding the $draw()$ to get circle objects
%to display themselves as actual circles.  Because we didn't override the
%$move()$ method, calling $circle.move()$ would invoke the base class
%method, $shape.move()$. 


{\bf Polymorphism} is the ability of one type to appear as and be used
like another type.  In OOP languages with inheritance, this usually
refers to the ability to treat derived/sub-class objects as if they were
members of a common base class. In particular, a group of mixed-type
objects can all be treated as members of a common base class. 
%For example, a group of %$circles$, $triangles$, and $squares$ could 
%be manipulated by code designed entirely to handel $shapes$; calling
%$[shape].draw()$ will invoke the right derived class $draw()$ method. 
This is a powerful mechanism because it allows existing old code,
without modification, to manipulate new objects so long as they 
derive from the original base class.
%If we later derive an entirely new kind of shape ($hexagon$, say) with
%it's own unique behaviour, the existing program, without modification,
%will process the new objects in the proper hexagon-specific way.  

In cylc, all task proxy objects are derived from a base class that 
embodies the properties and behaviour common to all task proxies. 
The scheduling algorithm works with instances of the base class so that
any current or future derived task object can be handled by the program
without modification (other than deriving the new subclass itself).


\pagebreak
\section{Pyro} 
\label{Pyro}

Pyro (Python Remote Objects) is a widely used open source objected
oriented Remote Procedure Call technology, see {\em
http://pyro.sourceforge.net}.

\subsection{Pyro Software License (MIT license)}
\label{PyroSoftwareLicense(MITlicense)}

Pyro is Copyright (c) 2002  by Irmen de Jong.

Permission is hereby granted, free of charge, to any person obtaining a
copy of this software and associated documentation files (the
``Software''), to deal in the Software without restriction, including
without limitation the rights to use, copy, modify, merge, publish,
distribute, sublicense, and/or sell copies of the Software, and to
permit persons to whom the Software is furnished to do so, subject to
the following conditions:

The above copyright notice and this permission notice shall be included
in all copies or substantial portions of the Software.

THE SOFTWARE IS PROVIDED ``AS IS'', WITHOUT WARRANTY OF ANY KIND,
EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF
MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT.
IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY
CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT,
TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE
SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.
                                          
\subsection{Single- or Multi-Threaded Pyro?}
\label{Single-orMulti-ThreadedPyro?}

In single threaded mode Pyro's \lstinline=handleRequests()= returns
after either a timeout has occurred or at least one request
(i.e.\ remote method call) was handled. Using \lstinline|timeout = None| 
allows us to process tasks {\em only} after remote method invocations
come in.  Further, we can detect the remote calls that actually change
task states, and thereby drop into the task processing code only when
necessary, which eliminates a lot of extraneous output when debugging
the task processing loop (e.g.\ in dummy mode there are a lot of remote
calls on the dummy clock object, which does not alter tasks at all). 

In multithreaded mode, \lstinline=handleRequests()= returns immediately
after creating a new request handling thread for a single remote object,
and thereafter remote method calls on that object come in asynchronously
in the dedicated thread. This is not good for cylc's scheduling
algorithm because tasks are only set running in the task processing
block which can be delayed while \lstinline=handleRequests()= blocks waiting
for a new connection to be established, even as messages that warrant
task processing are coming in on existing connections. The only way
around this seems to be to do task processing on \lstinline=handleRequests()=
timeouts which results in a lot of unnecessary processing when nothing
important is happening.

\subsection{Running Pyro}
\label{RunningPyro}

To see if there is a Pyro nameserver running already on your network
segment, use 
\begin{lstlisting}
pyro-nsc [-h host] [-p port] ping
\end{lstlisting}
Invoke the command without arguments to see a list of options.

\lstset{language=bash}

\begin{lstlisting}
$ pyro-nsc ping
Locator: searching Pyro Name Server...
Locator: retry 1
Locator: searching Pyro Name Server...
Locator: retry 1
Trying host oliverh-33191VL
Locator: contacting Pyro Name Server...
NS is at 127.0.0.2 (oliverh-33191VL.greta.niwa.co.nz) port 9090
NS is up and running!

$ pyro-nsc -h localhost ping
Locator: contacting Pyro Name Server...
NS is at 127.0.0.1 (localhost) port 9090
NS is up and running!
\end{lstlisting}

To start a Pyro nameserver, use \lstinline{nohup} so that it
will not die with your terminal session: 

\begin{lstlisting}
 nohup pyro-ns &
\end{lstlisting}

For more information, see the Pyro userguide.


\pagebreak
\section{Upgrading Taskdefs}

A suggested relatively painless way to make textual changes to many
taskdef files {\em en masse}, e.g.\ to make them compatible with a new
version of cylc that is not backward compatible in this respect:

\begin{itemize}
    \item record all pending changes to the system repository
    \item make bulk changes in-place using perl's powerful regex 
       substitution mechanism, e.g.:
       \begin{lstlisting}
for F in *.def; do perl -pi -e 's/OLD/NEW/g' $F; done
       \end{lstlisting}
   \item check this had the desired effect with 
       \lstinline=darcs whatsnew= (or the equivalent in your chosen
       revision control system). If not, revert and try again.
\end{itemize}


\pagebreak
\section{Current Limitations}

\subsection{Cycle Time Granularity}

{\em The minimum cycle time granularity for a task is currently one hour}.

Note that this is only loosely connected to when, or how frequently, a
task actually runs, and only in real time operation: under cylc tasks
can run as soon as their prerequisites are satisfied regardless of their
nominal cycle time. However, it would be easy to extend this to minutes
and seconds if necessary.  

\subsection{Task Frequency}

{\em Every task must run at least once per day.}

(Of cycle time, not real time). Valid cycles times for a task are 
specified in the taskdef \lstinline=CYCLES= key.  It would be
easy to allow less frequent tasks if required. 


%\section{Miscellaneous Notes}
%\label{MiscellaneousNotes}
%
%%\subsection{Cycle Dependent Prerequisites}
%%It may be better to split a task into two (or more) than use this 
%%capability. NOT FOR FORECAST MODELS WITH RESTART OUTPUTS!

%\subsection{Catching Up}
%labelsubsection{CatchingUp}
%
%The state of being ``caught up'' or not is a property of individual
%tasks, not the whole system, and additionally it should only matter to
%external contact tasks, i.e.\ those that wait on external data that is
%available at a wall clock time of T (task cycle time) + o (some offset
%insterval). Where this matters an external task can detect whether or
%not it has caught up (and signal this to its proxy object in cylc) by
%comparing its cycle time (and offset) to the wall clock time.  

\end{document}
